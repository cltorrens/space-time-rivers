---
title: "02_select and visualize NEON data for model"
author: "Christa Torrens"
format: html
editor: visual
---

## Selecting and visualizing NEON NO3 data for the stan model

The purpose of this script is to load the NEON nitrate Rdata, separate it by site, and then identify at least 100 complete "good" days per site, to inform the model. "Good" days = complete days where the diel signal of autotrophic nitrate uptake is clearly visible and not affected by, e.g., hydrology or other physical processes. When there are gaps in the data, we will fill up to 2-hour gaps using the zoo() package, linear method. If there are gaps > 2 hours, OR multiple smaller gaps, the day will be discarded. 

First load the required packages

### Loading required packages

Add these before knitting:


```{r loading packages}
#| warning: false
#| output: false

# load packages
library(scales)
library(magrittr) # moved from  'light each day as vector'
library(tidyverse)
library(lubridate)
library(streamMetabolizer)
library(rstan)
library(tidybayes)
library(GGally)
library(shinystan)
library(zoo)
library(neonUtilities)
library(ggpubr)
library(brms)
library(here) # allows project-based file paths
library(pracma) # for 1 type of light AUC calcs
library(httr) # helps w. the NSRDB light download
library(dygraphs) # creates interactive ts graphs

# make sure the working directory is set to the project level
setwd(here())

```


### Functions
Define any functions

```{r - functions}

selectRdata <- function(data, site, tz, span) {
  data %>%
  filter(siteID == site) %>%
  mutate(local_datetime = with_tz(startDateTime, tzone=tz),
         Jday = yday(local_datetime), , 
         model_datetime = local_datetime - hours(4), 
         model_jday = yday(model_datetime)) %>%
   filter(year(local_datetime) %in% span)
}

# data = the name of the NO3 Rdata 
# site = the site ID from the Rdata, in quotes " "
# tz = the desired time zone for the site, in quotes " " 
# span = the year or years to filter for in the Rdata. 

# NB: The current dataset (as of Feb 2025) runs from Dec 2016-Dec 2024; QA/QC'd data w good discharge = Jan 2021-June 2023


```

Then load the NEON NO3 Rdata

### Loading the NEON Rdata

```{r load NEON NO3 data}
#| output: false
#| message: false

load(here("N_uptake_NEON/data/neon_data_derived/no3_dataset.Rdata")) 
#no3_data_sensor is the object name

View(no3_data_sensor)
unique(no3_data_sensor$siteID)   

# CURRENT DATA FILE:
# ARIK, BIGC, BLDE, BLUE, BLWA, CARI, COMO, CUPE, FLNT, GUIL, HOPB, KING, LECO, MART, OKSR, POSE, PRIN, REDB, SYCA, TECR, WALK, WLOU

# ORIGINAL FOUR:"KING" "WALK" "BIGC" "CARI"

# Not pulled:Lewis Run [LEWI], Clarke, VA; Mayfield Creek [MAYF], Bibb, AL; McDiffett Creek [MCDI], Wabaunsee, KS; McRae Creek [MCRA], Linn, OR; Tombigbee River [TOMB], Choctaw, AL

```


### Viewing, selecting, and saving data by site

For each site:
* Filter by site ID and set appropriate time zone for local time (default for NEON is UTC)

* Use OlsonNames() to check for accurate timezone names: "US/Eastern" "US/Central" "US/Mountain" "US/Pacific" "US/Alaska" "US/Arizona" "US/Hawaii" "America/Puerto_Rico"

* Select the days to use in the model: create 1 dataframe per site, across mulitple years. Aim for at least 100 full days with clear diel no3 swings. It may be easiest to explore and select data by year... Try it by site and see how it goes. 

* Per Bobby Hensley, data from 2021 on will have the best discharge data (Q and O2 data prior to 2021 are 'shoddy'). Currently focusing on 2021-2023 data. 

* 2024 Q data has been QA/QC'd as of March 2025

* NB: for 2024 NO3 data, Jan-Jun data are QA/QC'd and July-Dec data are still provisional (as of 3/06/2025)

Site descriptions: 
https://www.neonscience.org/field-sites/explore-field-sites

Individual sites follow this pattern: 
BIGC: https://www.neonscience.org/field-sites/bigc 
CARI: https://www.neonscience.org/field-sites/cari 
KING: https://www.neonscience.org/field-sites/king 
WALK: https://www.neonscience.org/field-sites/walk
(etc.)


#### Arikaree River, Yuma, CO
nitrate sensor lat-long: 39.758356	-102.44859
reference elevation (m): 1178.7 

```{r ARIK}

##### Create object for ARIK => Arikaree River, Yuma, CO

# arik.df <- no3_data_sensor %>%
#   filter(siteID == "ARIK") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#    filter(year(local_datetime) == 2021:2023)
# 

arik.df <- selectRdata(data=no3_data_sensor, site="ARIK", tz="US/Mountain", span=2021:2024)


##### Visualize, select and clean ARIK data

yr <- 2021
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
arik.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("ARIK, 2023") +
  theme_bw()


##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/arik_df.csv")
write_csv(arik.df, path)

```




#### Upper Big Creek, Fresno, CA
nitrate sensor lat-long: 37.057672	-119.255375	 
elevation (m): 1131.24

"overhang" sensor location: lat-long: 37.057515	-119.255046	elevation (m): 1127.43

###### Load data

```{r - BIGC}
#| output: false
#| message: false

##### Create object for BIGC => West St Louis Creek, Grand, CO

bigc.df <- selectRdata(data=no3_data_sensor, site="BIGC", tz="US/Pacific", span=2021:2024)

bigc_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/BIGC_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Pacific"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(bigc_light.df$local_datetime)
tz(bigc.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

###### Visualize, select and clean BIGC data
```{r - BIGC visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "BIGC, Jun 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
bigc.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


# bigc_dy <- bigc.df %>%
  # select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=bigc_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     BIGC: COMMENTS?


# ID Jdays: 

##    2021: 56, 57, 58, 59, 60, 61, 63, 64, 65, 128, 129, 130, 133, 139, 140, 149, 150, 151, 152, 153, [154], 155, 156, 157, 158, 159, 160, 175, 176, [177], 178, [179], 197, 198, 202, 203, 204, 225, 226, 227, 228, 229, 230, 243, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259, 260, 261, 262, 263, 264, 267, 268, 269, 270, 274, 275, 276, [337,338, 339, 340 - ampl. may be too low]

##    2022:  22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 52, 58, 59, 68, 69, 70, 71, 72, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268 

##    2023: 33, 34, 41, 43, 44, 46, 47, 48, 49, 50, 51, 91, 92, 96, 101, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350

# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 24, 25, 26, 27, 28, 29, 30, 31, 74, 75, 76, 80, 81, 82, 93, 94, 99, 100, 137, 138, 142, 143, 146, 153, 154, 155, 163, 168


# create objects from selected jdays for each year
list.21 <- c(56, 57, 58, 59, 60, 61, 63, 64, 65, 128, 129, 130, 133, 139, 140, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 175, 176, 177, 178, 179, 197, 198, 202, 203, 204, 225, 226, 227, 228, 229, 230, 243, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259, 260, 261, 262, 263, 264, 267, 268, 269, 270, 274, 275, 276, 337, 338, 339, 340)

list.22 <- c(22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 52, 58, 59, 68, 69, 70, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268)

list.23 <- c(33, 34, 41, 43, 44, 46, 47, 48, 49, 50, 51, 91, 92, 96, 101, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350)


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
bigc.df.21 <- bigc.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
bigc.df.22 <- bigc.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

bigc.df.23 <- bigc.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

# Check for complete days: should have 96 obs/ day
bigc.df.21 %>% count(model_jday) #70
bigc.df.22 %>% count(model_jday) #86, after removing 71 and 72 (92 obs each)
bigc.df.23 %>% count(model_jday) #53, after removing 308 (100 obs)

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- bigc.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- bigc.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- bigc.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

# View days with alternate n values
# bigc22_310 <- bigc.df.22 %>% filter(model_jday == 310)
# bigc21_310 <- bigc.df.22 %>% filter(model_jday == 310)
# View(bigc73)
# View(bigc310)
# 
# bigc310 <- bigc.df.22 %>% filter(Jday == 310)
# View(bigc310)


##### Combine selected days into 1 df, select columns 
bigc.df.2123 <- bind_rows(bigc.df.21, bigc.df.22, bigc.df.23) %>%
  mutate(Year = year(local_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing bigc.df.2123 observations by 96 
# 209 for bigc


##### Combine df with sat_light data for the selected model days
bigc.wlight.df.2123 <- left_join(x=bigc.df.2123,
                                 y=bigc_light.df, 
                                 by = "local_datetime") 


View(bigc.wlight.df.2123)

# check the 1st day in the df to make sure light joined correctly
jday21_56 <- bigc_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 2) %>%
  filter(day(local_datetime) == 25)


# save to keep progress
write_csv(bigc.wlight.df.2123,file=here("N_uptake_NEON/data/neon_data_joined/BIGC_wlight_2123_joined.csv"))

```

###### Fill any gaps in no3 data
```{r fill gaps}

##############################  Reload data if needed  #########################
# bigc.wlight.df.2123 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2123_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(bigc.wlight.df.2123$surfWaterNitrateMean))
no3NA

# 13 occurrences: 595   596   877  3191  3523  3766  8476 15953 15968 15969 17308 17601 19377

# When do these occur? (ID any particularly bad days to remove)
NAdays <- bigc.wlight.df.2123 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  # 2021: 63(2), 128, 198, 204, 227
        # 2022: 70
        # 2023: 51(3), 304, 307, 342

# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(bigc.wlight.df.2123$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 15945:15985
plot(bigc.wlight.df.2123$local_datetime[span], bigc.wlight.df.2123$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
bigc.wlight.df.2123$surfWaterNitrateMean <- na.approx(bigc.wlight.df.2123$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(bigc.wlight.df.2123$surfWaterNitrateMean)) 

# no NAs remain

N_e <- mean(bigc.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)  #1.811533
N_sd <- sd(bigc.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)   #0.7407876

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
bigc.wlight.df.h <- bigc.wlight.df.2123 %>%
  filter(minute(local_datetime) == 0) 
# Mean of selected dataset
N_e <- mean(bigc.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #1.811583
N_sd <- sd(bigc.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #0.7408184



```


###### Visualize cleaned data

```{r - visualize BIGC clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(bigc.wlight.df.h$model_jday)



```



###### Save cleaned site df
```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/bigc_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/bigc_hourly_clean.csv")
write_csv(bigc.wlight.df.2123, path)
write_csv(bigc.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# bigc.wlight.df.2122 <- read_csv(path)
# bigc.wlight.df.h <- read_csv(path_h)

```



#### Blacktail Deer Creek, Park, WY
nitrate sensor lat-long: 44.953606	-110.589396	
elevation (m): 2023.27

```{r - BLDE}

##### Create object for BLDE => Blacktail Deer Creek, Park, WY

blde.df <- selectRdata(data=no3_data_sensor, site="BLDE", tz="US/Mountain", span=2021:2024)


# blde.df <- no3_data_sensor %>%
#   filter(siteID == "BLDE") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)



##### Visualize, select and clean BLDE data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
blde.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("BLDE, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/blde_df.csv")
write_csv(blde.df, path)

```


#### Blue River, Johnston, OK
nitrate sensor lat-long: 34.448448	-96.622796	** overhang sensor - the other sensor info says 'not used'
elevation (m): 288.31

```{r - BLUE}

##### Create object for BLUE => Blue River, Johnston, OK

blue.df <- selectRdata(data=no3_data_sensor, site="BLUE", tz="US/Central", span=2021:2024)


# blue.df <- no3_data_sensor %>%
#   filter(siteID == "BLUE") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Central"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean BLUE data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
blue.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("BLUE, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/blue_df.csv")
write_csv(blue.df, path)

```

#### Black Warrior River, Greene, AL
nitrate sensor lat-long: 32.542478	-87.797972	    ** sensor buoy (river)
elevation (m): 23

```{r - BLWA}

##### Create object for BLWA => Black Warrior River, Greene, AL

blwa.df <- selectRdata(data=no3_data_sensor, site="BLWA", tz="US/Central", span=2021:2024)


# blwa.df <- no3_data_sensor %>%
#   filter(siteID == "BLWA") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Central"),
#          Jday = yday(local_datetime)) %>%
#    filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean BLWA data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
blwa.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("BLWA, 2023") +
  theme_bw()


##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/blwa_df.csv")
write_csv(blwa.df, path)

```


#### Caribou Creek, Fairbanks North Star, AK
nitrate sensor lat-long: 65.153076	-147.502004	
elevation (m): 225.41

```{r - CARI}

##### Create object for CARI => Caribou Creek, Fairbanks North Star, AK

cari.df <- selectRdata(data=no3_data_sensor, site="CARI", tz="US/Alaska", span=2021:2024)


# cari.df <- no3_data_sensor %>%
#   filter(siteID == "CARI") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Alaska"), 
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean CARI data

yr <- 2023
mo <- 5:6

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
cari.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  facet_wrap(~Jday) +
  ggtitle("CARI, 2023: May-Jun") +
  theme_bw()


##### ID Jdays to save for model

cari.df$Jday


##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/cari_df.csv")
write_csv(cari.df, path)



## __________________________________________________________________________

##### filter data by selected year(s)
cari.df.2021 <- cari.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

cari.df.2022 <- cari.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

cari.df.2023 <- cari.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save df
path <- here("N_uptake_NEON/data/neon_data_by_year/cari.df_2021.csv")
write_csv(cari.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/cari.df_2022.csv")
write_csv(cari.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/cari.df_2023.csv")
write_csv(cari.df.2023, path)

```


#### Como Creek, Boulder CO
nitrate sensor lat-long: 40.034934	-105.544417	
elevation (m): 3022.86

```{r - COMO}

##### Create object for COMO => Como Creek, Boulder CO

como.df <- selectRdata(data=no3_data_sensor, site="COMO", tz="US/Mountain", span=2021:2024)

# como.df <- no3_data_sensor %>%
#   filter(siteID == "COMO") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean COMO data

yr <- 2023
mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
como.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(2,8) +
  facet_wrap(~Jday) +
  ggtitle("COMO, 2023: Jan-Feb") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/como_df.csv")
write_csv(como.df, path)

```


#### Rio Cupeyes, San German Municipio, PR
nitrate sensor lat-long: 18.110265	-66.986411	
elevation (m): 149.9

###### Load data
```{r - CUPE}
#| output: false
#| message: false

##### Create object for CUPE => Rio Cupeyes, San German Municipio, PR

cupe.df <- selectRdata(data=no3_data_sensor, site="CUPE", tz="America/Puerto_Rico", span=2021:2024)

cupe_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/CUPE_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="America/Puerto_Rico"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(cupe_light.df$local_datetime)
tz(cupe.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

###### Visualize, select and clean CUPE data
```{r - CUPE visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "CUPE, Jun 2024"
# ylim(20,30) for Jan-Jun 21, Jan-Jun 23; (20, 33) for ~ Aug-Dec 2023, Jan- 2024; (17,27) for Jul-Dec 21, most of 2022, Jul 23, Jan- 2024;    : (25,35) for Oct-Dec 22

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
cupe.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(17, 27) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


## Dygraph for interactive chart w slider - meh, doesn't work all that well for my purposes.
# cupe_dy <- cupe.df %>%
# select(local_datetime, surfWaterNitrateMean)
# 
# dygraph(data=cupe_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model
# doing this early this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays

# visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
# CUPE: COMMENTS?  High NO3-N (20-35 range), very clear signals unless the data is disrupted. Several extended (hydrologic?) issues, especially in 2022. TONS of days selected. 


# ID Jdays: 

##    2021: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, [52, 53 - odd shapes], 54, 55, 60, 61, 62, 63, 63, 65, 66, 68, 69, 72, 73, 74, 75, 91, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 120, [128 - slanted bseline], 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 148, 149, 150, 151, 154, 155, 156, 158, 162, 163, 164, 165, 166, 169, 170, 171, 179, 180, 185, 186, 187, 188, 189, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 210, 211, 212, 215, 216, 217, 221, 222, 223, 225, 226, 229, 232, 239, 240, 241, 242, 244, 246, 247, 281, 282, 283, 285, [286 - lower ampl], 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364

##    2022: 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, [141 - slight wobble], 149, 150, 155, 156, 157, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 184, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, [221, 222, 238, 239, 240, 249, 251, 252, 258, 293 - low ampl - don't use unless testing something later] 298, 321, 327, 328, 329, 330, 331,  - mb include even tho relatively low?], 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 352, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362 

##    2023: 1, 2, 3, 4, 5, 6, 9, 20, 21, 25, 26, 27, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 70, 71, 72, 77, 78, 79, 85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102, 111, 112, 113, 115, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 182, 183, 184, 186, 187, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 236, 245, 246, 249, 250, 257, 270, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 301, 302, 303, 304, 309, 310, 311, 312, 318, 319, 321, 322, 323, 326, 327, 328, 329, [335, 336, 338, 339, 340, 341, 342, 343, 346, 347, may be too low... ], 351, 352, 535, 356, 357, 358, 359, 362, 363, 364, 365


# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 1, 2, 3, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 26, 27, 28, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 71, 72, 76, 77, 79, 86, 87, 93, 94, 97, 98, 99, 100, 101, 105, 106, 107, 109, [125 - low?], 126, 140, 141, 142, 143, 144, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 171, 177, 178, [182 - partial final day in June bc of model_day use]

# create objects from selected jdays for each year
list.21 <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 60, 61, 62, 63, 63, 65, 66, 68, 69, 72, 73, 74, 75, 91, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 120, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 148, 149, 150, 151, 154, 155, 156, 158, 162, 163, 164, 165, 166, 169, 170, 171, 179, 180, 185, 186, 187, 188, 189, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 210, 211, 212, 215, 216, 217, 221, 222, 223, 225, 226, 229, 232, 239, 240, 241, 242, 244, 246, 247, 281, 282, 283, 285, 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364)

list.22 <- c(14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 149, 150, 155, 156, 157, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 184, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, 298, 321, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 352, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362)

list.23 <- c(1, 2, 3, 4, 5, 6, 9, 20, 21, 25, 26, 27, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 70, 71, 72, 77, 78, 79, 85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102, 111, 112, 113, 115, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 182, 183, 184, 186, 187, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 236, 245, 246, 249, 250, 257, 270, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 301, 302, 303, 304, 309, 310, 311, 312, 318, 319, 321, 322, 323, 326, 327, 328, 329, 351, 352, 535, 356, 357, 358, 359, 362, 363, 364, 365)


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
cupe.df.21 <- cupe.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
cupe.df.22 <- cupe.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

cupe.df.23 <- cupe.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

# Check for complete days: should have 96 obs/ day
cupe.df.21 %>% count(model_jday) #188
cupe.df.22 %>% count(model_jday) #132
cupe.df.23 %>% count(model_jday) #180

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- cupe.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- cupe.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- cupe.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

# All days, all 3 years had 96 obs. 

# View days with alternate n values
# cupe22_310 <- cupe.df.22 %>% filter(model_jday == 310)
# cupe21_310 <- cupe.df.22 %>% filter(model_jday == 310)
# View(cupe73)
# View(cupe310)
# 
# cupe310 <- cupe.df.22 %>% filter(Jday == 310)
# View(cupe310)


##### Combine selected days into 1 df, select columns 
cupe.df.2123 <- bind_rows(cupe.df.21, cupe.df.22, cupe.df.23) %>%
  mutate(Year = year(local_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing cupe.df.2123 observations by 96 
# 500 for cupe


##### Combine df with sat_light data for the selected model days
cupe.wlight.df.2123 <- left_join(x=cupe.df.2123,
                                 y=cupe_light.df, 
                                 by = "local_datetime") 


View(cupe.wlight.df.2123)

# check the 1st day in the df to make sure light joined correctly
jday21_01 <- cupe_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 1) %>%
  filter(day(local_datetime) == 1)

View(jday21_01)

# save to keep progress
write_csv(cupe.wlight.df.2123,file=here("N_uptake_NEON/data/neon_data_joined/CUPE_wlight_2123_joined.csv"))

```

###### Fill any gaps in no3 data
```{r fill gaps}

##############################  Reload data if needed  #########################
# cupe.wlight.df.2123 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2123_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(cupe.wlight.df.2123$surfWaterNitrateMean))
no3NA

# 46 occurrences:  888  1304  5839  5840  5844  5846  5847  5850  5854  5856  9618  9619  9620 11823 11824 12983 12984 12985 13786 15965 15966 15967 15988 21327 21328 21340 21709 24208 24442 31425 31736 31830 31831 32206 32877 39208 39209 40065 40066 40067 40068 40069 44076 44499 47174 47177

# When do these occur? (ID any particularly bad days to remove)
NAdays <- cupe.wlight.df.2123 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  # 2021: 10, 15, 75(8 - not continuous), 158(3), 201(2), 223(3), 242, 312(4)
        # 2022: 103(3), 110, 156, 165
        # 2023: 20, 26, 27(2), 31, 45, 166(2), 184(5), 257, 280, 352(2)

# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(cupe.wlight.df.2123$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 5830:5855, 40060:40075
# print(cupe.wlight.df.2123[5830:5860,])

span <- 40060:40075
plot(cupe.wlight.df.2123$local_datetime[span], cupe.wlight.df.2123$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable for both gaps


# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
cupe.wlight.df.2123$surfWaterNitrateMean <- na.approx(cupe.wlight.df.2123$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(cupe.wlight.df.2123$surfWaterNitrateMean)) 
# no NAs remain

N_e <- mean(cupe.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)  #24.42304
N_e
N_sd <- sd(cupe.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)   #2.786831
N_sd

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
cupe.wlight.df.h <- cupe.wlight.df.2123 %>%
  filter(minute(local_datetime) == 0) 
# Mean of selected dataset
N_e <- mean(cupe.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #24.4242
N_e
N_sd <- sd(cupe.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #2.785572
N_sd



```


###### Visualize cleaned data

```{r - visualize CUPE clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(cupe.wlight.df.h$model_jday)



```



###### Save cleaned site df
```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/cupe_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/cupe_hourly_clean.csv")
write_csv(cupe.wlight.df.2123, path)
write_csv(cupe.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# cupe.wlight.df.2122 <- read_csv(path)
# cupe.wlight.df.h <- read_csv(path_h)

```





#### Flint River, Baker, GA
nitrate sensor lat-long: 31.184609	-84.438438	** sensor buoy (river)
elevation (m): 30

```{r - FLNT}

##### Create object for FLNT => Flint River, Baker, GA

flnt.df <- selectRdata(data=no3_data_sensor, site="FLNT", tz="US/Eastern", span=2021:2024)


# flnt.df <- no3_data_sensor %>%
#   filter(siteID == "FLNT") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean FLNT data

yr <- 2023
mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
flnt.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  facet_wrap(~Jday) +
  ggtitle("FLNT, 2023: Jan-Feb") +
  theme_bw()


##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/flnt_df.csv")
write_csv(flnt.df, path)

```

#### Río Yahuecas, Adjuntas Municipio, PR
nitrate sensor lat-long: 18.174069	-66.799688	
elevation (m): 546.37

```{r - GUIL}

##### Create object for GUIL => Río Yahuecas, Adjuntas Municipio, PR

guil.df <- selectRdata(data=no3_data_sensor, site="GUIL", tz="America/Puerto_Rico", span=2021:2024)


# guil.df <- no3_data_sensor %>%
#   filter(siteID == "GUIL") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Puerto_Rico"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean GUIL data

yr <- 2023
# mo <- 2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
guil.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("GUIL, 2023") +
  theme_bw()


##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/guil_df.csv")
write_csv(guil.df, path)

```

#### Lower Hop Brook, Franklin, MA
nitrate sensor lat-long: 42.473264	-72.330924	
elevation (m): 214.2

overhang sensor location: 42.471752	-72.330641	elevation: 208.31

```{r - HOPB}

##### Create object for HOPB => Lower Hop Brook, Franklin, MA

hopb.df <- selectRdata(data=no3_data_sensor, site="HOPB", tz="US/Eastern", span=2021:2024)


# hopb.df <- no3_data_sensor %>%
#   filter(siteID == "HOPB") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean HOPB data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
hopb.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("HOPB, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/hopb_df.csv")
write_csv(hopb.df, path)

```

#### Kings Creek, Riley, KS
nitrate sensor lat-long: 39.105188	-96.603584	
elevation (m): 324.26

```{r - KING}

##### Create object for KING => Kings Creek, Riley, KS

king.df <- selectRdata(data=no3_data_sensor, site="KING", tz="US/Central", span=2021:2024)


# king.df <- no3_data_sensor %>%
#   filter(siteID == "KING") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Central"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)

##### Visualize, select and clean KING data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
king.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("KING, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/king_df.csv")
write_csv(king.df, path)





##________________________________________________________________________________

##### filter data by selected year(s)
king.df.2021 <- king.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

king.df.2022 <-  king.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

king.df.2023 <-  king.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)


##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/king.df_2021.csv")
write_csv(king.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/king.df_2022.csv")
write_csv(king.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/king.df_2023.csv")
write_csv(king.df.2023, path)



```


#### LeConte Creek, Sevier, TN
nitrate sensor lat-long: 35.69222	-83.504409	
elevation (m): 538.09

overhang sensor location: 35.692205	-83.504421	elevation: 537.52

```{r -  LECO}

##### Create object for LECO => LeConte Creek, Sevier, TN

leco.df <- selectRdata(data=no3_data_sensor, site="LECO", tz="US/Eastern", span=2021:2024) # LECO is in Sevier County = US Eastern

# leco.df <- no3_data_sensor %>%
#   filter(siteID == "LECO") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>% # Sevier County = US Eastern
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean LECO data

yr <- 2023
mo <- 3:4

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
leco.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  facet_wrap(~Jday) +
  ggtitle("LECO, 2023: Mar-Apr") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/leco_df.csv")
write_csv(leco.df, path)

```

[Did NOT model Lewis Run [LEWI], Clarke, VA]

#### Martha Creek, Skamania, WA
nitrate sensor lat-long: 45.792321	-121.929418	
elevation (m): 337.16

overhang sensor location: 45.792318	-121.92943	elevation: 337.02

```{r - MART}

##### Create object for MART => Martha Creek, Skamania, WA

mart.df <- selectRdata(data=no3_data_sensor, site="MART", tz="US/Pacific", span=2021:2024)


# mart.df <- no3_data_sensor %>%
#   filter(siteID == "MART") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Pacific"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean MART data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
mart.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("MART, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/mart_df.csv")
write_csv(mart.df, path)

```


[Did NOT model: Mayfield Creek [MAYF], Bibb, AL; McDiffett Creek [MCDI], Wabaunsee, KS; McRae Creek [MCRA], Linn, OR]

#### Oksrukuyik Creek, North Slope, AK
nitrate sensor lat-long: 68.669769	-149.142847	
elevation (m): 767.19

```{r - OKSR}

##### Create object for OKSR => Oksrukuyik Creek, North Slope, AK

oksr.df <- selectRdata(data=no3_data_sensor, site="OKSR", tz="US/Alaska", span=2021:2024)


# oksr.df <- no3_data_sensor %>%
#   filter(siteID == "OKSR") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Alaska"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)

##### Visualize, select and clean OKSR data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
oksr.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(0,10) +
  # facet_wrap(~Jday) + 
  ggtitle("OKSR, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/oksr_df.csv")
write_csv(oksr.df, path)

```


#### Posey Creek, Warren, VA 
nitrate sensor lat-long: 38.895193	-78.147862	
elevation (m): 271.86

```{r - POSE}

##### Create object for POSE => Posey Creek, Warren, VA 

pose.df <- selectRdata(data=no3_data_sensor, site="POSE", tz="US/Eastern", span=2021:2024)


# pose.df <- no3_data_sensor %>%
#   filter(siteID == "POSE") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean POSE data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
pose.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,50) +
  # facet_wrap(~Jday) + 
  ggtitle("POSE, 2023") +
  theme_bw()

##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/pose_df.csv")
write_csv(pose.df, path)

```

#### Pringle Creek, Wise County, TX
nitrate sensor lat-long: 33.37836	-97.78134	
elevation (m): 251.34

```{r - REDB}

##### Create object for PRIN ==> Pringle Creek, Wise, TX

prin.df <- selectRdata(data=no3_data_sensor, site="PRIN", tz="US/Central", span=2021:2024) ## check tz!!!



##### Visualize, select and clean PRIN data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
redb.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
   # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("PRIN, 2023") +
  theme_bw()


##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/prin_df.csv")
write_csv(prin.df, path)

```


#### Red Butte Creek, Salt Lake, UT
nitrate sensor lat-long: 40.78366	-111.79811	
elevation (m): 1689.47

```{r - REDB}

##### Create object for REDB => Red Butte Creek, Salt Lake, UT

redb.df <- selectRdata(data=no3_data_sensor, site="REDB", tz="US/Mountain", span=2021:2024)


# redb.df <- no3_data_sensor %>%
#   filter(siteID == "REDB") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)

##### Visualize, select and clean REDB data

yr <- 2024
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
redb.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
   # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("REDB, 2023") +
  theme_bw()


##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/redb_df.csv")
write_csv(redb.df, path)

```

#### Sycamore Creek, Maricopa, AZ
nitrate sensor lat-long: 33.751675	-111.508603	
elevation (m): 643

```{r - SYCA}

##### Create object for SYCA => Sycamore Creek, Maricopa, AZ

syca.df <- selectRdata(data=no3_data_sensor, site="SYCA", tz="US/Arizona", span=2021:2024)


# syca.df <- no3_data_sensor %>%
#   filter(siteID == "SYCA") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Arizona"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean SYCA data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
syca.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
   # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(0,10) +
  # facet_wrap(~Jday) + 
  ggtitle("SYCA, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/syca_df.csv")
write_csv(syca.df, path)

```

#### Teakettle Creek - Watershed 2, Fresno, CA
nitrate sensor lat-long: 36.955228	-119.023553	
elevation (m): 2002.75

```{r - TECR}

##### Create object for TECR => Teakettle Creek - Watershed 2, Fresno, CA

tecr.df <- selectRdata(data=no3_data_sensor, site="TECR", tz="US/Pacific", span=2021:2024)


# tecr.df <- no3_data_sensor %>%
#   filter(siteID == "TECR") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Pacific"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean TECR data

yr <- 2021
# mo <- 5:6

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
tecr.df %>%
 filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) +
  ggtitle("TECR, 2021") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/tecr_df.csv")
write_csv(tecr.df, path)

```

[Did NOT model Lower Tombigbee River [TOMB], Choctaw, AL]

#### Walker Branch, TN
nitrate sensor lat-long: 35.957219	-84.279206	
elevation (m): 261.76

```{r - WALK}

##### Create object for WALK  => Walker Branch, TN

walk.df <- selectRdata(data=no3_data_sensor, site="WALK", tz="US/Eastern", span=2021:2024) ## in Knox Co. = Eastern Time

# walk.df <- no3_data_sensor %>%
#   filter(siteID == "WALK") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%  ## in Knox Co. = Eastern Time
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean WALK data

yr <- 2023
mo <- 5:6

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
walk.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  #ylim(0,6) +
  facet_wrap(~Jday) +
  ggtitle("WALK, May-Jun 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/walk_df.csv")
write_csv(walk.df, path)

```

#### West St Louis Creek, Grand, CO
nitrate sensor lat-long: 39.890673	-105.911297	
elevation (m): 2900.74

###### Load data

```{r - WLOU}
#| output: false
#| message: false

##### Create object for WLOU => West St Louis Creek, Grand, CO

wlou.df <- selectRdata(data=no3_data_sensor, site="WLOU", tz="US/Mountain", span=2021:2023)

wlou_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/WLOU_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))

#tz(wlou_light.df$local_datetime) <- "US/Mountain"

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(wlou_light.df$local_datetime)
tz(wlou.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

# The function does this now: 
# wlou.df <- no3_data_sensor %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#         Jday = yday(local_datetime)) %>%
#   filter(siteID == "WLOU", 
#          year(local_datetime) %in% 2021:2023) 
#   
```

###### Visualize, select and clean WLOU data
```{r - WLOU visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
# mo <- 7:12

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
wlou.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(6,7) +
  # facet_wrap(~Jday) + 
  ggtitle("WLOU, 2024") +
  theme_bw(local_datetime, s)


wlou_dy <- wlou.df %>%
  select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=wlou_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     WLOU: summer is both more disturbed and appears to have low autotrophic uptake (Deciduous shading? Cottonwoods?)

# Jdays: 
##    2021 - 32, 34:37, 40:59, 68:72, 74, (80:90 if only 1h missing), 95:113, 153:160 :164?), 238, 240, 241, 265, 268:270, 276:278, 285, 287:294, 299:307, 309:311, 313:321; 340:344  

##    2022 - 43, 53:56, 87:107, 116:123, 171, 173, 178, 179, 182:185, 202, 203, 207, 221:224, 235:240, 242, 244:255 (Xed 249 for missingness), 267:273, 279:283, 305:310, 316:318, 340, 343, 360, 363, 364

# 2024 looks like it has a great string of days ~ Feb-April

# Removed days in 2021 and 22 for either too few or too many measurements/day: these could not be interpolated /filled/ deleted due to the 45-min data structure that proceeded from the resumed measurement time. Noticed this when looking at the Jday count, below. Excising them seemed like the simplest solution. 
# Removed 2021-73 (n=30), 2021-311 (n=34), and 2022-310 (n=33)

# PAD for model day stuff - add a day on each end of a string of consecutive days. Original selections retained in 'orig.list's

list.21 <- c(32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 68, 69, 70, 71, 74, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 238, 240, 241, 265, 268, 269, 270, 276, 277, 278, 285, 287, 288, 289, 290, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 340, 341, 342, 343, 344)

# padded.list.21 <- c(31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 67, 68, 69, 70, 71, 72, 73, 74, 75, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 237, 238, 239, 240, 241, 242, 264, 265, 266, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 339, 340, 341, 342, 343, 344)

list.22 <- c(43, 53, 54, 55, 56, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 116, 117, 118, 119, 120, 121, 122, 123, 171, 173, 178, 179, 182, 183, 184, 185, 202, 203, 207, 221, 222, 223, 224, 235, 236, 237, 238, 239, 240, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 267, 268, 269, 270, 271, 272, 273, 279, 280, 281, 282, 283, 305, 306, 307, 308, 310, 316, 317, 318, 340, 343, 360, 363, 364)

# padded.list.22 <- c(42, 43, 44, 52, 53, 54, 55, 56, 57, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 170, 171, 172, 173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 201, 202, 203, 204, 206, 207, 208, 220, 221, 222, 223, 224, 225, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 266, 267, 268, 269, 270, 271, 272, 273, 274, 278, 279, 280, 281, 282, 283, 283, 304, 305, 306, 307, 308, 309, 310, 215, 316, 317, 318, 319, 339, 340, 341, 342, 343, 344, 359, 360, 361, 363, 363, 364)

wlou.df.21 <- wlou.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
wlou.df.22 <- wlou.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

wlou.df.21 %>% count(model_jday) #106: after removing Jday73 (n=30 w. 45-min data) and Jday311 (n=34)  
# model_jday => #72 and 73 have 92 meas and # 310 has 100 (time change?)
wlou.df.22 %>% count(model_jday) #92: after removing Jday310 (n=33 w. 45-min data)
# model_jday => rm 309, which has 100 meas  

# wlou22_310 <- wlou.df.22 %>% filter(model_jday == 310)
# wlou21_310 <- wlou.df.22 %>% filter(model_jday == 310)
# View(wlou73)
# View(wlou310)
# 
# wlou310 <- wlou.df.22 %>% filter(Jday == 310)
# View(wlou310)


##### Combine selected days into 1 df 
wlou.df.2122 <- bind_rows(wlou.df.21, wlou.df.22) %>%
  mutate(Year = year(local_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days - CLUNKY
#unique(wlou.df.2122$yr_jday) #198


##### Combine df with sat_light data for the selected model days
wlou.wlight.df.2122 <- left_join(x=wlou.df.2122,
                                 y=wlou_light.df, 
                                 by = "local_datetime") 


View(wlou.wlight.df.2122)

# # check the 1st day in the df to make sure light joined correctly 
# jday31 <- wlou_light.df %>% 
#   filter(year(local_datetime) == 2021) %>%
#   filter(month(local_datetime) == 1) %>% 
#   filter(day(local_datetime) == 31)


# save to keep progress
write_csv(wlou.wlight.df.2122,file=here("N_uptake_NEON/data/neon_data_joined/WLOU_wlight_2122_joined.csv"))

```

###### Fill any gaps in no3 data
```{r fill gaps}

##############################  Reload data if needed  #########################
# wlou.wlight.df.2122 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2122_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(wlou.wlight.df.2122$surfWaterNitrateMean))
no3NA
# 32 occurrences: 3145  3241  3259  3337  3433  3529  3625  3721  3817  3913  4009  4105  4201 4297  4300  4393  4489  4585  4681  4777  4873  5425  5426  6029 14359 14360 16476 17035 17036 17037 17038 18856

# 33 occurrences, using model days: [1]  2966  3033  3129  3147  3225  3321  3417  3513  3609  3705  3801  3897  3993  4089  4185  4188  4281 4377  4473  4569  4665  4761  5313  5314  5917 14247 14248 16364 16923 16924 16925 16926 18744

# When do these occur? (ID any particularly bad days to remove)
NAdays <- wlou.wlight.df.2122 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays # 2021: 74, 95, 96, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 158, 158, 164, ## 2022: 202, 202, 253, 270, 270, 270, 270, 360

# 270 is missing 1 hour of data, that's fine for a gap fill. 

lightNA <- which(is.na(wlou.wlight.df.2122$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 16900:16930
plot(wlou.wlight.df.2122$local_datetime[span], wlou.wlight.df.2122$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
wlou.wlight.df.2122$surfWaterNitrateMean <- na.approx(wlou.wlight.df.2122$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(wlou.wlight.df.2122$surfWaterNitrateMean)) 

# no NAs remain

N_e <- mean(wlou.wlight.df.2122$surfWaterNitrateMean, na.rm = TRUE)  #3.028714
N_sd <- sd(wlou.wlight.df.2122$surfWaterNitrateMean, na.rm = TRUE)   #1.337295

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
wlou.wlight.df.h <- wlou.wlight.df.2122 %>%
  filter(minute(local_datetime) == 0) 
# Mean of selected dataset
N_e <- mean(wlou.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #3.028401
N_sd <- sd(wlou.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #1.33781



```
###### Visualize cleaned data

```{r - visualize WLOU clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(wlou.wlight.df.h$model_jday)



```



###### Save cleaned site df
```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/wlou_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/wlou_hourly_clean.csv")
write_csv(wlou.wlight.df.2122, path)
write_csv(wlou.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# wlou.wlight.df.2122 <- read_csv(path)
# wlou.wlight.df.h <- read_csv(path_h)

```


### OLD CODE
Skim from the stuff below, then delete


##### WALK -------------------------------------------

##### filter data by selected year(s)
walk.df.2021 <- walk.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

walk.df.2022 <- walk.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

walk.df.2023 <- walk.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/walk.df_2021.csv")
write_csv(walk.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/walk.df_2022.csv")
write_csv(walk.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/walk.df_2023.csv")
write_csv(walk.df.2023, path)



##### HOPB -------------------------------------------

##### filter data by selected year(s)
hopb.df.2021 <- hopb.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

hopb.df.2022 <- hopb.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

hopb.df.2023 <- hopb.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/hopb.df_2021.csv")
write_csv(hopb.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/hopb.df_2022.csv")
write_csv(hopb.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/hopb.df_2023.csv")
write_csv(hopb.df.2023, path)



##### POSE -------------------------------------------

##### filter data by selected year(s)
pose.df.2021 <- pose.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

pose.df.2022 <- pose.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

pose.df.2023 <- pose.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/pose.df_2021.csv")
write_csv(pose.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/pose.df_2022.csv")
write_csv(pose.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/pose.df_2023.csv")
write_csv(pose.df.2023, path)


##### FLNT -------------------------------------------

##### filter data by selected year(s)
flnt.df.2021 <- flnt.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

flnt.df.2022 <- flnt.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

flnt.df.2023 <- flnt.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/flnt.df_2021.csv")
write_csv(flnt.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/flnt.df_2022.csv")
write_csv(flnt.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/flnt.df_2023.csv")
write_csv(flnt.df.2023, path)


##### CUPE -------------------------------------------

##### filter data by selected year(s)
cupe.df.2021 <- cupe.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

cupe.df.2022 <- cupe.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

cupe.df.2023 <- cupe.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/cupe.df_2021.csv")
write_csv(cupe.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/cupe.df_2022.csv")
write_csv(cupe.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/cupe.df_2023.csv")
write_csv(cupe.df.2023, path)


##### GUIL -------------------------------------------

##### filter data by selected year(s)
guil.df.2021 <- guil.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

guil.df.2022 <- guil.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

guil.df.2023 <- guil.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/guil.df_2021.csv")
write_csv(guil.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/guil.df_2022.csv")
write_csv(guil.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/guil.df_2023.csv")
write_csv(guil.df.2023, path)


##### LECO -------------------------------------------

##### filter data by selected year(s)
leco.df.2021 <- leco.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

leco.df.2022 <- leco.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

leco.df.2023 <- leco.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/leco.df_2021.csv")
write_csv(leco.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/leco.df_2022.csv")
write_csv(leco.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/leco.df_2023.csv")
write_csv(leco.df.2023, path)


##### BLWA -------------------------------------------

##### filter data by selected year(s)
blwa.df.2021 <- blwa.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

blwa.df.2022 <- blwa.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

blwa.df.2023 <- blwa.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/blwa.df_2021.csv")
write_csv(blwa.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/blwa.df_2022.csv")
write_csv(blwa.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/blwa.df_2023.csv")
write_csv(blwa.df.2023, path)


##### ARIK -------------------------------------------

##### filter data by selected year(s)
arik.df.2021 <- arik.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

arik.df.2022 <- arik.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

arik.df.2023 <- arik.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/arik.df_2021.csv")
write_csv(arik.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/arik.df_2022.csv")
write_csv(arik.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/arik.df_2023.csv")
write_csv(arik.df.2023, path)


##### BLUE -------------------------------------------

##### filter data by selected year(s)
blue.df.2021 <- blue.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

blue.df.2022 <- blue.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

blue.df.2023 <- blue.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/blue.df_2021.csv")
write_csv(blue.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/blue.df_2022.csv")
write_csv(blue.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/blue.df_2023.csv")
write_csv(blue.df.2023, path)


##### BLDE -------------------------------------------

##### filter data by selected year(s)
blde.df.2021 <- blde.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

blde.df.2022 <- blde.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

blde.df.2023 <- blde.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/blde.df_2021.csv")
write_csv(blde.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/blde.df_2022.csv")
write_csv(blde.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/blde.df_2023.csv")
write_csv(blde.df.2023, path)


##### COMO -------------------------------------------

##### filter data by selected year(s)
como.df.2021 <- como.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

como.df.2022 <- como.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

como.df.2023 <- como.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/como.df_2021.csv")
write_csv(como.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/como.df_2022.csv")
write_csv(como.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/como.df_2023.csv")
write_csv(como.df.2023, path)


##### WLOU -------------------------------------------

##### filter data by selected year(s)
wlou.df.2021 <- wlou.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

wlou.df.2022 <- wlou.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

wlou.df.2023 <- wlou.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/wlou.df_2021.csv")
write_csv(wlou.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/wlou.df_2022.csv")
write_csv(wlou.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/wlou.df_2023.csv")
write_csv(wlou.df.2023, path)


##### SYCA -------------------------------------------

##### filter data by selected year(s)
syca.df.2021 <- syca.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

syca.df.2022 <- syca.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

syca.df.2023 <- syca.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/syca.df_2021.csv")
write_csv(syca.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/syca.df_2022.csv")
write_csv(syca.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/syca.df_2023.csv")
write_csv(syca.df.2023, path)


##### REDB -------------------------------------------

##### filter data by selected year(s)
redb.df.2021 <- redb.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

redb.df.2022 <- redb.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

redb.df.2023 <- redb.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/redb.df_2021.csv")
write_csv(redb.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/redb.df_2022.csv")
write_csv(redb.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/redb.df_2023.csv")
write_csv(redb.df.2023, path)


##### MART -------------------------------------------

##### filter data by selected year(s)
mart.df.2021 <- mart.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

mart.df.2022 <- mart.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

mart.df.2023 <- mart.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/mart.df_2021.csv")
write_csv(mart.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/mart.df_2022.csv")
write_csv(mart.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/mart.df_2023.csv")
write_csv(mart.df.2023, path)


##### TECR -------------------------------------------

##### filter data by selected year(s)
tecr.df.2021 <- tecr.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

tecr.df.2022 <- tecr.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

tecr.df.2023 <- tecr.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/tecr.df_2021.csv")
write_csv(tecr.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/tecr.df_2022.csv")
write_csv(tecr.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/tecr.df_2023.csv")
write_csv(tecr.df.2023, path)


##### OKSR -------------------------------------------

##### filter data by selected year(s)
oksr.df.2021 <- oksr.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

oksr.df.2022 <- oksr.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

oksr.df.2023 <- oksr.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/oksr.df_2021.csv")
write_csv(oksr.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/oksr.df_2022.csv")
write_csv(oksr.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/oksr.df_2023.csv")
write_csv(oksr.df.2023, path)

```

#### Plot selected data by site and year
```{r - plot selected data by site and year}

##### data site and year plots for SI

# When I'm ready to shade my study reach, insert this code into the graph(s):
# geom_rect(xmin = as.Date("2019-01-01"), xmax = as.Date("2019-03-15"), ymin = -Inf, ymax = Inf, fill = "gray", alpha = 0.3) +

# the geom_rect line adds a shaded rectangle to the specified portions of my graph. This is the code ChatGPT provided, I could probably use $local_datetime

### CHANGE UMOL to mu-mol
  
bigc.plot.2021 <- bigc.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Big Creek CA nitrate: 2021") +
  theme_bw()

bigc.plot.2022 <- bigc.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Big Creek nitrate: 2022") +
  theme_bw()

bigc.plot.2023 <- bigc.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Big Creek nitrate: 2023") +
  theme_bw()


  
cari.plot.2021 <- cari.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Caribou Creek AK nitrate: 2021") +
  theme_bw()
  
cari.plot.2022 <- cari.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Caribou Creek AK nitrate: 2022") +
  theme_bw()

cari.plot.2023 <- cari.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Caribou Creek AK nitrate: 2023") +
  theme_bw()


king.plot.2021 <- king.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "King's Creek KS nitrate: 2021") +
  theme_bw()

king.plot.2022 <- king.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "King's Creek KS nitrate: 2022") +
  theme_bw()

king.plot.2023 <- king.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "King's Creek KS nitrate: 2023") +
  theme_bw()



walk.plot.2021 <- walk.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

walk.plot.2022 <- walk.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

walk.plot.2023 <- walk.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()

# Current one: "HOPB" "POSE" "FLNT" "CUPE" "GUIL" "LECO" "BLWA" "ARIK" "BLUE" "BLDE" "COMO" "WLOU" "SYCA" "REDB" "MART" "TECR" "OKSR"


hopb.plot.2021 <- hopb.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

hopb.plot.2022 <- hopb.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

hopb.plot.2023 <- hopb.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


pose.plot.2021 <- pose.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

pose.plot.2022 <- pose.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

pose.plot.2023 <- pose.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


flnt.plot.2021 <- flnt.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

flnt.plot.2022 <- flnt.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

flnt.plot.2023 <- flnt.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


cupe.plot.2021 <- cupe.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

cupe.plot.2022 <- cupe.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

cupe.plot.2023 <- cupe.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


guil.plot.2021 <- guil.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

guil.plot.2022 <- guil.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

guil.plot.2023 <- guil.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


leco.plot.2021 <- leco.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

leco.plot.2022 <- leco.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

leco.plot.2023 <- leco.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


blwa.plot.2021 <- blwa.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

blwa.plot.2022 <- blwa.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

blwa.plot.2023 <- blwa.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


arik.plot.2021 <- arik.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

arik.plot.2022 <- arik.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

arik.plot.2023 <- arik.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()



blue.plot.2021 <- blue.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

blue.plot.2022 <- blue.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

blue.plot.2023 <- blue.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


blde.plot.2021 <- blde.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

blde.plot.2022 <- blde.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

blde.plot.2023 <- blde.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


como.plot.2021 <- como.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

como.plot.2022 <- como.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

como.plot.2023 <- como.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


wlou.plot.2021 <- wlou.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

wlou.plot.2022 <- wlou.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

wlou.plot.2023 <- wlou.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


syca.plot.2021 <- syca.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

syca.plot.2022 <- syca.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

syca.plot.2023 <- syca.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


redb.plot.2021 <- redb.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

redb.plot.2022 <- redb.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

redb.plot.2023 <- redb.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()



mart.plot.2021 <- mart.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

mart.plot.2022 <- mart.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

mart.plot.2023 <- mart.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()



tecr.plot.2021 <- tecr.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

tecr.plot.2022 <- tecr.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

tecr.plot.2023 <- tecr.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()


oksr.plot.2021 <- oksr.df.2021 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2021") +
  theme_bw()

oksr.plot.2022 <- oksr.df.2022 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2022") +
  theme_bw()

oksr.plot.2023 <- oksr.df.2023 %>%
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) + 
  geom_point() + 
  labs(x="Date", y=expression("NO"[3]~"(umol/L)"), title= "Walker Creek TN nitrate: 2023") +
  theme_bw()




# Plot all the selected site years 

bigc.plot.2021 # Jday 74-227, missing 183:184, also 135-147 (precip event)
bigc.plot.2022
bigc.plot.2023
cari.plot.2021
cari.plot.2022
cari.plot.2023
king.plot.2021
king.plot.2022
king.plot.2023
walk.plot.2021
walk.plot.2022
walk.plot.2023
hopb.plot.2021
hopb.plot.2022
hopb.plot.2023
pose.plot.2021
pose.plot.2022
pose.plot.2023
flnt.plot.2021
flnt.plot.2022
flnt.plot.2023
cupe.plot.2021
cupe.plot.2022
cupe.plot.2023
guil.plot.2021
guil.plot.2022
guil.plot.2023
leco.plot.2021
leco.plot.2022
leco.plot.2023
blwa.plot.2021
blwa.plot.2022
blwa.plot.2023
arik.plot.2021
arik.plot.2022
arik.plot.2023
blue.plot.2021
blue.plot.2022
blue.plot.2023
blde.plot.2021
blde.plot.2022
blde.plot.2023
como.plot.2021
como.plot.2022
como.plot.2023
wlou.plot.2021
wlou.plot.2022
wlou.plot.2023
syca.plot.2021
syca.plot.2022
syca.plot.2023
redb.plot.2021
redb.plot.2022
redb.plot.2023
mart.plot.2021
mart.plot.2022
mart.plot.2023
tecr.plot.2021
tecr.plot.2022
tecr.plot.2023
walk.plot.2021
walk.plot.2022
walk.plot.2023

# Current one: "HOPB" "POSE" "FLNT" "CUPE" "GUIL" "LECO" "BLWA" "ARIK" "BLUE" "BLDE" "COMO" "WLOU" "SYCA" "REDB" "MART" "TECR" "OKSR"
```

**NEON site coordinates:**

Big Creek, CA: 1128.13m (at DS sensor) site = 37.05972, -119.25755 DS sensor site = 37.05767, -119.25538 US sensor site = 37.05871, -119.25650

Caribou Creek, AK: 225.45m (at DS sensor) site = 65.15322, -147.50397 DS sensor site = 65.15307, -147.50195 US sensor site = 65.15254, -147.50786

King's Creek, KS: 525.24m (at sensor) site = 39.10506, -96.60383 sensor site = 39.10460, -96.60264 (the other sensors appear to be terrestrial? This site is by the discharge station)

Walker Branch, TN: 262.49m (at sensor) site = 35.95738, -84.27925 sensor site = 35.95722, -84.27921

### Select and clean data, fill gaps etc.

#### Big Creek, CA 2019

```{r - select, clean, and fill data: BIGC19}

#######################################################################
############################ Filter data  #############################

# filter to ~ 100 days w/o NAs

bigc.df.19 <- bigc.df.2019 %>%
  filter(local_datetime >= ymd_hms('20190315 040000', tz='US/Pacific') &
           local_datetime <= ymd_hms('20190814 040000', tz='US/Pacific')) 

# Visualize selection
bigc.df.19 %>%
  ggplot(aes(x=local_datetime, y = surfWaterNitrateMean)) + 
  geom_point() + 
  theme_bw()


## Select hourly no3 measurements to match what we've done  => CHANGE THIS LATER
bigc.df.19h <- bigc.df.19 %>%
  filter(minute(local_datetime) == 0) %>%
  mutate(N_mean_mgm3 = surfWaterNitrateMean * 14.0067) # new col w. N units = mg m^-3

# Visualize hourly data
plot(bigc.df.19h$local_datetime, bigc.df.19h$N_mean_mgm3, type = 'l')  # used 'l' for better visualization of diel patterns

# Mean of selected dataset
N_b <- mean(bigc.df.19h$surfWaterNitrateMean, na.rm = TRUE) # background N: here, = 3.71 uM or 51.94 mg/L 

###########################################################################
###################    Deal with  NAs   #############################


# Where are the NAs?
which(is.na(bigc.df.19h$surfWaterNitrateMean)) 


##############################   SMALL GAPS

# For smaller NA chunks, (6 or fewer hours?) e.g. 659-661 , we will interpolate using zoo()

#    first see where in the curve this gap falls: (now 611:613)
span <- 605:620
plot(bigc.df.19h$local_datetime[span], bigc.df.19h$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill - currently filling both uM and mg_L, can delete later


maxgap <- 6  # set the maximum gap for zoo() to fill
bigc.df.19h$N_mean_mgm3 <- na.approx(bigc.df.19h$N_mean_mgm3, maxgap = maxgap)  # maxgap = max # of NAs to fill
bigc.df.19h$surfWaterNitrateMean <- na.approx(bigc.df.19h$surfWaterNitrateMean, maxgap = maxgap)


# re-check NAs
which(is.na(bigc.df.19h$surfWaterNitrateMean)) 

##############################   LARGE GAPS

# For large NA chunks (eg 273-300), we will remove the entire day.

# Our model day starts at 4a, so need to create additional columns to easily excise days w NAs

bigc.df.19h <- bigc.df.19h %>%
  mutate(model_datetime = local_datetime - hours(4), 
         model_day = yday(model_datetime))

##### CHECK NA DAYS

gap.start <- 2625
gap.end <- 2652

bigc.df.19h$model_day[gap.start] #183
bigc.df.19h$model_day[gap.end] #184
# For BIGC, we need to remove model_days 183 and 184

# remove model days with big gaps AND with precip events
daylist <- c(135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 183, 184)
bigc.df.19h <- bigc.df.19h[!(bigc.df.19h$model_day %in% daylist),]

# re-check NAs
which(is.na(bigc.df.19h$surfWaterNitrateMean)) # None left!


#################################  SAVE TO CSV #################################

# Where does our data start and end? Use Jdays?
min(bigc.df.19h$Jday) # 74
max(bigc.df.19h$Jday) # 227  (only 4 hrs on Jday 227)

## The df is ready for the pooled-L NEON data model: save as a csv so these steps don't need to be repeated.
filepath <- here("N_uptake_NEON/data/neon_data_clean/bigc_2019_74_226.csv")
write_csv(bigc.df.19h, filepath)

```

#### Big Creek, CA 2021

```{r - select, clean, and fill data: BIGC2021}

# NOT DONE!!!

#######################################################################
############################ Filter data  #############################

# filter to ~ 100 days w/o NAs

bigc.df.21 <- bigc.df.2021 %>%
  filter(local_datetime >= ymd_hms('20210301 040000', tz='US/Pacific') &
           local_datetime <= ymd_hms('20211008 040000', tz='US/Pacific')) 

# Visualize selection
bigc.df.21 %>%
  ggplot(aes(x=local_datetime, y = surfWaterNitrateMean)) + 
  geom_point() + 
  theme_bw()


## Select hourly no3 measurements to match what we've done  => CHANGE THIS LATER
bigc.df.21h <- bigc.df.21 %>%
  filter(minute(local_datetime) == 0) %>%
  mutate(N_mean_mgm3 = surfWaterNitrateMean * 14.0067) # new col w. N units = mg m^-3

# Visualize hourly data
plot(bigc.df.21h$local_datetime, bigc.df.21h$surfWaterNitrateMean, type = 'l')  # used 'l' for better visualization of diel patterns

# Mean of selected dataset
N_b <- mean(bigc.df.21h$surfWaterNitrateMean, na.rm = TRUE) # background N: here, = 3.71 uM or 2.01 umol/L

###########################################################################
###################    Deal with  NAs   #############################


# Where are the NAs?
which(is.na(bigc.df.21h$surfWaterNitrateMean)) 


##############################   SMALL GAPS

# For smaller NA chunks, (6 or fewer hours?) e.g. 659-661 , we will interpolate using zoo()

#    first see where in the curve this gap falls: (now 55:60, 389, 1374:1380)
span <- 1370:1385
plot(bigc.df.21h$local_datetime[span], bigc.df.21h$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill - currently filling both uM and mg_L, can delete later


maxgap <- 7  # set the maximum gap for zoo() to fill (7 = 7h)
bigc.df.21h$N_mean_mgm3 <- na.approx(bigc.df.21h$N_mean_mgm3, maxgap = maxgap)  # maxgap = max # of NAs to fill
bigc.df.21h$surfWaterNitrateMean <- na.approx(bigc.df.21h$surfWaterNitrateMean, maxgap = maxgap)


# re-check NAs
which(is.na(bigc.df.21h$surfWaterNitrateMean)) 

##############################   LARGE GAPS

# For large NA chunks (eg 273-300), we will remove the entire day.

# Our model day starts at 4a, so need to create additional columns to easily excise days w NAs

bigc.df.21h <- bigc.df.21h %>%
  mutate(model_datetime = local_datetime - hours(4), 
         model_day = yday(model_datetime))

##### CHECK NA DAYS

## Gaps: 894-1012; 2046-2093; 3046-3078; 3085-3155; 3177-3249; 3918-3940; 4254-4379
##       97-102       145-147     =>         =>      186-195     223-224   237-242    

gap.start <- 5765
gap.end <- 7081
 
bigc.df.21h$model_day[gap.start] #183
bigc.df.21h$model_day[gap.end] #184
# For BIGC, we need to remove model_days 183 and 184

# remove model days with big gaps

daylist <- c(97, 98, 99, 100, 101, 102, 145, 146, 147, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 223, 224, 237, 238, 239, 240, 241, 242)

bigc.df.21h <- bigc.df.21h[!(bigc.df.21h$model_day %in% daylist),]

# re-check NAs
which(is.na(bigc.df.21h$surfWaterNitrateMean)) # None left!


#################################  SAVE TO CSV #################################

# Where does our data start and end? Use Jdays?
min(bigc.df.21h$Jday) # 60
max(bigc.df.21h$Jday) # 281  (only 4 hrs on final Jday bc of 4h model offset)

## The df is ready for the pooled-L NEON data model: save as a csv so these steps don't need to be repeated.
filepath <- here("N_uptake_NEON/data/neon_data_clean/bigc_2021_60_281.csv") #MODIFY!!!
write_csv(bigc.df.21h, filepath)

```

#### Caribou Creek, AK 2019

```{r - select, clean, and fill data: CARI2019}


#######################################################################
############################ Filter data  #############################

# filter to ~ 100 days w/o NAs

cari.df.19 <- cari.df.2019 %>%
  filter(local_datetime >= ymd_hms('20190507 040000', tz='US/Alaska') &
           local_datetime <= ymd_hms('20190925 040000', tz='US/Alaska')) 

# Visualize selection
cari.df.19 %>%
  ggplot(aes(x=local_datetime, y = surfWaterNitrateMean)) + 
  geom_point() + 
  theme_bw()


## Select hourly no3 measurements to match what we've done  => CHANGE THIS LATER
cari.df.19h <- cari.df.19 %>%
  filter(minute(local_datetime) == 0) %>%
  mutate(N_mean_mgm3 = surfWaterNitrateMean * 14.0067) # new col w. N units = mg m^-3

# Visualize hourly data
plot(cari.df.19h$local_datetime, cari.df.19h$surfWaterNitrateMean, type = 'l')  # used 'l' for better visualization of diel patterns
plot(cari.df.19h$local_datetime, cari.df.19h$surfWaterNitrateMean)


## look at outlier point
which(cari.df.19h$surfWaterNitrateMean > 50)  # 2374: CARI local_datetime = 2019-08-14 01:00:00, Jday = 226

# This is only one datapoint, not a rise and fall, so will treat as an error... 

# MARK THE SOLO BLIP AS NA
cari.df.19h <- cari.df.19h %>%
  mutate(surfWaterNitrateMean = ifelse(surfWaterNitrateMean > 50, NA, surfWaterNitrateMean))


# Mean of selected dataset
N_b <- mean(cari.df.19h$surfWaterNitrateMean, na.rm = TRUE) # background N: here, = 3.71 uM or 27.40 umol/L

###########################################################################
###################    Deal with  NAs   #############################


# Where are the NAs? 
which(is.na(cari.df.19h$surfWaterNitrateMean)) 

# several short and long runs of NAs


##############################   SMALL GAPS

# For smaller NA chunks, (6 or fewer hours?) e.g. 659-661 , we will interpolate using zoo()

#    first see where in the curve this gap falls: (now 55:60, 389, 1374:1380)
span <- 1370:1385
plot(cari.df.19h$local_datetime[span], cari.df.19h$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill - currently filling both uM and mg_L, can delete later


maxgap <- 7  # set the maximum gap for zoo() to fill (7 = 7h)
cari.df.19h$N_mean_mgm3 <- na.approx(cari.df.19h$N_mean_mgm3, maxgap = maxgap)  # maxgap = max # of NAs to fill
cari.df.19h$surfWaterNitrateMean <- na.approx(cari.df.19h$surfWaterNitrateMean, maxgap = maxgap)


# re-check NAs
which(is.na(cari.df.19h$surfWaterNitrateMean)) 

##############################   LARGE GAPS  ##############################

# For large NA chunks (> 7 points), we will remove the entire day.

# Our model day starts at 4a, so need to create additional columns to easily excise days w NAs

cari.df.19h <- cari.df.19h %>%
  mutate(model_datetime = local_datetime - hours(4), 
         model_day = yday(model_datetime))


############ Check NA days
# 279-286; 1904-1996; 3057-3076


gap.start <- 3057
gap.end <- 3076

 
cari.df.19h$model_day[gap.start]
cari.df.19h$model_day[gap.end]

daylist <- c(138, 206, 207, 208, 209, 210, 254, 255)

cari.df.19h <- cari.df.19h[!(cari.df.19h$model_day %in% daylist),]

# re-check NAs
which(is.na(cari.df.19h$surfWaterNitrateMean)) 

#################################  SAVE TO CSV #################################

# Where does our data start and end? Use Jdays?
min(cari.df.19h$model_day) # 127
max(cari.df.19h$model_day) # 267  (only 4 hrs on final Jday bc of 4h model offset)

## The df is ready for the pooled-L NEON data model: save as a csv so these steps don't need to be repeated.
filepath <- here("N_uptake_NEON/data/neon_data_clean/cari_2019_127_267.csv") #MODIFY!!!
write_csv(cari.df.19h, filepath)


```

#### Caribou Creek, AK 2020

```{r - select, clean, and fill data: CARI2020}


#######################################################################
############################ Filter data  #############################

# filter to ~ 100 days w/o NAs

cari.df.20 <- cari.df.2020 %>%
  filter(local_datetime >= ymd_hms('20200618 040000', tz='US/Alaska') &
           local_datetime <= ymd_hms('20200909 040000', tz='US/Alaska')) 

# Visualize selection
cari.df.20 %>%
  ggplot(aes(x=local_datetime, y = surfWaterNitrateMean)) + 
  geom_point() + 
  theme_bw()


## Select hourly no3 measurements to match what we've done  => CHANGE THIS LATER
cari.df.20h <- cari.df.20 %>%
  filter(minute(local_datetime) == 0) %>%
  mutate(N_mean_mgm3 = surfWaterNitrateMean * 14.0067) # new col w. N units = mg m^-3

# Visualize hourly data
plot(cari.df.20h$local_datetime, cari.df.20h$surfWaterNitrateMean, type = 'l')  # used 'l' for better visualization of diel patterns

# Mean of selected dataset
N_b <- mean(cari.df.20h$surfWaterNitrateMean, na.rm = TRUE) # background N: here, = 3.71 uM or 26.87 umol/L

###########################################################################
###################    Deal with  NAs   #############################


# Where are the NAs?
which(is.na(cari.df.20h$surfWaterNitrateMean)) 


##############################   SMALL GAPS

# For smaller NA chunks, (6 or fewer hours?) e.g. 659-661 , we will interpolate using zoo()

#    first see where in the curve this gap falls: (now 55:60, 389, 1374:1380)
span <- 1370:1385
plot(cari.df.20h$local_datetime[span], cari.df.20h$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill - currently filling both uM and mg_L, can delete later


maxgap <- 7  # set the maximum gap for zoo() to fill (7 = 7h)
cari.df.20h$N_mean_mgm3 <- na.approx(cari.df.20h$N_mean_mgm3, maxgap = maxgap)  # maxgap = max # of NAs to fill
cari.df.20h$surfWaterNitrateMean <- na.approx(cari.df.20h$surfWaterNitrateMean, maxgap = maxgap)


# re-check NAs
which(is.na(cari.df.20h$surfWaterNitrateMean)) # None left!

##############################   LARGE GAPS  ##############################

# For large NA chunks (eg 273-300), we will remove the entire day.

# Our model day starts at 4a, so need to create additional columns to easily excise days w NAs

cari.df.20h <- cari.df.20h %>%
  mutate(model_datetime = local_datetime - hours(4), 
         model_day = yday(model_datetime))


############ Check NA days

gap.start <- 1
gap.end <- 36

## For this year, I just re-ran the earlier code to begin the ts after this gap (on 6/18/2020 at 0400); This avoided missing days
 
# cari.df.20h$model_day[gap.start] 
# cari.df.20h$model_day[gap.end] 
# 
# cari.df.20h <- cari.df.20h[!(cari.df.20h$model_day %in% c()),]

#################################  SAVE TO CSV #################################

# Where does our data start and end? Use Jdays?
min(cari.df.20h$model_day) # 170
max(cari.df.20h$model_day) # 252  (only 4 hrs on final Jday bc of 4h model offset)

## The df is ready for the pooled-L NEON data model: save as a csv so these steps don't need to be repeated.
filepath <- here("N_uptake_NEON/data/neon_data_clean/cari_2020_170_252.csv") #MODIFY!!!

#~/Documents/R_working/Modelscape/space-time-rivers/N_uptake_NEON/data/neon_data_clean
write_csv(bigc.df.21h, filepath)

```

#### Kings Creek, KS 2019 tz = 'US/Central'

\`\`\`{r - select, clean, and fill data: KING2019}

# Remind yourself what the data look like:

king.plot.2019

####################################################################### 

############################ Filter data

# filter to \~ 100 days w/o NAs

king.df.19 \<- king.df.2019 %\>% filter(local_datetime \>= ymd_hms('20190820 040000', tz='US/Central') & local_datetime \<= ymd_hms('20191231 040000', tz='US/Central'))

# Visualize selection

king.df.19 %\>% ggplot(aes(x=local_datetime, y = surfWaterNitrateMean)) + geom_point() + theme_bw()

# may need to filter to Sept 01....

## Select hourly no3 measurements to match what we've done =\> CHANGE THIS LATER

king.df.19h \<- king.df.19 %\>% filter(minute(local_datetime) == 0) %\>% mutate(N_mean_mgm3 = surfWaterNitrateMean \* 14.0067) \# new col w. N units = mg m\^-3

# Visualize hourly data

plot(king.df.19h$local_datetime, king.df.19h$surfWaterNitrateMean) plot(king.df.19h$local_datetime, king.df.19h$surfWaterNitrateMean, type = 'l') \# used 'l' for better visualization of diel patterns

# Mean of selected dataset

N_b \<- mean(king.df.19h\$surfWaterNitrateMean, na.rm = TRUE) \# background N: here, = 3.71 uM or 3.87 umol/L

########################################################################### 

################### Deal with NAs

# Where are the NAs?

which(is.na(king.df.19h\$surfWaterNitrateMean))

# several small, one large NA chunk

############################## SMALL GAPS

# For smaller NA chunks, (6 or fewer hours?) e.g. 659-661 , we will interpolate using zoo()

# first see where in the curve this gap falls: (now 55:60, 389, 1374:1380)

span \<- 1370:1385 plot(king.df.19h$local_datetime[span], king.df.19h$surfWaterNitrateMean\[span\], type = 'l') #OK, linear seems reasonable

# Then fill - currently filling both uM and mg_L, can delete later

maxgap \<- 7 \# set the maximum gap for zoo() to fill (7 = 7h) king.df.19h$N_mean_mgm3 <- na.approx(king.df.19h$N_mean_mgm3, maxgap = maxgap) \# maxgap = max \# of NAs to fill king.df.19h$surfWaterNitrateMean <- na.approx(king.df.19h$surfWaterNitrateMean, maxgap = maxgap)

# re-check NAs

which(is.na(king.df.19h\$surfWaterNitrateMean))

############################## NO LARGE GAPS

# For large NA chunks (eg 273-300), we will remove the entire day.

# Our model day starts at 4a, so need to create additional columns to easily excise days w NAs

king.df.19h \<- king.df.19h %\>% mutate(model_datetime = local_datetime - hours(4), model_day = yday(model_datetime))

##### CHECK NA DAYS

## Lareg gaps: 1569-1590

gap.start \<- 1569 gap.end \<- 1590

king.df.19h$model_day[gap.start] #297
king.df.19h$model_day\[gap.end\] #298 \# For BIGC, we need to remove model_days 183 and 184

# remove model days with big gaps

daylist \<- c(297,298) king.df.19h \<- king.df.19h\[!(king.df.19h\$model_day %in% daylist),\]

# re-check NAs

which(is.na(king.df.19h\$surfWaterNitrateMean)) \# None left!

################################# SAVE TO CSV

# Where does our data start and end?

min(king.df.19h$model_day) # 232
max(king.df.19h$model_day) \# 365 (CHECK FOR FULL DAYS ON EACH END)

## The df is ready for the pooled-L NEON data model: save as a csv so these steps don't need to be repeated.

filepath \<- here("N_uptake_NEON/data/neon_data_clean/king_2019_232_365.csv") #MODIFY!!! write_csv(king.df.19h, filepath)

```         


#### Not done - Kings Creek, KS 2020  tz = 'US/Central'

```{r - select, clean, and fill data: KING2020}

# Remind yourself what the data look like: 
king.plot.2020

#######################################################################
############################ Filter data  #############################

# filter to ~ 100 days w/o NAs

king.df.20 <- king.df.2020 %>%
  filter(local_datetime >= ymd_hms('20200101 040000', tz='US/Central') &
           local_datetime <= ymd_hms('20201015 040000', tz='US/Central')) 

# Visualize selection
king.df.20 %>%
  ggplot(aes(x=local_datetime, y = surfWaterNitrateMean)) + 
  geom_point() + 
  theme_bw()
.

## Select hourly no3 measurements to match what we've done  => CHANGE THIS LATER
king.df.20h <- king.df.20 %>%
  filter(minute(local_datetime) == 0) %>%
  mutate(N_mean_mgm3 = surfWaterNitrateMean * 14.0067)

  # new col w. N units = mg m^-3

# Visualize hourly data
plot(king.df.20h$local_datetime, king.df.20h$surfWaterNitrateMean) #  , type = 'l')  # used 'l' for better visualization of diel patterns

# ID and remove sub-zero values (errors)
which(king.df.20h$surfWaterNitrateMean < 0)  # 2749


king.df.20h$surfWaterNitrateMean <- replace(king.df.20h$surfWaterNitrateMean, king.df.20h$surfWaterNitrateMean < 0, NA)

king.df.20h$N_mean_mgm3 <- replace(king.df.20h$N_mean_mgm3, king.df.20h$N_mean_mgm3 <0, NA)

# Re-run l851 to check... 


# Mean of selected dataset
N_b <- mean(king.df.20h$surfWaterNitrateMean, na.rm = TRUE) # background N: here, = 3.71 uM or 3.61 umol/L

###########################################################################
###################    Deal with  NAs   #############################


# Where are the NAs? 
which(is.na(king.df.20h$surfWaterNitrateMean)) 

# several small, one large NA chunk

##############################   SMALL GAPS

# For smaller NA chunks, (6 or fewer hours?) e.g. 659-661 , we will interpolate using zoo()

#    first see where in the curve this gap falls: (now 55:60, 389, 1374:1380)
span <- 1370:1385
plot(king.df.19h$local_datetime[span], king.df.19h$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill - currently filling both uM and mg_L, can delete later


maxgap <- 7  # set the maximum gap for zoo() to fill (7 = 7h)
king.df.20h$N_mean_mgm3 <- na.approx(king.df.20h$N_mean_mgm3, maxgap = maxgap)  # maxgap = max # of NAs to fill
king.df.20h$surfWaterNitrateMean <- na.approx(king.df.20h$surfWaterNitrateMean, maxgap = maxgap)


# re-check NAs
which(is.na(king.df.20h$surfWaterNitrateMean)) 

##############################   NO LARGE GAPS

# For large NA chunks (eg 273-300), we will remove the entire day.

# Our model day starts at 4a, so need to create additional columns to easily excise days w NAs

king.df.20h <- king.df.20h %>%
  mutate(model_datetime = local_datetime - hours(4), 
         model_day = yday(model_datetime))

##### CHECK NA DAYS

## Lareg gaps: 1569-1590

gap.start <- 4608
gap.end <- 5243
 
king.df.20h$model_day[gap.start] #297
king.df.20h$model_day[gap.end] #298
# For BIGC, we need to remove model_days 183 and 184

# remove model days with big gaps
daylist <- c(37, 145,146, 147, 148, 149, 150, 151, 152, 153, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219)
king.df.20h <- king.df.20h[!(king.df.20h$model_day %in% daylist),]

# re-check NAs
which(is.na(king.df.20h$surfWaterNitrateMean)) # None left!

#################################  SAVE TO CSV #################################

# Where does our data start and end? Use Jdays?
min(king.df.20h$Jday) # 1
max(king.df.20h$Jday) # 289  (only 4 hrs on final Jday bc of 4h model offset)

## The df is ready for the pooled-L NEON data model: save as a csv so these steps don't need to be repeated.
filepath <- here("N_uptake_NEON/data/neon_data_clean/king_2020_1_289.csv") #MODIFY!!!
write_csv(king.df.20h, filepath)

## May want to end at 192, before the LARGE gap 
```

#### Not done - lecoer Branch, TN 2019 tz = 'US/Eastern'

#### Not done - lecoer Branch, TN 2022 tz = 'US/Eastern'

OLD CODE: 
```{r - old code}
# bigc.df.2019 <- bigc.df %>%
#   filter(year(local_datetime) == 2019) %>%
#   dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)
# 
# #~/Documents/R_working/Modelscape/space-time-rivers/N_uptake_NEON/data/neon_data_by_year
# # save df
# force_tz(bigc.df.2019$local_datetime, tzone="US/Pacific")
# path <- here("N_uptake_NEON/data/neon_data_by_year/bigc.df_2019.csv")
# write_csv(bigc.df.2019, path)

# cari.df.2019 <- cari.df %>%
#   filter(year(local_datetime) == 2019) %>%
#   dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)
# 
# # save df
# path <- here("N_uptake_NEON/data/neon_data_by_year/cari.df_2019.csv")
# write_csv(cari.df.2019, path)
# 
# 
# cari.df.2020 <- cari.df %>%
#   filter(year(local_datetime) == 2020) %>%
#   dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)
# 
# # save df
# path <- here("N_uptake_NEON/data/neon_data_by_year/cari.df_2020.csv")
# write_csv(cari.df.2020, path)
# 
# walk.df.2019 <- walk.df %>%
#   filter(year(local_datetime) == 2019) %>%
#   dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)
# 
# # save df
# path <- here("N_uptake_NEON/data/neon_data_by_year/walk.df_2019.csv")
# write_csv(walk.df.2019, path)
# 

```
