---
title: "05_observation v process error for BIGC19"
author: "Christa Torrens"
format: html
editor: visual
---

## Intro

This document uses rstan::extract and tidybayes to extract and visualize model fit params for the BIGC (Big Creek, CA) runs comparing process and observation error.

Created 1/10/2025 by Christa Torrens

#### Load needed libraries and model fits

```{r}
# Load libraries
library(tidyverse)
library(tidybayes)
library(bayesplot)
library(rstanarm)
library(here)

# load model fits for observation and process error (stored as rds)
observation.fit <- readRDS(here("N_uptake_NEON/obs_v_process/observation.fit.rds"))

process.fit <- readRDS(here("N_uptake_NEON//obs_v_process/process.fit.rds"))

####### direct from model run:

# observation.fit <- fit.bigc19.obsE
  
# process.fit <- fit.bigc19.procE

```

### Observation error model

##### Extract model parameters

```{r - extract obs. error model params}
#| echo: false

# TIDYBAYES

#U.obsE.spread <- spread_draws(fit.bigc19.obsE, regex = "U")

# What was the modeled uptake?
o.U_mod <- rstan::extract(observation.fit, pars = "U")$U
o.U_mod_avg <- apply(o.U_mod, MARGIN = 2, FUN = mean) 
o.U_mod_sd <- apply(o.U_mod, MARGIN = 2, FUN = sd)

# what was modeled K? 

o.K_mod <- rstan::extract(observation.fit, pars = "K")$K
o.K_mod_avg <- apply(o.K_mod, MARGIN = 2, FUN = mean) 
o.K_mod_sd <- apply(o.K_mod, MARGIN = 2, FUN = sd)

# Get conc_hat from fit; plot vs concMA
o.conc_hat <- rstan::extract(observation.fit, pars = "conc_hat")$conc_hat 
#conc_hat.oe <- extract(fit.oe, pars = "conc_hat")$conc_hat 

# > dim(conc_hat)
# [1] 4000   24   39

# Collapse the 4000-layer array to a matrix rows = hours, columns = days - just like concMA
#avg_conc_hat_oeMA <- apply(conc_hat.oe, MARGIN = c(2, 3), FUN = mean) 
o.avg_conc_hat_MA <- apply(o.conc_hat, MARGIN = c(2, 3), FUN = mean)  


#avg_conc_hat.oe <- as.vector(c(avg_conc_hat_oeMA))
o.N_conc_hat <- as.vector(c(o.avg_conc_hat_MA))

#U_mean <- as.vector(c(U_mod_avg))

####### FROM REAL DATA --------------------------------------------

N_conc <- bigc.df.19h$surfWaterNitrateMean ##as.vector(c(concMA)) would give the same values

local_datetime <- bigc.df.19h$local_datetime  
model_datetime <- bigc.df.19h$local_datetime - hours(4)
model_day <-bigc.df.19h$model_day
hours <- hour(local_datetime)
mod_hours <- hour(model_datetime)
# find a way to remove day #212

mod_day <- unique(model_day)

o.N_output.df <- data.frame(local_datetime, hours, mod_hours, model_datetime, model_day, N_conc, o.N_conc_hat)

#mod_day <- unique(model_day)
o.U_output.df <- data.frame(mod_day, o.U_mod_avg, o.U_mod_sd, sumlight.real, model_datetime) 
o.K_output.df <- data.frame(mod_day, o.K_mod_avg, o.K_mod_sd, sumlight.real, model_datetime)

mean(o.K_mod_avg) # 3.054388  #2.95135

# credible intervals for each U
# extract 2.5% and 97.5% values - see Alice's code?

which.min(o.U_output.df$o.U_mean)

o.U_output.df$o.U_mod_avg

```

##### Create visualizations

```{r - create obs. error visualizations}

o.N_and_Nhat <- o.N_output.df %>%
  filter(model_day >= 175 & model_day <= 185) %>%  # to see these better...
  ggplot(aes(x=mod_hours)) +
  geom_point(aes(y=N_conc)) + 
  geom_line(aes(y=o.N_conc_hat), col='red')+
  labs(
    x="Time (h)", y=expression("N"~(mmol~m^-3))
  ) +
  #ggtitle("N and N_hat over time - Big Creek 2019 pooled model")+
  ggtitle("NEON: Big Creek - observation error model") +
  facet_wrap(~model_day)+
  #title("N conc vs conc-hat, Big Creek pooled 1 (by mean)")+
  #scale_color_manual(values=c("N_conc" = "black", "N_conc_hat" = "red"), name= "Big Creek N") +
  theme_bw()

quartz()
o.N_and_Nhat
# Use 'for' loop with matrix version or use hours as the x-axis... 

# datetimeMA <- matrix(local_datetime, nrow=24)
# 
# quartz()
# for (i in 1:nday) {
#   plot (datetimeMA[,i], concMA[,i])  
#  lines(datetimeMA[,i], avg_conc_hat_MA[,i], col='red')
# }


########  N-hat vs N


o.Nhat_V_N <- ggplot(data = o.N_output.df, aes(x=N_conc, y=o.N_conc_hat)) +
  geom_point() + 
  xlab("measured N (umol/L)") + ylab("modeled N (umol/L)") + 
  ggtitle("Measured N vs modeled N, Big Creek 2019 pooled model - observation error model") +
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  theme_bw()

quartz()
o.Nhat_V_N

##### U over time


o.U_time <- ggplot(data = o.U_output.df, aes(x=mod_day, y=o.U_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled U (mmol/m2/day)") + 
  #ylim(0,1) +
  #ggtitle("modeled U over time, Big Creek 2019 pooled model w real light") +
  ggtitle("Diel nitrate uptake (modeled), Big Creek 2019 - observation error model") +
  theme_bw()

quartz()
o.U_time


o.U_time_clip <- ggplot(data = o.U_output.df, aes(x=mod_day, y=o.U_mod_avg)) +
   geom_point() +
   # geom_point(y = sumlight.real, color = 'gold') +
   # ADD IN HIGH AND LOW CIs
   xlab("Julian day") + ylab("modeled U (mmol/m2/day)") +
   ylim(0,1) +
   ggtitle("modeled U over time, Big Creek 2019 pooled model w real light - observation error model") +
   theme_bw()

 quartz()
 o.U_time_clip

###### U vs sumlight


o.U_vs_light <- ggplot(data = U_output.df, aes(x=sumlight.real, y=o.U_mod_avg)) +
  geom_point() + 
  #xlab("true light (satellite)") + ylab("modeled U (mmol/m2/day)") +
  xlab("light (satellite)") + ylab("modeled U (mmol/m2/day)") +
  ggtitle("Big Creek 2019: scatterplot of NO3 uptake and daily light - observation error model") +
  #ylim = c(-0.2, 1) +
  theme_bw()

quartz()
o.U_vs_light

#######  K over time


o.K_time <- ggplot(data = o.K_output.df, aes(x=mod_day, y=o.K_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled K (day -1)") + # daily change in N concentration
  ylim(0,20) +
  ggtitle("modeled K over time, Big Creek 2019 pooled model w real light - observation error model") +
  theme_bw()

quartz()
o.K_time



K_time_clip <- ggplot(data = K_output.df, aes(x=mod_day, y=K_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled K (umol/day)") + # ??? UNITS?
  ylim(0,10) +
  ggtitle("modeled K over time, Big Creek 2019 pooled model w real light") +
  theme_bw()

quartz()
K_time_clip



# U vs K

plot(o.U_mod_avg, o.K_mod_avg)

```

### Process error model

##### Extract model parameters

```{r - extract process error model params}
#| echo: false

# What was the modeled uptake?
p.U_mod <- rstan::extract(process.fit, pars = "U")$U
p.U_mod_avg <- apply(p.U_mod, MARGIN = 2, FUN = mean) 
p.U_mod_sd <- apply(p.U_mod, MARGIN = 2, FUN = sd)

# what was modeled K? 

p.K_mod <- rstan::extract(process.fit, pars = "K")$K
p.K_mod_avg <- apply(p.K_mod, MARGIN = 2, FUN = mean) 
p.K_mod_sd <- apply(p.K_mod, MARGIN = 2, FUN = sd)

# Get conc_hat from fit; plot vs concMA
p.conc_hat <- rstan::extract(process.fit, pars = "conc_hat")$conc_hat 
#conc_hat.oe <- extract(fit.oe, pars = "conc_hat")$conc_hat 

# > dim(conc_hat)
# [1] 4000   24   39

# Collapse the 4000-layer array to a matrix rows = hours, columns = days - just like concMA
#avg_conc_hat_oeMA <- apply(conc_hat.oe, MARGIN = c(2, 3), FUN = mean) 
p.avg_conc_hat_MA <- apply(p.conc_hat, MARGIN = c(2, 3), FUN = mean)  


#avg_conc_hat.oe <- as.vector(c(avg_conc_hat_oeMA))
p.N_conc_hat <- as.vector(c(p.avg_conc_hat_MA))

#U_mean <- as.vector(c(U_mod_avg))

N_conc <- bigc.df.19h$surfWaterNitrateMean ##as.vector(c(concMA)) would give the same values

local_datetime <- bigc.df.19h$local_datetime  
model_datetime <- bigc.df.19h$local_datetime - hours(4)
model_day <-bigc.df.19h$model_day
hours <- hour(local_datetime)
mod_hours <- hour(model_datetime)
# find a way to remove day #212

mod_day <- unique(model_day)

p.N_output.df <- data.frame(local_datetime, hours, mod_hours, model_datetime, model_day, N_conc, p.N_conc_hat)

#mod_day <- unique(model_day)
p.U_output.df <- data.frame(mod_day, p.U_mod_avg, p.U_mod_sd, sumlight.real, model_datetime) 
p.K_output.df <- data.frame(mod_day, p.K_mod_avg, p.K_mod_sd, sumlight.real, model_datetime)

mean(p.K_mod_avg) # 2.950436

# credible intervals for each U
# extract 2.5% and 97.5% values - see Alice's code?

which.min(p.U_output.df$p.U_mean)

p.U_output.df$p.U_mod_avg


```

##### Create visualizations

```{r - create process error visualizations}
p.N_and_Nhat <- p.N_output.df %>%
  #filter(model_day >= 175 & model_day <= 185) %>%  # to see these better...
  ggplot(aes(x=mod_hours)) +
  geom_point(aes(y=N_conc)) + 
  geom_line(aes(y=p.N_conc_hat), col='red')+
  labs(
    x="Time (h)", y=expression("N"~(mmol~m^-3))
  ) +
  #ggtitle("N and N_hat over time - Big Creek 2019 pooled model")+
  ggtitle("NEON: Big Creek 2019 pooled model - process error model") +
  facet_wrap(~model_day)+
  #title("N conc vs conc-hat, Big Creek pooled 1 (by mean)")+
  #scale_color_manual(values=c("N_conc" = "black", "N_conc_hat" = "red"), name= "Big Creek N") +
  theme_bw()

quartz()
p.N_and_Nhat
# Use 'for' loop with matrix version or use hours as the x-axis... 

# datetimeMA <- matrix(local_datetime, nrow=24)
# 
# quartz()
# for (i in 1:nday) {
#   plot (datetimeMA[,i], concMA[,i])  
#  lines(datetimeMA[,i], avg_conc_hat_MA[,i], col='red')
# }


########  N-hat vs N


p.Nhat_V_N <- ggplot(data = p.N_output.df, aes(x=N_conc, y=p.N_conc_hat)) +
  geom_point() + 
  xlab("measured N (umol/L)") + ylab("modeled N (umol/L)") + 
  ggtitle("Measured N vs modeled N, Big Creek 2019 pooled model - process error model") +
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  theme_bw()

quartz()
p.Nhat_V_N

##### U over time


p.U_time <- ggplot(data = p.U_output.df, aes(x=mod_day, y=p.U_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled U (mmol/m2/day)") + 
  #ylim(0,1) +
  #ggtitle("modeled U over time, Big Creek 2019 pooled model w real light") +
  ggtitle("Diel nitrate uptake (modeled), Big Creek 2019 - process error model") +
  theme_bw()

quartz()
p.U_time


p.U_time_clip <- ggplot(data = p.U_output.df, aes(x=mod_day, y=p.U_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled U (mmol/m2/day)") + 
  ylim(0,2) +
  ggtitle("modeled U over time, Big Creek 2019 pooled model w real light - process error model") +
  theme_bw()

quartz()
p.U_time_clip

###### U vs sumlight


p.U_vs_light <- ggplot(data = p.U_output.df, aes(x=sumlight.real, y=p.U_mod_avg)) +
  geom_point() + 
  #xlab("true light (satellite)") + ylab("modeled U (mmol/m2/day)") +
  xlab("light (satellite)") + ylab("modeled U (mmol/m2/day)") +
  ggtitle("Big Creek 2019: scatterplot of NO3 uptake and daily light - process error model") +
  #ylim = c(-0.2, 1) +
  theme_bw()

quartz()
p.U_vs_light

#######  K over time
p.UK_output.df <- p.U_output.df


p.K_time <- ggplot(data = p.K_output.df, aes(x=mod_day, y=p.K_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled K (day -1)") + # daily change in N concentration
  ylim(0,20) +
  ggtitle("modeled K over time, Big Creek 2019 pooled model w real light - process error model") +
  theme_bw()

quartz()
p.K_time



p.K_time_clip <- ggplot(data = p.K_output.df, aes(x=mod_day, y=p.K_mod_avg)) +
  geom_point() + 
  # geom_point(y = sumlight.real, color = 'gold') +
  # ADD IN HIGH AND LOW CIs
  xlab("Julian day") + ylab("modeled K (umol/day)") + # ??? UNITS?
  ylim(0,10) +
  ggtitle("modeled K over time, Big Creek 2019 pooled model w real light - process error model") +
  theme_bw()

quartz()
p.K_time_clip



# U vs K

UvsK.p <- ggplot(p.U_mod_avg, p.K_mod_avg)


dev.off()

```

#### Comparing process and observation error models

```{r - comparing process and obs error models}

comp.df <- tibble(o.U_mod_avg, p.U_mod_avg, o.K_mod_avg, p.K_mod_avg)

compU <- ggplot(data=comp.df, aes(x=o.U_mod_avg, y=p.U_mod_avg)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  xlab("U - observation model") + ylab("U - process model") +
  ggtitle("Comparing U from process error vs observation error models") +
  theme_bw()
  
quartz()
compU

  
compK <- ggplot(data=comp.df, aes(x=o.K_mod_avg, y=p.K_mod_avg)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  xlab("K - observation model") + ylab("K - process model") +
  ggtitle("Comparing K from process error vs observation error models") +
  theme_bw()
                
quartz()
compK


p.UvsK <- ggplot(data=comp.df, aes(x=p.U_mod_avg, y=p.K_mod_avg)) +
  geom_point() +
  xlab("process model U (mmol m-2 d-1)") + ylab("process model K (d-1)") + 
  ggtitle("K vs U for the process model (Big Creek 2019 data)") +
  theme_bw()

quartz()
p.UvsK
#dev.off


```

Observation and process mod posterior prediction checks - WORK IN PROGRESS

```{r - posterior pred check}
######### Parameter density distrib for U and K (separate plots) - observation

posterior <- as.matrix(fit.bigc19.obsE)

plot_title <- ggtitle("Posterior distributions for U",
                      "with medians and 80% intervals")
quartz()
mcmc_areas(posterior,
           regex_pars = "U\\[[1-5]\\]",
           prob = 0.8) + plot_title

dev.off()

# write.csv(p.bigc,file="N_output_pooledU_bigc.csv")
# output_bigc <- read_csv("N_output_pooledU_bigc.csv")
# 
# max.print(fit,pars="conc_tilde")

```

### Process model warning messages (generated when fitting the model in 04\_... ):

Warning messages generated for the process error model fit: Warning messages: 1: There were 39 divergent transitions after warmup. See https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup to find out why this is a problem and how to eliminate them.

2: There were 4 chains where the estimated Bayesian Fraction of Missing Information was low. See https://mc-stan.org/misc/warnings.html#bfmi-low

3: Examine the pairs() plot to diagnose sampling problems

4: The largest R-hat is NA, indicating chains have not mixed. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#r-hat

5: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#bulk-ess

6: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#tail-ess
