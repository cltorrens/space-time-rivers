---
title: "02_select and visualize NEON data for model"
author: "Christa Torrens"
format: html
editor: visual
---

## Selecting and visualizing NEON NO3 data for the stan model

The purpose of this script is to load the NEON nitrate Rdata, separate it by site, and then identify at least 100 complete "good" days per site, to inform the model. "Good" days = complete days where the diel signal of autotrophic nitrate uptake is clearly visible and not affected by, e.g., hydrology or other physical processes. When there are gaps in the data, we will fill up to 2-hour gaps using the zoo() package, linear method. If there are gaps \> 2 hours, OR multiple smaller gaps, the day will be discarded.

First load the required packages

### Loading required packages

Add these before knitting:

```{r loading packages}
#| warning: false
#| output: false

# load packages
library(scales)
library(tidyverse) # includes magrittr, as part of dplyr
library(lubridate)
library(rstan)
library(tidybayes)
library(GGally) # adds functions to ggplot()
# library(shinystan)
library(zoo)
library(neonUtilities)
library(ggpubr) #publication-ready graphs
library(brms)
library(here) # allows project-based file paths
library(pracma) # for 1 type of light AUC calcs
library(dygraphs) # creates interactive ts graphs

# make sure the working directory is set to the project level
setwd(here())

```

### Functions

Define any functions

```{r - functions}

selectRdata <- function(data, site, tz, span) {
  data %>%
  filter(siteID == site) %>%
  mutate(local_datetime = with_tz(startDateTime, tzone=tz),
         Jday = yday(local_datetime),
         model_datetime = local_datetime - hours(4), 
         model_jday = yday(model_datetime)) %>%
   filter(year(local_datetime) %in% span)
}

# data = the name of the NO3 Rdata 
# site = the site ID from the Rdata, in quotes " "
# tz = the desired time zone for the site, in quotes " " 
# span = the year or years to filter for in the Rdata. 

# NB: The current dataset (as of Feb 2025) runs from Dec 2016-Dec 2024; QA/QC'd data w good discharge = Jan 2021-June 2023


```

Then load the NEON NO3 Rdata

### Loading the NEON Rdata

```{r load NEON NO3 data}
#| output: false
#| message: false

load(here("N_uptake_NEON/data/neon_data_derived/no3_dataset.Rdata")) 
#no3_data_sensor is the object name

# View(no3_data_sensor)
# unique(no3_data_sensor$siteID)   

# CURRENT DATA FILE:
# ARIK, BIGC, BLDE, BLUE, BLWA, CARI, COMO, CUPE, FLNT, GUIL, HOPB, KING, LECO, MART, OKSR, POSE, PRIN, REDB, SYCA, TECR, WALK, WLOU

# ORIGINAL FOUR:"KING" "WALK" "BIGC" "CARI"

# Not pulled:Lewis Run [LEWI], Clarke, VA; Mayfield Creek [MAYF], Bibb, AL; McDiffett Creek [MCDI], Wabaunsee, KS; McRae Creek [MCRA], Linn, OR; Tombigbee River [TOMB], Choctaw, AL

```

### Viewing, selecting, and saving data by site

For each site: \* Filter by site ID and set appropriate time zone for local time (default for NEON is UTC)

-   Use OlsonNames() to check for accurate timezone names: "US/Eastern" "US/Central" "US/Mountain" "US/Pacific" "US/Alaska" "US/Arizona" "US/Hawaii" "America/Puerto_Rico"

-   Select the days to use in the model: create 1 dataframe per site, across mulitple years. Aim for at least 100 full days with clear diel no3 swings. It may be easiest to explore and select data by year... Try it by site and see how it goes.

-   Per Bobby Hensley, data from 2021 on will have the best discharge data (Q and O2 data prior to 2021 are 'shoddy'). Currently focusing on 2021-2023 data.

-   2024 Q data has been QA/QC'd as of March 2025

-   NB: for 2024 NO3 data, Jan-Jun data are QA/QC'd and July-Dec data are still provisional (as of 3/06/2025)

Site descriptions: https://www.neonscience.org/field-sites/explore-field-sites

Individual sites follow this pattern: BIGC: https://www.neonscience.org/field-sites/bigc CARI: https://www.neonscience.org/field-sites/cari KING: https://www.neonscience.org/field-sites/king WALK: https://www.neonscience.org/field-sites/walk (etc.)

#### Arikaree River, Yuma, CO

nitrate sensor lat-long: 39.758356 -102.44859 reference elevation (m): 1178.7

```{r ARIK}

##### Create object for ARIK => Arikaree River, Yuma, CO

# arik.df <- no3_data_sensor %>%
#   filter(siteID == "ARIK") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#    filter(year(local_datetime) == 2021:2023)
# 

arik.df <- selectRdata(data=no3_data_sensor, site="ARIK", tz="US/Mountain", span=2021:2024)


##### Visualize, select and clean ARIK data

yr <- 2021
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
arik.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("ARIK, 2023") +
  theme_bw()


##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/arik_df.csv")
write_csv(arik.df, path)

```

#### Upper Big Creek, Fresno, CA

nitrate sensor lat-long: 37.057672 -119.255375\
elevation (m): 1131.24 tz="US/Pacific"

"overhang" sensor location: lat-long: 37.057515 -119.255046 elevation (m): 1127.43

###### Load data

```{r - BIGC}
#| output: false
#| message: false

##### Create object for BIGC => West St Louis Creek, Grand, CO

bigc.df <- selectRdata(data=no3_data_sensor, site="BIGC", tz="US/Pacific", span=2021:2024)

bigc_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/BIGC_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Pacific"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(bigc_light.df$local_datetime)
tz(bigc.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize bigc lightdata}

# Get summed 15 and 60m data for light:

bigc_light.df.15 <- bigc_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 

bigc_light.df.h <- bigc_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 

```

###### Visualize, select and clean BIGC data

```{r - BIGC visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "BIGC, Jun 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
bigc.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


# bigc_dy <- bigc.df %>%
  # select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=bigc_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     BIGC: COMMENTS?


# ID Jdays: 

##    2021: 56, 57, 58, 59, 60, 61, 63, 64, 65, 128, 129, 130, 133, 139, 140, 149, 150, 151, 152, 153, [154], 155, 156, 157, 158, 159, 160, 175, 176, [177], 178, [179], 197, 198, 202, 203, 204, 225, 226, 227, 228, 229, 230, 243, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259, 260, 261, 262, 263, 264, 267, 268, 269, 270, 274, 275, 276, [337,338, 339, 340 - ampl. may be too low]

##    2022:  22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 52, 58, 59, 68, 69, 70, 71, 72, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268 

##    2023: 33, 34, 41, 43, 44, 46, 47, 48, 49, 50, 51, 91, 92, 96, 101, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350

# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 24, 25, 26, 27, 28, 29, 30, 31, 74, 75, 76, 80, 81, 82, 93, 94, 99, 100, 137, 138, 142, 143, 146, 153, 154, 155, 163, 168


# create objects from selected jdays for each year
# list.21 <- c(56, 57, 58, 59, 60, 61, 63, 64, 65, 128, 129, 130, 133, 139, 140, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 175, 176, 177, 178, 179, 197, 198, 202, 203, 204, 225, 226, 227, 228, 229, 230, 243, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259, 260, 261, 262, 263, 264, 267, 268, 269, 270, 274, 275, 276, 337, 338, 339, 340)

# for WY22 only
list.21 <- c(274, 275, 276, 337, 338, 339, 340)

list.22 <- c(22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 52, 58, 59, 68, 69, 70, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268)

list.23 <- c(33, 34, 41, 43, 44, 46, 47, 48, 49, 50, 51, 91, 92, 96, 101, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350)

list.24 <- c(25, 26, 27, 28, 29, 30, 31, 74, 75, 76, 80, 81, 82, 93, 94, 99, 100, 137, 138, 142, 143, 146, 153, 154, 155, 163, 168)


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
bigc.df.21 <- bigc.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
bigc.df.22 <- bigc.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

bigc.df.23 <- bigc.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

bigc.df.24 <- bigc.df %>%  
  filter(year(local_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
bigc.df.21 %>% count(model_jday) #7
bigc.df.22 %>% count(model_jday) #86, after removing 71 and 72 (92 obs each)
bigc.df.23 %>% count(model_jday) #53, after removing 308 (100 obs)
bigc.df.24 %>% count(model_jday) #27

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- bigc.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- bigc.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- bigc.df.23 %>%
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- bigc.df.24 %>%
  count(model_jday) %>%
  filter(n != 96)

# View days with alternate n values
# bigc22_310 <- bigc.df.22 %>% filter(model_jday == 310)
# bigc21_310 <- bigc.df.22 %>% filter(model_jday == 310)
# View(bigc73)
# View(bigc310)
# 
# bigc310 <- bigc.df.22 %>% filter(Jday == 310)
# View(bigc310)


##### Combine selected days into 1 df, select columns 
bigc.df.2124 <- bind_rows(bigc.df.21, bigc.df.22, bigc.df.23, bigc.df.24) %>%
  # dplyr::filter(model_datetime >= "2021-10-01 00:00:00") %>%  # already done in date selection
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing bigc.df.2124 observations by 96 
# 173 for bigc WY 22-24

##### Combine df with sat_light data for the selected model days
bigc.wlight.df.2124 <- left_join(x=bigc.df.2124,
                                 y=bigc_light.df.15, 
                                 by = "local_datetime") 


View(bigc.wlight.df.2124)

### ADD IN Q, TOO



# check the 1st day in the df to make sure light joined correctly
jday21_274 <- bigc_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 10) %>%
  filter(day(local_datetime) == 01)


# save to keep progress
write_csv(bigc.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/BIGC_wlight_2124_joined.csv"))


```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# bigc.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/BIGC_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Pacific"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(bigc.wlight.df.2124$surfWaterNitrateMean))
no3NA

# 15 NAS: 2428  9905  9920  9921 11260 11553 13329 15212 15213 15214 15578 15579 15580 15581 16576

QMfail <- which(bigc.wlight.df.2124$rangeFailQM == 1) # none, whew


# When do these occur? (ID any particularly bad days to remove)
NAdays <- bigc.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  # 2021: 63(2), 128, 198, 204, 227
        # 2022: 70
        # 2023: 51(3), 304, 307, 342

# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(bigc.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew



##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 15570:15585
plot(bigc.wlight.df.2124$local_datetime[span], bigc.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill (2h)
bigc.wlight.df.2124$surfWaterNitrateMean <- na.approx(bigc.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(bigc.wlight.df.2124$surfWaterNitrateMean)) 

# no NAs remain

N_e <- mean(bigc.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #1.74
N_sd <- sd(bigc.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #0.67

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
bigc.wlight.df.h <- bigc.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = bigc_light.df.h, by = "local_datetime")


# cari.wlight.df.2124.h <- cari.df.2124 %>%
#   filter(minute(local_datetime)==0) %>%
#   left_join(y = cari_light.df.h, by = "local_datetime") %>%
#   dplyr::select(-startDateTime) %>%
#   dplyr::select(1:3, PAR, everything())

# Mean of selected dataset
N_e <- mean(bigc.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #1.74
N_sd <- sd(bigc.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #0.67

# checking the other light data... 
lightNA <- which(is.na(bigc.wlight.df.h$GHI_wm2))

```

###### Visualize cleaned data

```{r - visualize BIGC clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(bigc.wlight.df.h$model_jday)



```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/bigc_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/bigc_hourly_clean.csv")
write_csv(bigc.wlight.df.2124, path)
write_csv(bigc.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# bigc.wlight.df.2124 <- read_csv(path)
# bigc.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))
```

#### Blacktail Deer Creek, Park, WY

nitrate sensor lat-long: 44.953606 -110.589396 elevation (m): 2023.27 tz="US/Mountain"

###### Load data

```{r - BLDE}
#| output: false
#| message: false

##### Create object for BLDE => West St Louis Creek, Grand, CO

blde.df <- selectRdata(data=no3_data_sensor, site="BLDE", tz="US/Mountain", span=2021:2024)

blde_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/BLDE_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(blde_light.df$local_datetime)
tz(blde.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

###### Visualize, select and clean BLDE data

```{r - BLDE visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "BLDE, Jun 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
blde.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


# blde_dy <- blde.df %>%
  # select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=blde_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     BLDE: COMMENTS?


# ID Jdays: 

##    2021: 56, 57, 58, 59, 60, 61, 63, 64, 65, 128, 129, 130, 133, 139, 140, 149, 150, 151, 152, 153, [154], 155, 156, 157, 158, 159, 160, 175, 176, [177], 178, [179], 197, 198, 202, 203, 204, 225, 226, 227, 228, 229, 230, 243, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259, 260, 261, 262, 263, 264, 267, 268, 269, 270, 274, 275, 276, [337,338, 339, 340 - ampl. may be too low]

##    2022:  22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 52, 58, 59, 68, 69, 70, 71, 72, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268 

##    2023: 33, 34, 41, 43, 44, 46, 47, 48, 49, 50, 51, 91, 92, 96, 101, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350

# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 24, 25, 26, 27, 28, 29, 30, 31, 74, 75, 76, 80, 81, 82, 93, 94, 99, 100, 137, 138, 142, 143, 146, 153, 154, 155, 163, 168


# create objects from selected jdays for each year
list.21 <- c(56, 57, 58, 59, 60, 61, 63, 64, 65, 128, 129, 130, 133, 139, 140, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 175, 176, 177, 178, 179, 197, 198, 202, 203, 204, 225, 226, 227, 228, 229, 230, 243, 245, 246, 247, 248, 249, 250, 251, 257, 258, 259, 260, 261, 262, 263, 264, 267, 268, 269, 270, 274, 275, 276, 337, 338, 339, 340)

list.22 <- c(22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 52, 58, 59, 68, 69, 70, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268)

# list.23 <- c(33, 34, 41, 43, 44, 46, 47, 48, 49, 50, 51, 91, 92, 96, 101, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350)

# after removing days w. serious Q data issues: 
list.23 <- c(291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 313, 314, 315, 317, 318, 325, 326, 327, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350)


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
blde.df.21 <- blde.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
blde.df.22 <- blde.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

blde.df.23 <- blde.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

# Check for complete days: should have 96 obs/ day
blde.df.21 %>% count(model_jday) #70
blde.df.22 %>% count(model_jday) #86, after removing 71 and 72 (92 obs each)
blde.df.23 %>% count(model_jday) #53, after removing 308 (100 obs)

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- blde.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- blde.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- blde.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

# View days with alternate n values
# blde22_310 <- blde.df.22 %>% filter(model_jday == 310)
# blde21_310 <- blde.df.22 %>% filter(model_jday == 310)
# View(blde73)
# View(blde310)
# 
# blde310 <- blde.df.22 %>% filter(Jday == 310)
# View(blde310)


##### Combine selected days into 1 df, select columns 
blde.df.2123 <- bind_rows(blde.df.21, blde.df.22, blde.df.23) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing blde.df.2123 observations by 96 
# 209 for blde


##### Combine df with sat_light data for the selected model days
blde.wlight.df.2123 <- left_join(x=blde.df.2123,
                                 y=blde_light.df, 
                                 by = "local_datetime") 


View(blde.wlight.df.2123)

# check the 1st day in the df to make sure light joined correctly
jday21_56 <- blde_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 2) %>%
  filter(day(local_datetime) == 25)


# save to keep progress
write_csv(blde.wlight.df.2123,file=here("N_uptake_NEON/data/neon_data_joined/BLDE_wlight_2123_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# blde.wlight.df.2123 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2123_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(blde.wlight.df.2123$surfWaterNitrateMean))
no3NA

# 13 occurrences: 595   596   877  3191  3523  3766  8476 15953 15968 15969 17308 17601 19377

# When do these occur? (ID any particularly bad days to remove)
NAdays <- blde.wlight.df.2123 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  # 2021: 63(2), 128, 198, 204, 227
        # 2022: 70
        # 2023: 51(3), 304, 307, 342

# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(blde.wlight.df.2123$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 15945:15985
plot(blde.wlight.df.2123$local_datetime[span], blde.wlight.df.2123$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
blde.wlight.df.2123$surfWaterNitrateMean <- na.approx(blde.wlight.df.2123$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(blde.wlight.df.2123$surfWaterNitrateMean)) 

# no NAs remain

N_e <- mean(blde.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)  #1.811533
N_sd <- sd(blde.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)   #0.7407876

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
blde.wlight.df.h <- blde.wlight.df.2123 %>%
  filter(minute(local_datetime) == 0) 
# Mean of selected dataset
N_e <- mean(blde.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #1.811583
N_sd <- sd(blde.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #0.7408184



```

###### Visualize cleaned data

```{r - visualize BLDE clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(blde.wlight.df.h$model_jday)



```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/blde_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/blde_hourly_clean.csv")
write_csv(blde.wlight.df.2123, path)
write_csv(blde.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# blde.wlight.df.2122 <- read_csv(path)
# blde.wlight.df.h <- read_csv(path_h)

```

#### Blue River, Johnston, OK

nitrate sensor lat-long: 34.448448 -96.622796 \*\* overhang sensor - the other sensor info says 'not used' elevation (m): 288.31 tz="US/Central"

```{r - BLUE}

##### Create object for BLUE => Blue River, Johnston, OK

blue.df <- selectRdata(data=no3_data_sensor, site="BLUE", tz="US/Central", span=2021:2024)


# blue.df <- no3_data_sensor %>%
#   filter(siteID == "BLUE") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Central"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean BLUE data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
blue.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("BLUE, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/blue_df.csv")
write_csv(blue.df, path)

```

#### Black Warrior River, Greene, AL

nitrate sensor lat-long: 32.542478 -87.797972 \*\* sensor buoy (river) elevation (m): 23 tz="US/Central"

```{r - BLWA}

##### Create object for BLWA => Black Warrior River, Greene, AL

blwa.df <- selectRdata(data=no3_data_sensor, site="BLWA", tz="US/Central", span=2021:2024)


# blwa.df <- no3_data_sensor %>%
#   filter(siteID == "BLWA") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Central"),
#          Jday = yday(local_datetime)) %>%
#    filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean BLWA data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
blwa.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("BLWA, 2023") +
  theme_bw()


##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/blwa_df.csv")
write_csv(blwa.df, path)

```

#### Caribou Creek, Fairbanks North Star, AK

nitrate sensor lat-long: 65.153076 -147.502004 elevation (m): 225.41 tz="US/Alaska"

###### Load data

```{r - CARI}
#| output: false
#| message: false

##### Create object for CARI => West St Louis Creek, Grand, CO

cari.df <- selectRdata(data=no3_data_sensor, site="CARI", tz="US/Alaska", span=2021:2024) %>%
  mutate(model_datetime = local_datetime - hours(2),  # adjusting model dates because #midsummer days start 2:45a, end 1a the next day; 2-hour offset ensures the start of the day is in darkness
         model_jday = yday(model_datetime))

# needed to reset Jday and model_jday values for some reason; they were not matching the actual jday and model jday.
cari_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/CARI_neonlight05m_all.csv")) %>%
  mutate(local_datetime = with_tz(startDateTime, tz="US/Alaska")) %>%
  dplyr::select(local_datetime, PAR, startDateTime)

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(cari_light.df$local_datetime)
tz(cari.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize cari lightdata}

# First, check and clean if needed (NEON data):
cari_light <- ggplot(data = cari_light.df, aes(x=local_datetime, y=PAR)) + 
  geom_point() + 
  labs(title = "Caribou Creek light", 
       xlab = "datetime", 
       ylab = "PAR") + 
  theme_bw()

cari_light
ggplotly(cari_light)

# 9/12/2023 clip 11:15-11:40, linear fill
# PAR < 0 == 0

cari_light.df <- cari_light.df %>%
  mutate(
    PAR = if_else(
      local_datetime >= ymd_hm("2023-09-12 11:10", tz = "US/Alaska") &
      local_datetime <= ymd_hm("2023-09-12 12:10", tz = "US/Alaska") &
      PAR > 1180, 1150, PAR
      )
  )

which(is.na(cari_light.df$PAR))

# AVOID 4/29/24, jd 120 => sensor glitch



# Get summed 15 and 60m data for light: 
cari_light.df.15 <- cari_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes"), 
         startDateTime = ceiling_date(startDateTime, unit = "15minutes")) %>%
  group_by(local_datetime, startDateTime) %>%
  summarise(PAR = sum(PAR, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(PAR = if_else(PAR < 0, 0, PAR), 
         PAR = if_else(lag(PAR) == 0 & lead(PAR) == 0, 0, PAR))
 

cari_light.df.h <- cari_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour"), 
         startDateTime = ceiling_date(startDateTime, unit = "hour")) %>%
  group_by(local_datetime, startDateTime) %>%
  summarise(PAR = sum(PAR, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(PAR = if_else(PAR < 0, 0, PAR), 
         PAR = if_else(lag(PAR) == 0 & lead(PAR) == 0, 0, PAR))

na15 <- which(is.na(cari_light.df.15$PAR)) # none
na60 <- which(is.na(cari_light.df.h$PAR)) # none

```

###### Visualize, select and clean CARI data

```{r - CARI visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "CARI, June 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
cari.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(22,30) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


# cari_dy <- cari.df %>%
  # select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
# dygraph(data=cari_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     CARI: COMMENTS - Low appears to be ~ 8-10p (!!) in May,  - and that *is* local time. Daylight hours = 5:15a-10:20p in early May, 2:45a-25:00a (1a next day) mid-June...

#########   CARI MODEL DAY STARTS AT 2A

# ID Jdays: 

##    2021: [140-147; 149-151; 163-170; 172-175; 177-183; 185-187; 191-196; 198-201; 223-226; 246-265; 267-277] - Neq at around 5-10a

# 2021: REMOVE PAR NAdays if applicable: 2021: 119, 120, 121, 122, 123, 124, 154, 189, 353, 354 (none included)

##    2022: [130-131; 135-142; 144-147; 149-159; 161-166; 169-170; 174-183; 186; 188-190; 194-195; 198-199; 202-205; 208-212; 215-218; 223-226; 229-243; 246-254; 260-269; 271-282] Neq at around 5-10a

# 2022: REMOVE PAR NAdays if applicable: 2022: 116, 171, 206, 207, 227-235, 244, 258, 312, 313, 315, 316, 317, 336, 338-345, 348, 357 
# RM 229-235

##    2023: [132-134; 139-141; 158-167; 170-173; 175-185; 191-194; 196-206; 208-221; 223-224; 252-259; 263-271; 274-277; 279-285; 287-288; 290-291] Neq at around 5-10a

# 2023: REMOVE PAR NAdays if applicable: 16, 125, 156, 157, 167, 195, 206, 255
# 2023, RM 167, 206, 255

# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: [111-113; 121-126; 137-142; 148-149; 153-156; 160-163; 172-176; ]
#     2024: REMOVE PAR NAdays if applicable: RM 120 (done)

# create objects from selected jdays for each year
# list.21 <- c(140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 163, 164, 165, 166, 167, 168, 169, 170, 172, 713, 174, 175, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 223, 224, 225, 226, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277)


## AVOID 120-2024 - light sensor errors (removed from list)


# for WY22 only
list.21 <- c(274, 275, 276, 277)

list.22 <- c(130, 131, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 169, 170, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 186, 188, 189, 190, 194, 195, 198, 199, 202, 203, 204, 205, 208, 209, 210, 211, 212, 215, 216, 217, 218, 223, 224, 225, 226, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282)


list.23 <- c(132, 133, 134, 139, 140, 141, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213,  214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 252, 253, 254, 256, 257, 258, 259, 263, 264, 265, 266, 267, 268, 269, 270, 271, 274, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 287, 288, 290, 291)

# 2024
list.24 <- c(111, 112, 113, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 142, 148, 149, 153, 154, 155, 156, 160, 161, 162, 163, 172, 173, 274)  # 28d, ending on Sept 30, 2024  


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
cari.df.21 <- cari.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
cari.df.22 <- cari.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

cari.df.23 <- cari.df %>%
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

cari.df.24 <- cari.df %>%
  filter(year(local_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
cari.df.21 %>% count(model_jday) # 4
cari.df.22 %>% count(model_jday) # 107
cari.df.23 %>% count(model_jday) # 91
cari.df.24 %>% count(model_jday) # 27

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- cari.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- cari.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- cari.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- cari.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)

# View days with alternate n values
# cari22_310 <- cari.df.22 %>% filter(model_jday == 310)
# cari21_310 <- cari.df.22 %>% filter(model_jday == 310)
# View(cari73)
# View(cari310)
# 
# cari310 <- cari.df.22 %>% filter(Jday == 310)
# View(cari310)


##### Combine selected days into 1 df, select columns 
cari.df.2124 <- bind_rows(cari.df.21, cari.df.22, cari.df.23, cari.df.24) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing cari.df.2124 observations by 96 
# 229 for cari



#### Combine df with sat_light data for the selected model days
cari.wlight.df.2124 <- left_join(x=cari.df.2124,
                                 y=cari_light.df.15, 
                                 by = "local_datetime") %>%
  dplyr::select(-startDateTime)


View(cari.wlight.df.2124)

### ADD IN Q, TOO

# check the 1st day in the df to make sure light joined correctly
jday21_274 <- cari_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 10) %>%
  filter(day(local_datetime) == 01)

### Save the 15-min NO3 df
write_csv(cari.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/CARI_wlight_2124.csv"))

# convert to hourly NO3 df
cari.wlight.df.2124.h <- cari.df.2124 %>%
  filter(minute(local_datetime)==0) %>%
  left_join(y = cari_light.df.h, by = "local_datetime") %>%
  dplyr::select(-startDateTime) %>%
  dplyr::select(1:3, PAR, everything())


# View(cari.df.2124.h)

View(cari.wlight.df.2124.h)

# save to keep progress
# write_csv(cari.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/CARI_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# cari.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/CARI_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Alaska"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(cari.wlight.df.2124.h$surfWaterNitrateMean))
no3NA

# 6 occurrences:  388 1343 2487 3538 4427 5103

# When do these occur? (ID any particularly bad days to remove)
NAdays <- cari.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  # 2021: 144(2), 255, 
        # 2022: 137, 146, 202(4), 275, 277,  
        # 2023: 139(3), 162, 196, 198(5), 201, 204, 252, 269(6), 283

# all are missing <= 1.5h of data, which is fine for a gap fill 

# lightNA <- which(is.na(cari.wlight.df.2123$PARMean))
# lightNA  
# none, whew

QMfail <- which(cari.wlight.df.2124$rangeFailQM == 1) 

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 15945:15985
plot(cari.wlight.df.2124$local_datetime[span], cari.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill the hourly data
maxgap <- 2  # set the maximum gap for zoo() to fill; 2h or less
cari.wlight.df.2124.h$surfWaterNitrateMean <- na.approx(cari.wlight.df.2124.h$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(cari.wlight.df.2124.h$surfWaterNitrateMean)) 

# no NAs remain

N_e <- mean(cari.wlight.df.2124.h$surfWaterNitrateMean, na.rm = TRUE)  #27.81
N_sd <- sd(cari.wlight.df.2124.h$surfWaterNitrateMean, na.rm = TRUE)   #4.51

# ## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
# cari.wlight.df.h <- cari.wlight.df.2124 %>%
#   filter(minute(local_datetime) == 0) 
# # Mean of selected dataset
# N_e <- mean(cari.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #1.811583
# N_sd <- sd(cari.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #0.7408184
# 


```

###### Visualize cleaned data

```{r - visualize CARI clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(cari.wlight.df.2124.h$model_jday)

#good distribution from ~ April-October

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

# path <- here("N_uptake_NEON/data/neon_data_clean/cari_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/cari_hourly_clean.csv")
# write_csv(cari.wlight.df.2124, path)
write_csv(cari.wlight.df.2124.h, path_h)


##### Reload data-in-progress as needed
# cari.wlight.df.2124 <- read_csv(path)
# cari.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### Como Creek, Boulder CO

nitrate sensor lat-long: 40.034934 -105.544417 elevation (m): 3022.86 tz="US/Mountain"

```{r - COMO}

##### Create object for COMO => Como Creek, Boulder CO

como.df <- selectRdata(data=no3_data_sensor, site="COMO", tz="US/Mountain", span=2021:2024)

# como.df <- no3_data_sensor %>%
#   filter(siteID == "COMO") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean COMO data

yr <- 2023
mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
como.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(2,8) +
  facet_wrap(~Jday) +
  ggtitle("COMO, 2023: Jan-Feb") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/como_df.csv")
write_csv(como.df, path)

```

#### Rio Cupeyes, San German Municipio, PR

nitrate sensor lat-long: 18.110265 -66.986411\
elevation (m): 149.9 tz = "America/Puerto_Rico"

###### Load data

```{r - CUPE}
#| output: false
#| message: false

##### Create object for CUPE => Rio Cupeyes, San German Municipio, PR

cupe.df <- selectRdata(data=no3_data_sensor, site="CUPE", tz="America/Puerto_Rico", span=2021:2024)

cupe_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/CUPE_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="America/Puerto_Rico"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(cupe_light.df$local_datetime)
tz(cupe.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize cupe lightdata}

# Get summed 15 and 60m data for light: 
cupe_light.df.15 <- cupe_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


cupe_light.df.h <- cupe_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
 summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


```

###### Visualize, select and clean CUPE data

```{r - CUPE visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "CUPE, Jun 2024"
# ylim(20,30) for Jan-Jun 21, Jan-Jun 23; (20, 33) for ~ Aug-Dec 2023, Jan- 2024; (17,27) for Jul-Dec 21, most of 2022, Jul 23, Jan- 2024;    : (25,35) for Oct-Dec 22

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
cupe.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(17, 27) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


## Dygraph for interactive chart w slider - meh, doesn't work all that well for my purposes.
# cupe_dy <- cupe.df %>%
# select(local_datetime, surfWaterNitrateMean)
# 
# dygraph(data=cupe_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model
# doing this early this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays

# visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
# CUPE: COMMENTS?  High NO3-N (20-35 range), very clear signals unless the data is disrupted. Several extended (hydrologic?) issues, especially in 2022. TONS of days selected. 


# ID Jdays: 

##    2021: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, [52, 53 - odd shapes], 54, 55, 60, 61, 62, 63, 63, 65, 66, 68, 69, 72, 73, 74, 75, 91, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 120, [128 - slanted bseline], 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 148, 149, 150, 151, 154, 155, 156, 158, 162, 163, 164, 165, 166, 169, 170, 171, 179, 180, 185, 186, 187, 188, 189, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 210, 211, 212, 215, 216, 217, 221, 222, 223, 225, 226, 229, 232, 239, 240, 241, 242, 244, 246, 247, 281, 282, 283, 285, [286 - lower ampl], 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364

##    2022: 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, [141 - slight wobble], 149, 150, 155, 156, 157, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 184, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, [221, 222, 238, 239, 240, 249, 251, 252, 258, 293 - low ampl - don't use unless testing something later] 298, 321, 327, 328, 329, 330, 331,  - mb include even tho relatively low?], 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 352, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362 

##    2023: 1, 2, 3, 4, 5, 6, 9, 20, 21, 25, 26, 27, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 70, 71, 72, 77, 78, 79, 85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102, 111, 112, 113, 115, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 182, 183, 184, 186, 187, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 236, 245, 246, 249, 250, 257, 270, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 301, 302, 303, 304, 309, 310, 311, 312, 318, 319, 321, 322, 323, 326, 327, 328, 329, [335, 336, 338, 339, 340, 341, 342, 343, 346, 347, may be too low... ], 351, 352, 535, 356, 357, 358, 359, 362, 363, 364, 365


# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 1, 2, 3, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 26, 27, 28, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 71, 72, 76, 77, 79, 86, 87, 93, 94, 97, 98, 99, 100, 101, 105, 106, 107, 109, [125 - low?], 126, 140, 141, 142, 143, 144, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 171, 177, 178, [182 - partial final day in June bc of model_day use]

# create objects from selected jdays for each year
# list.21 <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 60, 61, 62, 63, 63, 65, 66, 68, 69, 72, 73, 74, 75, 91, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 120, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 148, 149, 150, 151, 154, 155, 156, 158, 162, 163, 164, 165, 166, 169, 170, 171, 179, 180, 185, 186, 187, 188, 189, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 210, 211, 212, 215, 216, 217, 221, 222, 223, 225, 226, 229, 232, 239, 240, 241, 242, 244, 246, 247, 281, 282, 283, 285, 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364)

# FOR WY 22 ONLY
list.21 <- c(281, 282, 283, 285, 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364)

list.22 <- c(14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 149, 150, 155, 156, 157, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 184, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, 298, 321, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 352, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362)

list.23 <- c(1, 2, 3, 4, 5, 6, 9, 20, 21, 25, 26, 27, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 70, 71, 72, 77, 78, 79, 85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102, 111, 112, 113, 115, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 182, 183, 184, 186, 187, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 236, 245, 246, 249, 250, 257, 270, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 301, 302, 303, 304, 309, 310, 311, 312, 318, 319, 321, 322, 323, 326, 327, 328, 329, 351, 352, 535, 356, 357, 358, 359, 362, 363, 364, 365)

# 2024 not used yet
list.24 <- c(1, 2, 3, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 26, 27, 28, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 71, 72, 76, 77, 79, 86, 87, 93, 94, 97, 98, 99, 100, 101, 105, 106, 107, 109, 125, 126, 140, 141, 142, 143, 144, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 171)


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
cupe.df.21 <- cupe.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
cupe.df.22 <- cupe.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

cupe.df.23 <- cupe.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

cupe.df.24 <- cupe.df %>%  
  filter(year(local_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
cupe.df.21 %>% count(model_jday) #41
cupe.df.22 %>% count(model_jday) #132
cupe.df.23 %>% count(model_jday) #180
cupe.df.24 %>% count(model_jday) #70

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- cupe.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- cupe.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- cupe.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- cupe.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)

# All days, all 3 years had 96 obs. 

# View days with alternate n values
# cupe22_310 <- cupe.df.22 %>% filter(model_jday == 310)
# cupe21_310 <- cupe.df.22 %>% filter(model_jday == 310)
# View(cupe73)
# View(cupe310)
# 
# cupe310 <- cupe.df.22 %>% filter(Jday == 310)
# View(cupe310)


##### Combine selected days into 1 df, select columns 
cupe.df.2124 <- bind_rows(cupe.df.21, cupe.df.22, cupe.df.23, cupe.df.24) %>%
  mutate(Year = year(model_datetime)) %>%  #changed to be consistent w. model_jday => important in CUPE where there are year-round good days!
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing cupe.df.2123 observations by 96 
# 500 for cupe


##### Combine df with sat_light data for the selected model days
cupe.wlight.df.2124 <- left_join(x=cupe.df.2124,
                                 y=cupe_light.df.15, 
                                 by = "local_datetime") 


View(cupe.wlight.df.2124)

# plot(x= cupe.wlight.df.2124$)
# check the 1st day in the df to make sure light joined correctly
jday21_01 <- cupe_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 10) %>%
  filter(day(local_datetime) == 1)

View(jday21_01)

# save to keep progress
write_csv(cupe.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/CUPE_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# cupe.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="America/Puerto_Rico"))


##############################  Where are the NAs?  ############################

QMfail <- which(cupe.wlight.df.2124$rangeFailQM == 1) # none, whew

### Set low/ clearly sensor-error values to NA: 

# First, ID whether there are any
sensorfaildays <- cupe.wlight.df.2124 %>%
  filter(surfWaterNitrateMean < 10)  # all are less than 5

# then change the values to NA
cupe.wlight.df.2124 <- cupe.wlight.df.2124 %>%
  mutate(surfWaterNitrateMean = replace(surfWaterNitrateMean, surfWaterNitrateMean < 5, NA))


no3NA <- which(is.na(cupe.wlight.df.2124$surfWaterNitrateMean))
no3NA

# 72 occurrences:  307   308  1853  1854  1855  1876  7031  7032  7215  7216  7228  7597 10096 10330 12401 13938 13940 13941 13942 13943 13944 14707 14708 14709 15473 15474 16433 16434 17313 17624 17718 17719 18094 18765 22403 23650 25096 25097 25953 25954 25955 25956 25957 26722 28160 28161 29699 29700 29701 29964 30387 30755 30756 32002 32003 33062 33063 33065 34135 34467 35857 39160 39269 39272 39273 39289 39323 39333 39345 39384 39430 39887



# When do these occur? (ID any particularly bad days to remove)
NAdays <- cupe.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  
# 2021: 285(2), 312(4)
# 2022: 101(2), 103(3), 110, 156, 165, 201, 332(6), 340(3), 349(2), 361(2)
# 2023: 20, 26, 27(2), 31, 45, 166(2), 184(5), 200, 221(2), 249(3), 257, 280, 284(2), 312(2), 352(3)
# 2024: 3, 13, 40, 143, 149(7), 150, 157

# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(cupe.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 5830:5855, 40060:40075
# print(cupe.wlight.df.2123[5830:5860,])

span <- 40060:40075
plot(cupe.wlight.df.2124$local_datetime[span], cupe.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable for both gaps


# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
cupe.wlight.df.2124$surfWaterNitrateMean <- na.approx(cupe.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(cupe.wlight.df.2124$surfWaterNitrateMean)) 
# no NAs remain

N_e <- mean(cupe.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #24.55
N_e
N_sd <- sd(cupe.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #2.89 
N_sd

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
cupe.wlight.df.h <- cupe.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = cupe_light.df.h, by = "local_datetime")

# Mean of hourly dataset
N_e <- mean(cupe.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #24.55
N_e
N_sd <- sd(cupe.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #2.89
N_sd



```

###### Visualize cleaned data

```{r - visualize CUPE clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(cupe.wlight.df.h$model_jday)

clean.cupe.plot <- ggplot(cupe.wlight.df.h, aes(x=yr_jday, y=surfWaterNitrateMean)) + 
  geom_point() + 
  ggtitle("CUPE - cleaned and filled data") +
  theme_bw()

  quartz(height=6, width=7.5)
  clean.cupe.plot

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/cupe_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/cupe_hourly_clean.csv")
write_csv(cupe.wlight.df.2124, path)
write_csv(cupe.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# cupe.wlight.df.2124<- read_csv(path)
# cupe.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

Will not model Flint River, Baker, GA - no hydraulic z/ Aho nitrate sensor lat-long: 31.184609 -84.438438 \*\* sensor buoy (river) elevation (m): 30 tz = "US/Eastern"

#### Ro Yahuecas, Adjuntas Municipio, PR

nitrate sensor lat-long: 18.174069 -66.799688\
elevation (m): 546.37 tz = "America/Puerto_Rico"

```{r - GUIL}

##### Create object for GUIL => Ro Yahuecas, Adjuntas Municipio, PR

guil.df <- selectRdata(data=no3_data_sensor, site="GUIL", tz="America/Puerto_Rico", span=2021:2024)


# guil.df <- no3_data_sensor %>%
#   filter(siteID == "GUIL") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Puerto_Rico"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean GUIL data

yr <- 2023
# mo <- 2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
guil.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("GUIL, 2023") +
  theme_bw()


##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/guil_df.csv")
write_csv(guil.df, path)

```

#### Lower Hop Brook, Franklin, MA

nitrate sensor lat-long: 42.473264 -72.330924\
elevation (m): 214.2 tz="US/Eastern"

overhang sensor location: 42.471752 -72.330641 elevation: 208.31

```{r - HOPB}

##### Create object for HOPB => Lower Hop Brook, Franklin, MA

hopb.df <- selectRdata(data=no3_data_sensor, site="HOPB", tz="US/Eastern", span=2021:2024)


# hopb.df <- no3_data_sensor %>%
#   filter(siteID == "HOPB") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean HOPB data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
hopb.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("HOPB, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/hopb_df.csv")
write_csv(hopb.df, path)

```

#### Kings Creek, Riley, KS

nitrate sensor lat-long: 39.105188 -96.603584\
elevation (m): 324.26 tz="US/Central"

```{r - KING}

##### Create object for KING => Kings Creek, Riley, KS

king.df <- selectRdata(data=no3_data_sensor, site="KING", tz="US/Central", span=2021:2024)


# king.df <- no3_data_sensor %>%
#   filter(siteID == "KING") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Central"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)

##### Visualize, select and clean KING data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
king.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("KING, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/king_df.csv")
write_csv(king.df, path)





##________________________________________________________________________________

##### filter data by selected year(s)
king.df.2021 <- king.df %>%
  filter(year(local_datetime) == 2021) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

king.df.2022 <-  king.df %>%
  filter(year(local_datetime) == 2022) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)

king.df.2023 <-  king.df %>%
  filter(year(local_datetime) == 2023) %>%
  dplyr::select(siteID, local_datetime, Jday, startDateTime:surfWaterNitrateStdErMean)


##### save dfs
path <- here("N_uptake_NEON/data/neon_data_by_year/king.df_2021.csv")
write_csv(king.df.2021, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/king.df_2022.csv")
write_csv(king.df.2022, path)

path <- here("N_uptake_NEON/data/neon_data_by_year/king.df_2023.csv")
write_csv(king.df.2023, path)



```

#### LeConte Creek, Sevier, TN

nitrate sensor lat-long: 35.69222 -83.504409\
elevation (m): 538.09 tz="US/Eastern"

overhang sensor location: 35.692205 -83.504421 elevation: 537.52

```{r -  LECO}

##### Create object for LECO => LeConte Creek, Sevier, TN

leco.df <- selectRdata(data=no3_data_sensor, site="LECO", tz="US/Eastern", span=2021:2024) # LECO is in Sevier County = US Eastern

# leco.df <- no3_data_sensor %>%
#   filter(siteID == "LECO") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>% # Sevier County = US Eastern
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean LECO data

yr <- 2023
mo <- 3:4

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
leco.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  facet_wrap(~Jday) +
  ggtitle("LECO, 2023: Mar-Apr") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/leco_df.csv")
write_csv(leco.df, path)

```

\[Did NOT model Lewis Run \[LEWI\], Clarke, VA\]

#### Martha Creek, Skamania, WA

nitrate sensor lat-long: 45.792321 -121.929418 elevation (m): 337.16 tz="US/Pacific"

overhang sensor location: 45.792318 -121.92943 elevation: 337.02

###### Load data

```{r - MART}
#| output: false
#| message: false

##### Create object for MART => Pringle Creek, Wise Co., TX

mart.df <- selectRdata(data=no3_data_sensor, site="MART", tz="US/Pacific", span=2021:2024)

mart_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/MART_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Pacific"))

#tz(mart_light.df$local_datetime) <- "US/Mountain"

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(mart_light.df$local_datetime)
tz(mart.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

# The function does this now: 
# mart.df <- no3_data_sensor %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#         Jday = yday(local_datetime)) %>%
#   filter(siteID == "MART", 
#          year(local_datetime) %in% 2021:2023) 
#   
```

###### Visualize, select and clean MART data

```{r - MART visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "MART, Jun 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
mart.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle(plottitle) +
  theme_bw()


mart_dy <- mart.df %>%
  select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=mart_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     MART: comments?

# Jdays: 
##    2021: 

##    2022: 

##    2023: 

##    2024: 


list.21 <- c()

list.22 <- c()

list.23 <- c()

# Creating and visualizing dataframes from the selected days - 
#   MART looked really ... wobby and odd, so making sure these seem like reasonable model options

mart.df.21 <- mart.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)

quartz(6.5, 6.5)
mart.df.21 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("MART 2021") +
  theme_bw()
  
mart.df.22 <- mart.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

quartz(6.5, 6.5)
mart.df.22 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("MART 2022") +
  theme_bw()

mart.df.23 <- mart.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

quartz(6.5, 6.5)
mart.df.23 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("MART 2023") +
  theme_bw()

# Check for complete days: should have 96 obs/ day

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- mart.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- mart.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- mart.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)


length(mart.df.21$model_jday)/96 #35
length(mart.df.22$model_jday)/96 #57
length(mart.df.23$model_jday)/96 #48

# mart.df.21 %>% count(model_jday) # 35
# mart.df.22 %>% count(model_jday) # 57 (after removing jday 121 because of no3 spikes at end of model day) 
# mart.df.23 %>% count(model_jday) # 48 (after removing jday 71, w. only 92 obs)


##### Combine selected days into 1 df 
mart.df.2123 <- bind_rows(mart.df.21, mart.df.22, mart.df.23) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)


##### Combine df with sat_light data for the selected model days
mart.wlight.df.2123 <- left_join(x=mart.df.2123,
                                 y=mart_light.df, 
                                 by = "local_datetime") 


View(mart.wlight.df.2123)

# # check the 1st day in the df to make sure light joined correctly 
# jday31 <- mart_light.df %>% 
#   filter(year(local_datetime) == 2021) %>%
#   filter(month(local_datetime) == 1) %>% 
#   filter(day(local_datetime) == 31)


# save to keep progress
write_csv(mart.wlight.df.2123,file=here("N_uptake_NEON/data/neon_data_joined/MART_wlight_2123_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# mart.wlight.df.2122 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2122_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(mart.wlight.df.2123$surfWaterNitrateMean))
no3NA
# 20 NAs:  188   189  7651  7652  9053  9054  9055  9056 10914 10915 10916 10917 11338 12498 12499 12500 12501 12502 12503 12504

# 
# When do these occur? (ID any particularly bad days to remove)
NAdays <- mart.wlight.df.2123 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays # 2021: 184(2)
       # 2022: 132(2)
       # 2023:  72(4), 109(4), 121, 143(7)


lightNA <- which(is.na(mart.wlight.df.2123$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  ###################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 12495:12510
plot(mart.wlight.df.2123$local_datetime[span], mart.wlight.df.2123$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
mart.wlight.df.2123$surfWaterNitrateMean <- na.approx(mart.wlight.df.2123$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(mart.wlight.df.2123$surfWaterNitrateMean)) 

# no NAs remain

N_e <- mean(mart.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)  #15.567
N_sd <- sd(mart.wlight.df.2123$surfWaterNitrateMean, na.rm = TRUE)   #6.575

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
mart.wlight.df.h <- mart.wlight.df.2123 %>%
  filter(minute(local_datetime) == 0) 
# Mean of selected dataset
N_e <- mean(mart.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #15.576
N_sd <- sd(mart.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #6.581



```

###### Visualize cleaned data

```{r - visualize MART clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(mart.wlight.df.h$model_jday)

# big gaps in the middle of the year - things really seemed to wash out then (flashy stream?)

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/mart_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/mart_hourly_clean.csv")
write_csv(mart.wlight.df.2123, path)
write_csv(mart.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# mart.wlight.df.2123 <- read_csv(path)
# mart.wlight.df.h <- read_csv(path_h)

```

\[Did NOT model: Mayfield Creek \[MAYF\], Bibb, AL; McDiffett Creek \[MCDI\], Wabaunsee, KS; McRae Creek \[MCRA\], Linn, OR\]

#### Oksrukuyik Creek, North Slope, AK

nitrate sensor lat-long: 68.669769 -149.142847 elevation (m): 767.19 tz="US/Alaska"

```{r - OKSR}

##### Create object for OKSR => Oksrukuyik Creek, North Slope, AK

oksr.df <- selectRdata(data=no3_data_sensor, site="OKSR", tz="US/Alaska", span=2021:2024)


# oksr.df <- no3_data_sensor %>%
#   filter(siteID == "OKSR") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Alaska"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)

##### Visualize, select and clean OKSR data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
oksr.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(0,10) +
  # facet_wrap(~Jday) + 
  ggtitle("OKSR, 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/oksr_df.csv")
write_csv(oksr.df, path)

```

#### Posey Creek, Warren, VA

nitrate sensor lat-long: 38.895193 -78.147862\
elevation (m): 271.86 tz="US/Eastern"

```{r - POSE}

##### Create object for POSE => Posey Creek, Warren, VA 

pose.df <- selectRdata(data=no3_data_sensor, site="POSE", tz="US/Eastern", span=2021:2024)


# pose.df <- no3_data_sensor %>%
#   filter(siteID == "POSE") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean POSE data

yr <- 2023
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
pose.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,50) +
  # facet_wrap(~Jday) + 
  ggtitle("POSE, 2023") +
  theme_bw()

##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/pose_df.csv")
write_csv(pose.df, path)

```

#### Pringle Creek, Wise County, TX

nitrate sensor lat-long: 33.37836 -97.78134\
elevation (m): 251.34 tz="US/Central"

###### Load data

```{r - PRIN}
#| output: false
#| message: false

##### Create object for PRIN => Pringle Creek, Wise Co., TX

prin.df <- selectRdata(data=no3_data_sensor, site="PRIN", tz="US/Central", span=2021:2024)

prin_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/PRIN_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Central"))

#tz(prin_light.df$local_datetime) <- "US/Mountain"

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(prin_light.df$local_datetime)
tz(prin.df$local_datetime)

```

```{r summarize prin lightdata}

# Get summed 15 and 60m data for light: 
prin_light.df.15 <- prin_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


prin_light.df.h <- prin_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


```

###### Visualize, select and clean PRIN data

```{r - PRIN visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 3
plottitle <- "PRIN, Mar 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
prin.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle(plottitle) +
  theme_bw()

# prin.df %>%
#   filter(year(model_datetime) == yr) %>%
#   filter(month(model_datetime) == mo) %>%
#   ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
#   # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
#   geom_point() + 
#   geom_line() +
#   ylim(10, 30) +
#   facet_wrap(~Jday) +
#   ggtitle(plottitle) +
#   theme_bw()



prin_dy <- prin.df %>%
  select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=prin_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     PRIN: lots of disturbance, April-May seem to be the best months for the autotrophic cycle (except 2024, where June was *lovely*); maybe a tough sensor placement? Often sudden peaks from ~ 8-noon, centered at 10a: sharper than other sites I've seen

# Jdays: 
##    2021: 181, 184, 186, 188, 234-237, 240-244, 249, 251, 253, 254, 255, 261, 265-269, 294, 295, 304, 318, 319, 324, 343, 344, 355, 356, 357, 

# 2021: maybes: [127-129, 170-171 -MESSY] [185-outliers]

##    2022: 4, 5, 6, 10, 11, 12, 13, 16, 17, 18, 19, 25, 27, 29, 30, 31, 38-41, 44, 45, 61, 68, 74-78, 84-87, 90, 91, 104-107, 110-112, 121, 130-132, 134-140, 182, 304, 305, 306, 310

# 2022-62 has declining Neq throughout day; 97-100(? - slanty baseline; april)]; [186, 187, weird sharp bump up ~ 10a]

##    2023: 55, 71, 72, 75, 77, 84, 85, 86, 88, 90, 94, 95, 96, 97, 100, 102-104, 106-111, 113, 115, 121-126, 137-143, 146-148, 149, 150, 151, 152, 328, 329, 337

# 2024: 48, 61, 69, 71, 72, 73, 74, 80, 95, 97, 118, 139, 140, 141, 142, 144, 145, 147, 159, 160, 161, 165-175, 177, 179


list.21 <- c(181, 184, 186, 188, 234, 235, 236, 237, 240, 241, 242, 243, 244, 249, 251, 253, 254, 255, 261, 265, 266, 267, 268, 269, 294, 295, 304, 318, 319, 324, 343, 344, 355, 356, 357)

list.22 <- c(4, 5, 6, 10, 11, 12, 13, 16, 17, 18, 19, 25, 27, 29, 30, 31, 38, 39, 40, 41, 44, 45, 61, 68, 74, 75, 76, 77, 78, 84, 85, 86, 87, 90, 91, 104, 105, 106, 107, 110, 111, 112, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 182, 304, 305, 306, 310)

list.23 <- c(55, 72, 75, 77, 84, 85, 86, 88, 90, 94, 95, 96, 97, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 113, 115, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 142, 143, 146, 147, 148, 149, 150, 151, 152, 328, 329, 337)

# 2024 
list.24 <- c(48, 71, 72, 73, 74, 80, 95, 97, 139, 140, 141, 142, 144, 145, 147, 159, 160, 161, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179)



# Creating and visualizing dataframes from the selected days - 
#   PRIN looked really ... wobbly and odd, so making sure these seem like reasonable model options

prin.df.21 <- prin.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)

quartz(6.5, 6.5)
prin.df.21 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("PRIN 2021") +
  theme_bw()
  
prin.df.22 <- prin.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

quartz(6.5, 6.5)
prin.df.22 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("PRIN 2022") +
  theme_bw()

prin.df.23 <- prin.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

quartz(6.5, 6.5)
prin.df.23 %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~model_jday) +
  ggtitle("PRIN 2023") +
  theme_bw()

prin.df.24 <- prin.df %>%  
  filter(year(local_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

quartz(6.5, 6.5)
prin.df.24 %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~model_jday) +
  ggtitle("PRIN 2024") +
  theme_bw()

# Check for complete days: should have 96 obs/ day

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- prin.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- prin.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- prin.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- prin.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)
# remove 69 (missing 1:15) and 118 (glitchy stuff)

length(prin.df.21$model_jday)/96 #35
length(prin.df.22$model_jday)/96 #57
length(prin.df.23$model_jday)/96 #48
length(prin.df.24$model_jday)/96 #31

# prin.df.21 %>% count(model_jday) # 35
# prin.df.22 %>% count(model_jday) # 57 (after removing jday 121 because of no3 spikes at end of model day) 
# prin.df.23 %>% count(model_jday) # 48 (after removing jday 71, w. only 92 obs)


##### Combine selected days into 1 df 
prin.df.2124 <- bind_rows(prin.df.21, prin.df.22, prin.df.23, prin.df.24) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)


##### Combine df with sat_light data for the selected model days
prin.wlight.df.2124 <- left_join(x=prin.df.2124,
                                 y=prin_light.df.15, 
                                 by = "local_datetime") 


View(prin.wlight.df.2124)

# # check the 1st day in the df to make sure light joined correctly 
# jday31 <- prin_light.df %>% 
#   filter(year(local_datetime) == 2021) %>%
#   filter(month(local_datetime) == 1) %>% 
#   filter(day(local_datetime) == 31)


# save to keep progress
write_csv(prin.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/PRIN_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# prin.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/PRIN_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

QMfail <- which(prin.wlight.df.2124$rangeFailQM == 1) # none, whew

no3NA <- which(is.na(prin.wlight.df.2124$surfWaterNitrateMean))
no3NA
# 30 NAs:   188   189  7651  7652  8961  8962  8963  8964 10822 10823 10824 10825 11246 12406 12407 12408 12409 12410 12411 12412 13756 13757 13758 13759 14877 15762 15763 15764 15765 15766

# 
# When do these occur? (ID any particularly bad days to remove)
NAdays <- prin.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays 
# 2021: 184(2)
# 2022: 132(2)
# 2023:  72(4), 109(4), 121, 143(7)
# 2024: 72(4), 145, 170(5)


lightNA <- which(is.na(prin.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  ###################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()
# 12406 12407 12408 12409 12410 12411 12412    13756 13757 13758 13759
#    first see where in the curve this gap falls: 
span <- 15755:15770
plot(prin.wlight.df.2124$local_datetime[span], prin.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #nope, the last day it seems not linear... 

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
prin.wlight.df.2124$surfWaterNitrateMean <- na.spline(prin.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill

# re-check NAs
which(is.na(prin.wlight.df.2124$surfWaterNitrateMean)) 
# no NAs remain

# visualize to make sure the spline didn't create weird outliers (esp 2023 and 2024)
yr <- 2024
# mo <- 3
plottitle <- "PRIN, 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
prin.wlight.df.2124 %>%
  filter(year(model_datetime) == yr) %>%
  # filter(month(model_datetime) == mo) %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(5, 30) +
  facet_wrap(~model_jday) +
  ggtitle(plottitle) +
  theme_bw()




N_e <- mean(prin.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #15.12
N_sd <- sd(prin.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #6.05

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
prin.wlight.df.h <- prin.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = prin_light.df.h, by = "local_datetime")

# Mean of selected dataset
N_e <- mean(prin.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #15.13
N_sd <- sd(prin.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #6.06



```

###### Visualize cleaned data

```{r - visualize PRIN clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(prin.wlight.df.h$model_jday)

# big gaps in the middle of the year - things really seemed to wash out then (flashy stream?)

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/prin_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/prin_hourly_clean.csv")
write_csv(prin.wlight.df.2124, path)
write_csv(prin.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# prin.wlight.df.2123 <- read_csv(path)
# prin.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### Red Butte Creek, Salt Lake, UT

nitrate sensor lat-long: 40.78366 -111.79811\
elevation (m): 1689.47 tz="US/Mountain"

```{r - REDB}

##### Create object for REDB => Red Butte Creek, Salt Lake, UT

redb.df <- selectRdata(data=no3_data_sensor, site="REDB", tz="US/Mountain", span=2021:2024)


# redb.df <- no3_data_sensor %>%
#   filter(siteID == "REDB") %>% 
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Mountain"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)

##### Visualize, select and clean REDB data

yr <- 2024
# mo <- 1:2

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
redb.df %>%
  filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
   # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) + 
  ggtitle("REDB, 2023") +
  theme_bw()


##### ID Jdays to save for model



##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/redb_df.csv")
write_csv(redb.df, path)

```

#### Sycamore Creek, Maricopa, AZ

nitrate sensor lat-long: 33.751675 -111.508603 elevation (m): 643 tz="US/Arizona"

###### Load data

```{r - SYCA}
#| output: false
#| message: false

##### Create object for SYCA => Rio Cupeyes, San German Municipio, PR

syca.df <- selectRdata(data=no3_data_sensor, site="SYCA", tz="US/Arizona", span=2021:2024)

syca_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/SYCA_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Arizona"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(syca_light.df$local_datetime)
tz(syca.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime
```


```{r summarize syca lightdata}
# Get summed 15 and 60m data for light: 
syca_light.df.15 <- syca_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


syca_light.df.h <- syca_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 



```

###### Visualize, select and clean SYCA data

```{r - SYCA visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 4
plottitle <- "SYCA, Apr 2024"
# ylim(20,30) for Jan-Jun 21, Jan-Jun 23; (20, 33) for ~ Aug-Dec 2023, Jan- 2024; (17,27) for Jul-Dec 21, most of 2022, Jul 23, Jan- 2024;    : (25,35) for Oct-Dec 22

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
syca.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(5, 15) +
  facet_wrap(~Jday) +
  ggtitle(plottitle) +
  theme_bw()


## Dygraph for interactive chart w slider - meh, doesn't work all that well for my purposes.
# syca_dy <- syca.df %>%
# select(local_datetime, surfWaterNitrateMean)
# 
# dygraph(data=syca_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model
# doing this early this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays

# visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
# SYCA: COMMENTS  Clear diel no3 cycling; pattern shoots UP to pointy peak ~ 5-9a, then drops off sharply. Especially noticeable Feb 2021, March 2022, . 
# No data 2021: Jan, Jun-Dec; 2022: Jan; 2023: Jan (crazy-high data (90-120 umol/L), likely sensor error), Feb, [most of] Mar, Nov, Dec; 2024: Jan, Feb, 
# Apr-Nov 2022 - disturbance, and shifts so pattern peaks in afternoon (~10-17), w. trough in AM (~ 5-10); goes back to afternoon trough in Dec. 2022; same in June 2023

# ID Jdays: 

##    2021: 28, 32, 33, 36, 37, 41, 43, 47, 49, 50-70, 79-81, 87-90, 96-98, 103-109, 111-114, 116, 141, 142

##    2022: 34-46, 49-53, 56-62, 64-71, [72-78 - odd shape and 'nipple' at ~ 6-7:30a; nipple also in 64-71 but less evident], 350-352, 356-360

##    2023: 101-106 (a little nipple-y), 125-129, 132, 138, 139, 143-148, 150, [257, 263, 266, 274, 278, 279, 280, 281, 282, - VERY low (<1) but clear cycles]

# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 64, 97-100, 103-105, [112-116, nipple-y], 119-121, 125-129, 131, 138, 142, 145-147, 150-152, 155, 156


# create objects from selected jdays for each year
# list.21 <- c(28, 32, 33, 36, 37, 41, 43, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 79, 80, 81, 87, 88, 89, 90, 96, 97, 98, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 141, 142)

# FOR WY22 ONLY
# list.21 <- c()  ## NONE

list.22 <- c(34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 350, 351, 352, 356, 357, 358, 359, 360)

list.23 <- c(101, 102, 103, 104, 105, 106, 125, 126, 127, 128, 129, 132, 138, 139, 143, 144, 145, 146, 147, 148, 150, 257, 263, 266, 274, 278, 279, 280, 281, 282)

list.24 <- c(64, 97, 98, 99, 100, 103, 104, 105, 112, 113, 114, 115, 116, 119, 120, 121, 125, 126, 127, 128, 129, 131, 138, 142, 145, 146, 147, 150, 151, 152, 155, 156)

# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)

# No SYCA days in Oct-Dec 2021 (WY 2022) - need to add in days to get > 100
# syca.df.21 <- syca.df %>%
#   filter(year(local_datetime) == 2021) %>%
#   filter(model_jday %in% list.21)

syca.df.22 <- syca.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

syca.df.23 <- syca.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

syca.df.24 <- syca.df %>%  
  filter(year(local_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
# causes of n < 96 are often time change days, or some sensor irregularity

# remove.21 <- syca.df.21 %>% 
#   count(model_jday) %>%
#   filter(n != 96)

remove.22 <- syca.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- syca.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- syca.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)

# All days, all 3 years had 96 obs. 

# Double-check for even days, and get count per df
# length(syca.df.21$model_jday)/96 #54
length(syca.df.22$model_jday)/96 #41
length(syca.df.23$model_jday)/96 #30
length(syca.df.24$model_jday)/96 #32


##### Combine selected days into 1 df, select columns 
syca.df.2224 <- bind_rows(syca.df.22, syca.df.23,syca.df.24) %>%
  mutate(Year = year(model_datetime)) %>%  #changed to be consistent w. model_jday => important in SYCA where there are year-round good days!
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing syca.df.2123 observations by 96 
# XXX for syca


##### Combine df with sat_light data for the selected model days
syca.wlight.df.2224 <- left_join(x=syca.df.2224,
                                 y=syca_light.df, 
                                 by = "local_datetime") 


View(syca.wlight.df.2224)


# check the 1st day in the df to make sure light joined correctly
jday22_28 <- syca_light.df %>%
  filter(year(local_datetime) == 2022) %>%
  filter(month(local_datetime) == 1) %>%
  filter(day(local_datetime) == 28)

View(jday21_28)

# save to keep progress
write_csv(syca.wlight.df.2224,file=here("N_uptake_NEON/data/neon_data_joined/SYCA_wlight_2123_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
syca.wlight.df.2224 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/SYCA_wlight_2224_joined.csv")) %>%
  mutate(local_datetime = with_tz(local_datetime, tzone="US/Arizona"), 
         model_datetime = with_tz())


##############################  Where are the NAs?  ############################

QMfail <- which(syca.wlight.df.2124$rangeFailQM == 1) # none, whew

### Set low/ clearly sensor-error values to NA: 

# First, ID whether there are any measurements <0
sensorfaildays <- syca.wlight.df.2224 %>%
  filter(surfWaterNitrateMean < 0)  ### none! 

sensorflagdays <- syca.wlight.df.2224 %>%
  filter(rangeFailQM == 1)  ### also none!

max(sensorfaildays$surfWaterNitrateMean) #-0.1
min(sensorfaildays$surfWaterNitrateMean) #-1
which(min(sensorfaildays$surfWaterNitrateMean) == -1)

unique(sensorfaildays$yr_jday) #24:  "2021_28" - OK  "2021_32" - kinda low  "2021_33"- OK  "2021_87"  "2021_88"  "2021_89"  "2021_90"  "2021_96"  "2021_97" "2021_98"  "2021_103" "2021_104" "2021_105" "2021_106" "2021_107" "2021_108" "2021_109" "2021_111" "2021_112" "2021_113" "2021_114" "2021_116" "2021_141" "2021_142"

# re-check the images: is this likely to be 0, or is it a sensor blip?  The curves look good, but seems like the sensor is reading low.. check flags

# then change the applicable <0 values to 0
# syca.wlight.df.2123 <- syca.wlight.df.2123 %>%
#   mutate(surfWaterNitrateMean = replace(surfWaterNitrateMean, surfWaterNitrateMean < 0, 0))


no3NA <- which(is.na(syca.wlight.df.2224$surfWaterNitrateMean))
no3NA

# 11 occurrences: 2045 2075 3647 3847 4632 5350 5995 5996 5997 8423 9471


# When do these occur? (ID any particularly bad days to remove)
NAdays <- syca.wlight.df.2224 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  
# 2022: 2022_59 (2), 2022_357, 2022_360
# 2023: 2023_126, 2023_143, 2023_257 (3)
# 2024: 2024_125, 2024_150


# all are missing < 2h of data, which is fine for a gap fill 

lightNA <- which(is.na(syca.wlight.df.2224$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 5830:5855, 40060:40075
# print(syca.wlight.df.2123[5830:5860,])

span <- #4445:4460
plot(syca.wlight.df.2224$local_datetime[span], syca.wlight.df.2224$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable for both gaps


# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
syca.wlight.df.2224$surfWaterNitrateMean <- na.approx(syca.wlight.df.2224$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(syca.wlight.df.2224$surfWaterNitrateMean)) 
# no NAs remain

N_e <- mean(syca.wlight.df.2224$surfWaterNitrateMean, na.rm = TRUE)  #12.08029
N_e
N_sd <- sd(syca.wlight.df.2224$surfWaterNitrateMean, na.rm = TRUE)   #9.644951
N_sd

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
syca.wlight.df.h <- syca.wlight.df.2224 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = syca_light.df.h, by = "local_datetime")


# Mean of selected dataset
N_e <- mean(syca.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #12.0803
N_sd <- sd(syca.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #9.644568
N_sd



```

###### Visualize cleaned data

```{r - visualize SYCA clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(syca.wlight.df.h$model_jday)

clean.syca.plot <- ggplot(syca.wlight.df.h, aes(x=yr_jday, y=surfWaterNitrateMean)) + 
  geom_point() + 
  ggtitle("SYCA - cleaned and filled data") +
  theme_bw()

  quartz(height=6, width=7.5)
  clean.syca.plot

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/syca_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/syca_hourly_clean.csv")
write_csv(syca.wlight.df.2224, path)
write_csv(syca.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# syca.wlight.df.2123 <- read_csv(path)
# syca.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### Teakettle Creek - Watershed 2, Fresno, CA

nitrate sensor lat-long: 36.955228 -119.023553 elevation (m): 2002.75 tz="US/Pacific"

```{r - TECR}

##### Create object for TECR => Teakettle Creek - Watershed 2, Fresno, CA

tecr.df <- selectRdata(data=no3_data_sensor, site="TECR", tz="US/Pacific", span=2021:2024)


# tecr.df <- no3_data_sensor %>%
#   filter(siteID == "TECR") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Pacific"),
#          Jday = yday(local_datetime)) %>%
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean TECR data

yr <- 2021
# mo <- 5:6

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
tecr.df %>%
 filter(year(local_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  # ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,4) +
  # facet_wrap(~Jday) +
  ggtitle("TECR, 2021") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/tecr_df.csv")
write_csv(tecr.df, path)

```

\[Did NOT model Lower Tombigbee River \[TOMB\], Choctaw, AL\]

#### Walker Branch, TN

nitrate sensor lat-long: 35.957219 -84.279206\
elevation (m): 261.76 tz="US/Eastern"

```{r - WALK}

##### Create object for WALK  => Walker Branch, TN

walk.df <- selectRdata(data=no3_data_sensor, site="WALK", tz="US/Eastern", span=2021:2024) ## in Knox Co. = Eastern Time

# walk.df <- no3_data_sensor %>%
#   filter(siteID == "WALK") %>%
#   mutate(local_datetime = with_tz(startDateTime, tzone="US/Eastern"),
#          Jday = yday(local_datetime)) %>%  ## in Knox Co. = Eastern Time
#   filter(year(local_datetime) == 2021:2023)


##### Visualize, select and clean WALK data

yr <- 2023
mo <- 5:6

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
walk.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  #ylim(0,6) +
  facet_wrap(~Jday) +
  ggtitle("WALK, May-Jun 2023") +
  theme_bw()

##### ID Jdays to save for model




##### save site df
path <- here("N_uptake_NEON/data/neon_data_clean/walk_df.csv")
write_csv(walk.df, path)

```

#### West St Louis Creek, Grand, CO

nitrate sensor lat-long: 39.890673 -105.911297 elevation (m): 2900.74 tz="US/Mountain"

###### Load data

```{r - WLOU}
#| output: false
#| message: false

##### Create object for WLOU => West St Louis Creek, Grand, CO

wlou.df <- selectRdata(data=no3_data_sensor, site="WLOU", tz="US/Mountain", span=2021:2024)

wlou_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/WLOU_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))

#tz(wlou_light.df$local_datetime) <- "US/Mountain"

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(wlou_light.df$local_datetime)
tz(wlou.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize wlou lightdata}
# Get summed 15 and 60m data for light: 
wlou_light.df.15 <- wlou_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


wlou_light.df.h <- wlou_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


```

###### Visualize, select and clean WLOU data

```{r - WLOU visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 10

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
wlou.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3.5) +
  facet_wrap(~Jday) +
  ggtitle("WLOU, 2024 10") +
  theme_bw()


wlou_dy <- wlou.df %>%
  select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=wlou_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     WLOU: summer is both more disturbed and appears to have low autotrophic uptake (Deciduous shading? Cottonwoods?)

# Jdays: 
##    2021 - 32, 34:37, 40:59, 68:72, 74, (80:90 if only 1h missing), 95:113, 153:160 :164?), 238, 240, 241, 265, 268:270, 276:278, 285, 287:294, 299:307, 309:311, 313:321; 340:344  

##    2022 - 43, 53:56, 87:107, 116:123, 171, 173, 178, 179, 182:185, 202, 203, 207, 221:224, 235:240, 242, 244:255 (Xed 249 for missingness), 267:273, 279:283, 305:310, 316:318, 340, 343, 360, 363, 364

## 2023: 3, 4, 13, 16, 17, 18, 20, 21, 24, 46, 60, 62, 63, 67, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 85, 88, 98, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 1116, 117, 118, 119, 124, 125, 126, 128, 129, 142, 143, 144, 146, 147, 148, 149, 150, 152, 154, 158, 159, 162, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 227, 228, 232, 233, 269, 270, 271, 286, 287, 288, 290, 291, 292, 321, 322, 327, 328, 352, 353, 354, 355, 357, 358, 359, 365

## 2024: 1, 4, 34, 35, 40, 41, 45, 46, 47, 49, 52, 53, 54, 65, 67, 71, 73, 74, 77, 81, 82, 83, 84, 86, 88, 91, 92, 95, 97, 100, 104, 105, 113, 115, 117, 123, 124, 125, 135, 150, 151, 155, 157, 158, 159, 172, 173, 175, 176, 177, 181, 

# 2024 looks like it has a great string of days ~ Feb-April

# Removed days in 2021 and 22 for either too few or too many measurements/day: these could not be interpolated /filled/ deleted due to the 45-min data structure that proceeded from the resumed measurement time. Noticed this when looking at the Jday count, below. Excising them seemed like the simplest solution. 
# Removed 2021-73 (n=30), 2021-311 (n=34), and 2022-310 (n=33)


# list.21 <- c(32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 68, 69, 70, 71, 74, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 238, 240, 241, 265, 268, 269, 270, 276, 277, 278, 285, 287, 288, 289, 290, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 340, 341, 342, 343, 344)

# WY 2022 only (Oct 1 and later - jday 274)
list.21 <- c(276, 277, 278, 285, 287, 288, 289, 290, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 340, 341, 342, 343, 344)

list.22 <- c(43, 53, 54, 55, 56, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 116, 117, 118, 119, 120, 121, 122, 123, 171, 173, 178, 179, 182, 183, 184, 185, 202, 203, 207, 221, 222, 223, 224, 235, 236, 237, 238, 239, 240, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 267, 268, 269, 270, 271, 272, 273, 279, 280, 281, 282, 283, 305, 306, 307, 308, 310, 316, 317, 318, 340, 343, 360, 363, 364)

list.23 <- c(3, 4, 13, 16, 17, 18, 20, 21, 24, 46, 60, 62, 63, 67, 69, 72, 73, 74, 75, 77, 79, 80, 85, 88, 98, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 1116, 117, 118, 119, 124, 125, 126, 128, 129, 142, 143, 144, 146, 147, 148, 149, 150, 152, 154, 158, 159, 162, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 227, 228, 232, 233, 269, 270, 271, 286, 287, 288, 290, 291, 292, 321, 322, 327, 328, 352, 353, 354, 355, 357, 358, 359, 365)

list.24 <- c(1, 4, 34, 35, 40, 41, 45, 46, 47, 49, 52, 53, 54, 65, 67, 71, 73, 74, 77, 81, 82, 83, 84, 86, 88, 91, 92, 95, 97, 100, 104, 105, 113, 115, 117, 123, 124, 125, 135, 150, 151, 155, 157, 158, 159, 172, 173, 175, 176, 177, 181)

wlou.df.21 <- wlou.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
wlou.df.22 <- wlou.df %>%  
  filter(year(local_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

wlou.df.23 <- wlou.df %>%  
  filter(year(local_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

wlou.df.24 <- wlou.df %>%  
  filter(year(local_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

wlou.df.21 %>% count(model_jday) #37
wlou.df.22 %>% count(model_jday) #92
wlou.df.23 %>% count(model_jday) #111
wlou.df.24 %>% count(model_jday) #51

# check for days where obs != 96 (often leap years, or some sensor irregularity)
remove.21 <- wlou.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- wlou.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- wlou.df.23 %>%
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- wlou.df.24 %>%
  count(model_jday) %>%
  filter(n != 96)


##### Combine selected days into 1 df 
wlou.df.2124 <- bind_rows(wlou.df.21, wlou.df.22, wlou.df.23, wlou.df.24) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days - CLUNKY
#unique(wlou.df.2122$yr_jday) #291


##### Combine df with sat_light data for the selected model days
wlou.wlight.df.2124 <- left_join(x=wlou.df.2124,
                                 y=wlou_light.df.15, 
                                 by = "local_datetime") 


View(wlou.wlight.df.2124)

# # check the 1st day in the df to make sure light joined correctly 
# jday31 <- wlou_light.df %>% 
#   filter(year(local_datetime) == 2021) %>%
#   filter(month(local_datetime) == 1) %>% 
#   filter(day(local_datetime) == 31)


# save to keep progress
write_csv(wlou.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/WLOU_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# wlou.wlight.df.2122 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2122_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

QMfail <- which(wlou.wlight.df.2124$rangeFailQM == 1) # none, whew

no3NA <- which(is.na(wlou.wlight.df.2124$surfWaterNitrateMean))
no3NA
# 64 occurrences: 7623  7624  9740 10299 10300 10301 10302 12120 12697 12698 12699 12700 12701 12702 15340 16766 16767 16768 16769 16770 17737 17833 17929 18025 18121 18217 18313 18409 18505 18601 18697 18793 18889 18985 19081 19177 19273 19369 19465 19561 19657 19753 19849 19945 20041 20137 20233 20329 20425 20521 20617 20674 21644 22020 22021 24247 24561 25068 25282 26822 26824 27016 27017 27018

# When do these occur? (ID any particularly bad days to remove)
NAdays <- wlou.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays 
# 2021: none
# 2022: 202(2), 253, 270(4), 360
# 2023: 16(6), 109, 142(5), 158, 159, 162, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 227, 290, 322(2)
# 2024: 150(2), 155(3)

# 270 is missing 1 hour of data, that's fine for a gap fill. 

lightNA <- which(is.na(wlou.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 10299 10300 10301 10302; 12697 12698 12699 12700 12701 12702;  16766 16767 16768 16769 16770;  27016 27017 27018 
span <- 27010:27023
plot(wlou.wlight.df.2124$local_datetime[span], wlou.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #linear could work, spline may better represent actual dynamics

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
wlou.wlight.df.2124$surfWaterNitrateMean <- na.spline(wlou.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill

# re-check NAs - none remain
which(is.na(wlou.wlight.df.2124$surfWaterNitrateMean)) 

# visualize data again to make sure splining didn't do odd things... 

yr <- 2024
mo <- 1:3

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
# wlou.wlight.df.2124 %>%
wlou.df.24 %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3.5) +
  facet_wrap(~Jday) +
  ggtitle("WLOU, 2024") +
  theme_bw()


N_e <- mean(wlou.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #3.39
N_sd <- sd(wlou.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #1.604

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
wlou.wlight.df.h <- wlou.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = wlou_light.df.h, by = "local_datetime")


# Mean of selected dataset
N_e <- mean(wlou.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #3.39
N_sd <- sd(wlou.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #1.605



```

###### Visualize cleaned data

```{r - visualize WLOU clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(wlou.wlight.df.h$model_jday)



```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/wlou_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/wlou_hourly_clean.csv")
write_csv(wlou.wlight.df.2124, path)
write_csv(wlou.wlight.df.h, path_h)

##### Reload data-in-progress as needed
# wlou.wlight.df.2122 <- read_csv(path)
# wlou.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```
