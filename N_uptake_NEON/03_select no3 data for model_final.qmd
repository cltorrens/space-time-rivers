---
title: "02_select and visualize NEON data for model"
author: "Christa Torrens"
format: html
editor: visual
---

## Selecting and visualizing NEON NO3 data for the stan model

The purpose of this script is to load the NEON nitrate Rdata, separate it by site, and then identify at least 100 complete "good" days per site, to inform the model. "Good" days = complete days where the diel signal of autotrophic nitrate uptake is clearly visible and not affected by, e.g., hydrology or other physical processes. When there are gaps in the data, we will fill up to 2-hour gaps using the zoo() package, linear method. If there are gaps \> 2 hours, OR multiple smaller gaps, the day will be discarded.

First load the required packages

### Loading required packages

Add these before knitting:

```{r loading packages}
#| warning: false
#| output: false

# load packages
library(scales)
library(tidyverse) # includes magrittr, as part of dplyr
library(lubridate)
library(rstan)
library(tidybayes)
library(GGally) # adds functions to ggplot()
# library(shinystan)
library(zoo)
library(neonUtilities)
library(ggpubr) #publication-ready graphs
library(brms)
library(here) # allows project-based file paths
library(pracma) # for 1 type of light AUC calcs
library(dygraphs) # creates interactive ts graphs

# make sure the working directory is set to the project level
setwd(here())

```

### Functions

Define any functions

```{r - functions}

selectRdata <- function(data, site, tz, span) {
  data %>%
  filter(siteID == site) %>%
  mutate(local_datetime = with_tz(startDateTime, tzone=tz),
         Jday = yday(local_datetime),
         model_datetime = local_datetime - hours(4), 
         model_jday = yday(model_datetime)) %>%
   filter(year(local_datetime) %in% span)
}

# data = the name of the NO3 Rdata 
# site = the site ID from the Rdata, in quotes " "
# tz = the desired time zone for the site, in quotes " " 
# span = the year or years to filter for in the Rdata. 

# NB: The current dataset (as of Feb 2025) runs from Dec 2016-Dec 2024; QA/QC'd data w good discharge = Jan 2021-June 2023


```

Then load the NEON NO3 Rdata

### Loading the NEON Rdata

```{r load NEON NO3 data}
#| output: false
#| message: false

load(here("N_uptake_NEON/data/neon_data_derived/no3_dataset.Rdata")) 
#no3_data_sensor is the object name

# View(no3_data_sensor)
# unique(no3_data_sensor$siteID)   

# CURRENT DATA FILE:
# ARIK, BIGC, BLDE, BLUE, BLWA, CARI, COMO, CUPE, FLNT, GUIL, HOPB, KING, LECO, MART, OKSR, POSE, PRIN, REDB, SYCA, TECR, WALK, WLOU

# ORIGINAL FOUR:"KING" "WALK" "BIGC" "CARI"

# Not pulled:Lewis Run [LEWI], Clarke, VA; Mayfield Creek [MAYF], Bibb, AL; McDiffett Creek [MCDI], Wabaunsee, KS; McRae Creek [MCRA], Linn, OR; Tombigbee River [TOMB], Choctaw, AL

```

### Viewing, selecting, and saving data by site

For each site: \* Filter by site ID and set appropriate time zone for local time (default for NEON is UTC)

-   Use OlsonNames() to check for accurate timezone names: "US/Eastern" "US/Central" "US/Mountain" "US/Pacific" "US/Alaska" "US/Arizona" "US/Hawaii" "America/Puerto_Rico"

-   Select the days to use in the model: create 1 dataframe per site, across mulitple years. Aim for at least 100 full days with clear diel no3 swings. It may be easiest to explore and select data by year... Try it by site and see how it goes.

-   Per Bobby Hensley, data from 2021 on will have the best discharge data (Q and O2 data prior to 2021 are 'shoddy'). Currently focusing on 2021-2023 data.

-   2024 Q data has been QA/QC'd as of March 2025

-   NB: for 2024 NO3 data, Jan-Jun data are QA/QC'd and July-Dec data are still provisional (as of 3/06/2025)

Site descriptions: https://www.neonscience.org/field-sites/explore-field-sites

Individual sites follow this pattern: BIGC: https://www.neonscience.org/field-sites/bigc CARI: https://www.neonscience.org/field-sites/cari KING: https://www.neonscience.org/field-sites/king WALK: https://www.neonscience.org/field-sites/walk (etc.)

#### Upper Big Creek, Fresno, CA

nitrate sensor lat-long: 37.057672 -119.255375\
elevation (m): 1131.24 tz="US/Pacific"

"overhang" sensor location: lat-long: 37.057515 -119.255046 elevation (m): 1127.43

###### Load data

```{r - BIGC}
#| output: false
#| message: false

##### Create object for BIGC => West St Louis Creek, Grand, CO

bigc.df <- selectRdata(data=no3_data_sensor, site="BIGC", tz="US/Pacific", span=2021:2024)

bigc_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/BIGC_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Pacific"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(bigc_light.df$local_datetime)
tz(bigc.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize bigc lightdata}

# Get summed 15 and 60m data for light:

bigc_light.df.15 <- bigc_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 

bigc_light.df.h <- bigc_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 

```

###### Visualize, select and clean BIGC data

```{r - BIGC visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 9
plottitle <- "BIGC, 9 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
bigc.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


# bigc_dy <- bigc.df %>%
  # select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=bigc_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     BIGC: COMMENTS?

# for WY22 only
list.21 <- c(274, 275, 276, 338, 339, 340)

list.22 <- c(22, 23, 24, 25, 26, 27, 28, 38, 41, 42, 48, 49, 51, 58, 59, 68, 69, 70, 82, 83, 84, 85, 91, 92, 93, 94, 95, 100, 103, 104, 105, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 155, 160, 170, 195, 196, 204, 205, 206, 221, 222, 230, 231, 232, 233, 234, 237, 238, 239, 244, 247, 251, 252, 257, 258, 259, 266, 267, 268)

list.23 <- c(33, 34, 41, 43, 46, 47, 48, 49, 50, 51, 91, 92, 96, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 313, 314, 315, 317, 318, 328, 329, 330, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 350)

list.24 <- c(27, 28, 29, 30, 74, 75, 76, 80, 81, 93, 94, 99, 100, 138, 142, 143, 146, 153, 154, 155, 168, 183, 186, 187, 189, 190, 198, 199, 200, 205, 207, 209, 216, 217, 222, 223, 224, 235, 236, 237, 241, 242, 245, 246, 247, 248, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 264, 265, 266, 267, 268, 270, 271, 272)


# remove these: 2023:44, 101, 325, 326, 327; 2024: 82, 211, 262 - 
# AND these days that didn't model well (none from 2023) - 12/31/25: 
# 2021: 337
# 2022: 052
# 2024: 025, 026, 031, 137, 163, 184, 185, 203, 210, 212 


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
bigc.df.21 <- bigc.df %>%
  filter(year(model_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
bigc.df.22 <- bigc.df %>%  
  filter(year(model_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

bigc.df.23 <- bigc.df %>%  
  filter(year(model_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

bigc.df.24 <- bigc.df %>%  
  filter(year(model_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
bigc.df.21 %>% count(model_jday) #6
bigc.df.22 %>% count(model_jday) #85, after removing 56, 71 and 72 (92 obs each)
bigc.df.23 %>% count(model_jday) #48, after removing 308 (100 obs)
bigc.df.24 %>% count(model_jday) #65

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- bigc.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- bigc.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- bigc.df.23 %>%
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- bigc.df.24 %>%
  count(model_jday) %>%
  filter(n != 96)

# View days with alternate n values
# bigc22_310 <- bigc.df.22 %>% filter(model_jday == 310)
# bigc21_310 <- bigc.df.22 %>% filter(model_jday == 310)
# View(bigc73)
# View(bigc310)
# 
# bigc310 <- bigc.df.22 %>% filter(Jday == 310)
# View(bigc310)


##### Combine selected days into 1 df, select columns 
bigc.df.2124 <- bind_rows(bigc.df.21, bigc.df.22, bigc.df.23, bigc.df.24) %>%
  # dplyr::filter(model_datetime >= "2021-10-01 00:00:00") %>%  # already done in date selection
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing bigc.df.2124 observations by 96 
# 173 for bigc WY 22-24

##### Combine df with sat_light data for the selected model days
bigc.wlight.df.2124 <- left_join(x=bigc.df.2124,
                                 y=bigc_light.df.15, 
                                 by = "local_datetime") 


View(bigc.wlight.df.2124)

### ADD IN Q, TOO



# check the 1st day in the df to make sure light joined correctly
jday21_274 <- bigc_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 10) %>%
  filter(day(local_datetime) == 01)


# save to keep progress
write_csv(bigc.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/BIGC_wlight_2124_joined.csv"))


```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# bigc.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/BIGC_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Pacific"))


##############################  Where are the NAs?  ############################

# first remove the subzero outliers I saw
bigc.wlight.df.2124 <- bigc.wlight.df.2124 %>%
  mutate(surfWaterNitrateMean = ifelse(surfWaterNitrateMean < 0, NA, surfWaterNitrateMean))

no3NA <- which(is.na(bigc.wlight.df.2124$surfWaterNitrateMean))
no3NA

# 22 NAS:   [1]  2236  5727  9617  9632  9633 10876 11169 12657 14522 14523 14524 14525 15328 15786 15866 15867 15868 15869 17130 17969 17970 17971

QMfail <- which(bigc.wlight.df.2124$rangeFailQM == 1) # none, whew

# When do these occur? (ID any particularly bad days to remove)
NAdays <- bigc.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  
# 2021: none (!)
# 2022: 70, 141
# 2023: 51(3), 304, 307, 341
# 2024: 100(4), 168, 190, 198(4), 237, 253(3)

# removed days w/ > 2h gaps (2024: 238, 239, 249) from the lists and recompiled
# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(bigc.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew



##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

# 15212 15213 15214          15206:15222 linear
# 15578 15579 15580 15581    15570:15588 linear OK, spline better
# 17306 17307 17308 17309    17300:17317 linear OK, spline better
# 18114 18115 18116 18117    18109:18123 linear OK, spline better
# 19793 19794 19795          19785:19803 linear

#    first see where in the curve this gap falls: 
span <- 19785:19803
plot(bigc.wlight.df.2124$local_datetime[span], bigc.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill (2h)
bigc.wlight.df.2124$surfWaterNitrateMean <- na.spline(bigc.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill 

# re-check NAs
which(is.na(bigc.wlight.df.2124$surfWaterNitrateMean)) 
# no NAs remain

# Re-visualize data to check for odd spline effects

yr <- 2024
mo <- 6:9
plottitle <- "BIGC, 6-9 2024"

clean.bigc.plot <- bigc.wlight.df.2124 %>%
  filter(year(model_datetime) == yr) %>%
  filter(month(model_datetime) == mo) %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3) +
  facet_wrap(~model_jday) + 
  ggtitle(plottitle) +
  theme_bw()

quartz(height=6, width=7.5)
clean.bigc.plot
# spline worked, but ID'd some additional days to remove: removed from lists and recompiled

N_e <- mean(bigc.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #1.68
N_sd <- sd(bigc.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #0.65

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
bigc.wlight.df.h <- bigc.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = bigc_light.df.h, by = "local_datetime")


# cari.wlight.df.2124.h <- cari.df.2124 %>%
#   filter(minute(local_datetime)==0) %>%
#   left_join(y = cari_light.df.h, by = "local_datetime") %>%
#   dplyr::select(-startDateTime) %>%
#   dplyr::select(1:3, PAR, everything())

# Mean of selected dataset
N_e <- mean(bigc.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #1.68
N_sd <- sd(bigc.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #0.65

# checking the other light data... 
lightNA <- which(is.na(bigc.wlight.df.h$GHI_wm2))

```

###### Visualize cleaned data

```{r - visualize BIGC clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(bigc.wlight.df.h$model_jday)

# yr <- 2022
# mo <- 1:4
# plottitle <- "BIGC, 9 2024"
# 
# clean.bigc.plot <- bigc.wlight.df.h %>%
#   filter(year(model_datetime) == yr) %>%
#   filter(month(model_datetime) == mo) %>%
#   ggplot(aes(x=yr_jday, y=surfWaterNitrateMean)) + 
#   geom_point() + 
#   ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
#   # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
#   geom_point() + 
#   geom_line() +
#   # ylim(0,3) +
#   facet_wrap(~model_jday) + 
#   ggtitle(plottitle) +
#   theme_bw()
# 
# quartz(height=6, width=7.5)
# clean.bigc.plot
# 
# 

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/bigc_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/bigc_hourly_clean.csv")
write_csv(bigc.wlight.df.2124, path)
write_csv(bigc.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# bigc.wlight.df.2124 <- read_csv(path)
# bigc.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))
```

#### Caribou Creek, Fairbanks North Star, AK

nitrate sensor lat-long: 65.153076 -147.502004 elevation (m): 225.41 tz="US/Alaska"

###### Load data

```{r - CARI}
#| output: false
#| message: false

##### Create object for CARI => West St Louis Creek, Grand, CO

cari.df <- selectRdata(data=no3_data_sensor, site="CARI", tz="US/Alaska", span=2021:2024) %>%
  mutate(model_datetime = local_datetime - hours(2),  # adjusting model dates because #midsummer days start 2:45a, end 1a the next day; 2-hour offset ensures the start of the day is in darkness
         model_jday = yday(model_datetime))

# needed to reset Jday and model_jday values for some reason; they were not matching the actual jday and model jday.
cari_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/CARI_neonlight05m_all.csv")) %>%
  mutate(local_datetime = with_tz(startDateTime, tz="US/Alaska")) %>%
  dplyr::select(local_datetime, PAR, startDateTime)

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(cari_light.df$local_datetime)
tz(cari.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize cari lightdata}

# First, check and clean if needed (NEON data):
cari_light <- ggplot(data = cari_light.df, aes(x=local_datetime, y=PAR)) + 
  geom_point() + 
  labs(title = "Caribou Creek light", 
       xlab = "datetime", 
       ylab = "PAR") + 
  theme_bw()

cari_light
ggplotly(cari_light)

# 9/12/2023 clip 11:15-11:40, linear fill
# PAR < 0 == 0

cari_light.df <- cari_light.df %>%
  mutate(
    PAR = if_else(
      local_datetime >= ymd_hm("2023-09-12 11:10", tz = "US/Alaska") &
      local_datetime <= ymd_hm("2023-09-12 12:10", tz = "US/Alaska") &
      PAR > 1180, 1150, PAR
      )
  )

which(is.na(cari_light.df$PAR))

# AVOID 4/29/24, jd 120 => sensor glitch



# Get summed 15 and 60m data for light: 
cari_light.df.15 <- cari_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes"), 
         startDateTime = ceiling_date(startDateTime, unit = "15minutes")) %>%
  group_by(local_datetime, startDateTime) %>%
  summarise(PAR = sum(PAR, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(PAR = if_else(PAR < 0, 0, PAR), 
         PAR = if_else(lag(PAR) == 0 & lead(PAR) == 0, 0, PAR))
 

cari_light.df.h <- cari_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour"), 
         startDateTime = ceiling_date(startDateTime, unit = "hour")) %>%
  group_by(local_datetime, startDateTime) %>%
  summarise(PAR = sum(PAR, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(PAR = if_else(PAR < 0, 0, PAR), 
         PAR = if_else(lag(PAR) == 0 & lead(PAR) == 0, 0, PAR))

na15 <- which(is.na(cari_light.df.15$PAR)) # none
na60 <- which(is.na(cari_light.df.h$PAR)) # none

cari_light.15 <- ggplot(data = cari_light.df.15, aes(x=local_datetime, y=PAR)) + 
  geom_point() + 
  labs(title = "Caribou Creek light", 
       xlab = "datetime", 
       ylab = "PAR") + 
  theme_bw()

cari_light.15
ggplotly(cari_light.15)

```

###### Visualize, select and clean CARI data

```{r - CARI visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "CARI, June 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
cari.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(22,30) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


# cari_dy <- cari.df %>%
  # select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
# dygraph(data=cari_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     CARI: COMMENTS - Low appears to be ~ 8-10p (!!) in May,  - and that *is* local time. Daylight hours = 5:15a-10:20p in early May, 2:45a-25:00a (1a next day) mid-June...

#########   CARI MODEL DAY STARTS AT 2A

## AVOID 120-2024 - light sensor errors (removed from list)
## REMOVE additional days that did not model well (12/31/25): 
    # 2021, 2023: none
    # 2022: 139, 140, 141, 142, 144
    # 2024: 113, 123, 124, 137, 138, 139, 140  

# for WY22 only
list.21 <- c(274, 275, 276, 277)

list.22 <- c(130, 131, 135, 136, 137, 138, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 169, 170, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 186, 188, 189, 190, 194, 195, 198, 199, 202, 203, 204, 205, 208, 209, 210, 211, 212, 215, 216, 217, 218, 223, 224, 225, 226, 236, 237, 238, 239, 240, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282)


list.23 <- c(132, 133, 134, 139, 140, 141, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213,  214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 252, 253, 254, 256, 257, 258, 259, 263, 264, 265, 266, 267, 268, 269, 270, 271, 274, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 287, 288, 290, 291)

# 2024
list.24 <- c(111, 112, 121, 122, 125, 126, 141, 142, 148, 149, 153, 154, 155, 156, 160, 161, 162, 163, 172, 173)  # 28d, ending on Sept 30, 2024  ... but model day 274 is incomplete, so removing


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
cari.df.21 <- cari.df %>%
  filter(year(model_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
cari.df.22 <- cari.df %>%  
  filter(year(model_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

cari.df.23 <- cari.df %>%
  filter(year(model_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

cari.df.24 <- cari.df %>%
  filter(year(model_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
cari.df.21 %>% count(model_jday) # 4
cari.df.22 %>% count(model_jday) # 102
cari.df.23 %>% count(model_jday) # 91
cari.df.24 %>% count(model_jday) # 20

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- cari.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- cari.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- cari.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- cari.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)

# View days with alternate n values
# cari22_310 <- cari.df.22 %>% filter(model_jday == 310)
# cari21_310 <- cari.df.22 %>% filter(model_jday == 310)
# View(cari73)
# View(cari310)
# 
# cari310 <- cari.df.22 %>% filter(Jday == 310)
# View(cari310)


##### Combine selected days into 1 df, select columns 
cari.df.2124 <- bind_rows(cari.df.21, cari.df.22, cari.df.23, cari.df.24) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing cari.df.2124 observations by 96 
# 229 for cari



#### Combine df with sat_light data for the selected model days
cari.wlight.df.2124 <- left_join(x=cari.df.2124,
                                 y=cari_light.df.15, 
                                 by = "local_datetime") %>%
  dplyr::select(-startDateTime)


View(cari.wlight.df.2124)

### ADD IN Q, TOO

# check the 1st day in the df to make sure light joined correctly
jday21_274 <- cari_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 10) %>%
  filter(day(local_datetime) == 01)

### Save the 15-min NO3 df
write_csv(cari.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/CARI_wlight_2124.csv"))


```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# cari.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/CARI_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Alaska"))


##############################  Where are the NAs?  ############################

no3NA <- which(is.na(cari.wlight.df.2124$surfWaterNitrateMean))
no3NA

# 29 occurrences:  815  1069  4888  4889  4890  4891  9465  9690 10502 10503 10504 11194 13446 13667 13668 13669 13670 13671 13954 14271 15982 17222 17223 17224 17225 17226 17227 18283 19770

# When do these occur? (ID any particularly bad days to remove)
NAdays <- cari.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  # 2022: 137, 146, 202(4), 275, 277,  
        # 2023: 139(3), 162, 196, 198(5), 201, 204, 252, 269(6), 283
        # 2024: 148

# all are missing <= 1.5h of data, which is fine for a gap fill 

# lightNA <- which(is.na(cari.wlight.df.2123$PARMean))
# lightNA  
# none, whew

QMfail <- which(cari.wlight.df.2124$rangeFailQM == 1) # none - whew!

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 
span <- 15945:15985
plot(cari.wlight.df.2124$local_datetime[span], cari.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable

# Then fill the hourly data
maxgap <- 8  # set the maximum gap for zoo() to fill; 2h or less
cari.wlight.df.2124$surfWaterNitrateMean <- na.approx(cari.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs - no NAs remain
which(is.na(cari.wlight.df.2124$surfWaterNitrateMean)) 


N_e <- mean(cari.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #27.74
N_sd <- sd(cari.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #4.51

# ## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
# cari.wlight.df.h <- cari.wlight.df.2124 %>%
#   filter(minute(local_datetime) == 0) 
# # Mean of selected dataset
# N_e <- mean(cari.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #1.811583
# N_sd <- sd(cari.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #0.7408184
# 


# convert to hourly NO3 df
cari.wlight.df.2124.h <- cari.df.2124 %>%
  filter(minute(local_datetime)==0) %>%
  left_join(y = cari_light.df.h, by = "local_datetime") %>%
  dplyr::select(-startDateTime) %>%
  dplyr::select(1:3, PAR, everything())


# View(cari.df.2124.h)

View(cari.wlight.df.2124.h)

# save to keep progress
# write_csv(cari.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/CARI_wlight_2124_joined.csv"))


```

###### Visualize cleaned data

```{r - visualize CARI clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(cari.wlight.df.2124.h$model_jday)

#good distribution from ~ April-October

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/cari_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/cari_hourly_clean.csv")
write_csv(cari.wlight.df.2124, path)
write_csv(cari.wlight.df.2124.h, path_h)


##### Reload data-in-progress as needed
# cari.wlight.df.2124 <- read_csv(path)
# cari.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### Rio Cupeyes, San German Municipio, PR

nitrate sensor lat-long: 18.110265 -66.986411\
elevation (m): 149.9 tz = "America/Puerto_Rico"

###### Load data

```{r - CUPE}
#| output: false
#| message: false

##### Create object for CUPE => Rio Cupeyes, San German Municipio, PR

cupe.df <- selectRdata(data=no3_data_sensor, site="CUPE", tz="America/Puerto_Rico", span=2021:2024)

cupe_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/CUPE_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="America/Puerto_Rico"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(cupe_light.df$local_datetime)
tz(cupe.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize cupe lightdata}

# Get summed 15 and 60m data for light: 
cupe_light.df.15 <- cupe_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


cupe_light.df.h <- cupe_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
 summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


```

###### Visualize, select and clean CUPE data

```{r - CUPE visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 6
plottitle <- "CUPE, Jun 2024"
# ylim(20,30) for Jan-Jun 21, Jan-Jun 23; (20, 33) for ~ Aug-Dec 2023, Jan- 2024; (17,27) for Jul-Dec 21, most of 2022, Jul 23, Jan- 2024;    : (25,35) for Oct-Dec 22

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
cupe.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(17, 27) +
  facet_wrap(~Jday) + 
  ggtitle(plottitle) +
  theme_bw()


## Dygraph for interactive chart w slider - meh, doesn't work all that well for my purposes.
# cupe_dy <- cupe.df %>%
# select(local_datetime, surfWaterNitrateMean)
# 
# dygraph(data=cupe_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model
# doing this early this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays

# visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
# CUPE: COMMENTS?  High NO3-N (20-35 range), very clear signals unless the data is disrupted. Several extended (hydrologic?) issues, especially in 2022. TONS of days selected. 


# ID Jdays: 

##    2021: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, [52, 53 - odd shapes], 54, 55, 60, 61, 62, 63, 63, 65, 66, 68, 69, 72, 73, 74, 75, 91, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 120, [128 - slanted bseline], 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 148, 149, 150, 151, 154, 155, 156, 158, 162, 163, 164, 165, 166, 169, 170, 171, 179, 180, 185, 186, 187, 188, 189, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 210, 211, 212, 215, 216, 217, 221, 222, 223, 225, 226, 229, 232, 239, 240, 241, 242, 244, 246, 247, 281, 282, 283, 285, [286 - lower ampl], 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364

##    2022: 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, [141 - slight wobble], 149, 150, 155, 156, 157, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 184, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, [221, 222, 238, 239, 240, 249, 251, 252, 258, 293 - low ampl - don't use unless testing something later] 298, 321, 327, 328, 329, 330, 331,  - mb include even tho relatively low?], 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 352, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362 

##    2023: 1, 2, 3, 4, 5, 6, 9, 20, 21, 25, 26, 27, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 70, 71, 72, 77, 78, 79, 85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102, 111, 112, 113, 115, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 182, 183, 184, 186, 187, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 236, 245, 246, 249, 250, 257, 270, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 301, 302, 303, 304, 309, 310, 311, 312, 318, 319, 321, 322, 323, 326, 327, 328, 329, [335, 336, 338, 339, 340, 341, 342, 343, 346, 347, may be too low... ], 351, 352, 535, 356, 357, 358, 359, 362, 363, 364, 365


# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 1, 2, 3, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 26, 27, 28, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 71, 72, 76, 77, 79, 86, 87, 93, 94, 97, 98, 99, 100, 101, 105, 106, 107, 109, [125 - low?], 126, 140, 141, 142, 143, 144, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 171, 177, 178, [182 - partial final day in June bc of model_day use]

# create objects from selected jdays for each year
# list.21 <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 60, 61, 62, 63, 63, 65, 66, 68, 69, 72, 73, 74, 75, 91, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 120, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 148, 149, 150, 151, 154, 155, 156, 158, 162, 163, 164, 165, 166, 169, 170, 171, 179, 180, 185, 186, 187, 188, 189, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 210, 211, 212, 215, 216, 217, 221, 222, 223, 225, 226, 229, 232, 239, 240, 241, 242, 244, 246, 247, 281, 282, 283, 285, 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364)

## Remove a few days due to sensor glitches/ modeling weirdness: 2022: 298 (sensor issue), 354 (high K and U, glitchy fit); 2023: 066 (sensor issue)


# FOR WY 22 ONLY
list.21 <- c(281, 282, 283, 285, 287, 295, 296, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 323, 324, 325, 335, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364)

list.22 <- c(14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 38, 39, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 149, 150, 155, 156, 157, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 184, 187, 188, 189, 192, 193, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, 321, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362)

list.23 <- c(1, 2, 3, 4, 5, 6, 9, 20, 21, 25, 26, 27, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 70, 71, 72, 77, 78, 79, 85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102, 111, 112, 113, 115, 119, 120, 121, 122, 126, 127, 128, 129, 130, 134, 135, 136, 142, 143, 144, 145, 146, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 182, 183, 184, 186, 187, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 236, 245, 246, 249, 250, 257, 270, 274, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 301, 302, 303, 304, 309, 310, 311, 312, 318, 319, 321, 322, 323, 326, 327, 328, 329, 351, 352, 535, 356, 357, 358, 359, 362, 363, 364, 365)


list.24 <- c(1, 2, 3, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 26, 27, 28, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 71, 72, 76, 77, 79, 86, 87, 93, 94, 97, 98, 99, 100, 101, 105, 106, 107, 109, 125, 126, 140, 141, 142, 143, 144, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 171)


# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)
cupe.df.21 <- cupe.df %>%
  filter(year(model_datetime) == 2021) %>%     # changed all to model_datetime because it makes a difference here: because days include 12/31 and 1/1/, having the year and jday on the different timescales didn't work here. There were fragments of days. 
  filter(model_jday %in% list.21)
  
cupe.df.22 <- cupe.df %>%  
  filter(year(model_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

cupe.df.23 <- cupe.df %>%  
  filter(year(model_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

cupe.df.24 <- cupe.df %>%  
  filter(year(model_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
cupe.df.21 %>% count(model_jday) #41
cupe.df.22 %>% count(model_jday) #130
cupe.df.23 %>% count(model_jday) #179
cupe.df.24 %>% count(model_jday) #70

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- cupe.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- cupe.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- cupe.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- cupe.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)

# All days, all 3 years had 96 obs. 

# View days with alternate n values
# cupe22_310 <- cupe.df.22 %>% filter(model_jday == 310)
# cupe21_310 <- cupe.df.22 %>% filter(model_jday == 310)
# View(cupe73)
# View(cupe310)
# 
# cupe310 <- cupe.df.22 %>% filter(Jday == 310)
# View(cupe310)


##### Combine selected days into 1 df, select columns 
cupe.df.2124 <- bind_rows(cupe.df.21, cupe.df.22, cupe.df.23, cupe.df.24) %>%
  mutate(Year = year(model_datetime)) %>%  #changed to be consistent w. model_jday => important in CUPE where there are year-round good days!
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing cupe.df.2123 observations by 96 
# 500 for cupe


##### Combine df with sat_light data for the selected model days
cupe.wlight.df.2124 <- left_join(x=cupe.df.2124,
                                 y=cupe_light.df.15, 
                                 by = "local_datetime") 


View(cupe.wlight.df.2124)

# plot(x= cupe.wlight.df.2124$)
# check the 1st day in the df to make sure light joined correctly
jday21_01 <- cupe_light.df %>%
  filter(year(local_datetime) == 2021) %>%
  filter(month(local_datetime) == 10) %>%
  filter(day(local_datetime) == 1)

View(jday21_01)

# save to keep progress
write_csv(cupe.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/CUPE_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# cupe.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="America/Puerto_Rico"))


##############################  Where are the NAs?  ############################

QMfail <- which(cupe.wlight.df.2124$rangeFailQM == 1) # none, whew

### Set low/ clearly sensor-error values to NA: 

# First, ID whether there are any
sensorfaildays <- cupe.wlight.df.2124 %>%
  filter(surfWaterNitrateMean < 10)  # all are less than 5

# then change the values to NA
cupe.wlight.df.2124 <- cupe.wlight.df.2124 %>%
  mutate(surfWaterNitrateMean = replace(surfWaterNitrateMean, surfWaterNitrateMean < 5, NA))


no3NA <- which(is.na(cupe.wlight.df.2124$surfWaterNitrateMean))
no3NA

# 72 occurrences: 307   308  1853  1854  1855  1876  7031  7032  7215  7216  7228  7597 10096 10330 12401 13842 13844 13845 13846 13847 13848 14611 14612 14613 15377 15378 16241 16242 17105 17416 17510 17511 17886 18557 22099 23346 24792 24793 25649 25650 25651 25652 25653 26418 27856 27857 29395 29396 29397 29660 30083 30451 30452 31698 31699 32758 32759 32761 33847 34179 35569 38872 38981 38984 38985 39001 39035 39045 39057 39096 39142 39599



# When do these occur? (ID any particularly bad days to remove)
NAdays <- cupe.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  
# 2021: 285(2), 312(4)
# 2022: 101(2), 103(3), 110, 156, 165, 201, 332(6), 340(3), 349(2), 361(2)
# 2023: 20, 26, 27(2), 31, 45, 166(2), 184(5), 200, 221(2), 249(3), 257, 280, 284(2), 312(2), 352(3)
# 2024: 3, 13, 40, 143, 149(7), 150(2), 157

# all are missing < 1h of data, which is fine for a gap fill 

lightNA <- which(is.na(cupe.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 5830:5855, 40060:40075
# print(cupe.wlight.df.2123[5830:5860,])

span <- 40060:40075
plot(cupe.wlight.df.2124$local_datetime[span], cupe.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable for both gaps


# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
cupe.wlight.df.2124$surfWaterNitrateMean <- na.approx(cupe.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(cupe.wlight.df.2124$surfWaterNitrateMean)) 
# no NAs remain

N_e <- mean(cupe.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #24.52
N_e
N_sd <- sd(cupe.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #2.86 
N_sd

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
cupe.wlight.df.h <- cupe.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = cupe_light.df.h, by = "local_datetime")

# Mean of hourly dataset
N_e <- mean(cupe.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #24.52
N_e
N_sd <- sd(cupe.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #2.86
N_sd



```

###### Visualize cleaned data

```{r - visualize CUPE clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(cupe.wlight.df.h$model_jday)

clean.cupe.plot <- ggplot(cupe.wlight.df.h, aes(x=yr_jday, y=surfWaterNitrateMean)) + 
  geom_point() + 
  ggtitle("CUPE - cleaned and filled data") +
  theme_bw()

  quartz(height=6, width=7.5)
  clean.cupe.plot

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/cupe_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/cupe_hourly_clean.csv")
write_csv(cupe.wlight.df.2124, path)
write_csv(cupe.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# cupe.wlight.df.2124<- read_csv(path)
# cupe.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### Pringle Creek, Wise County, TX

nitrate sensor lat-long: 33.37836 -97.78134\
elevation (m): 251.34 tz="US/Central"

###### Load data

```{r - PRIN}
#| output: false
#| message: false

##### Create object for PRIN => Pringle Creek, Wise Co., TX

prin.df <- selectRdata(data=no3_data_sensor, site="PRIN", tz="US/Central", span=2021:2024)

prin_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/PRIN_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Central"))

#tz(prin_light.df$local_datetime) <- "US/Mountain"

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(prin_light.df$local_datetime)
tz(prin.df$local_datetime)

```

```{r summarize prin lightdata}

# Get summed 15 and 60m data for light: 
prin_light.df.15 <- prin_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


prin_light.df.h <- prin_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


```

###### Visualize, select and clean PRIN data

```{r - PRIN visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 3
plottitle <- "PRIN, Mar 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
prin.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle(plottitle) +
  theme_bw()

# prin.df %>%
#   filter(year(model_datetime) == yr) %>%
#   filter(month(model_datetime) == mo) %>%
#   ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
#   # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
#   geom_point() + 
#   geom_line() +
#   ylim(10, 30) +
#   facet_wrap(~Jday) +
#   ggtitle(plottitle) +
#   theme_bw()



prin_dy <- prin.df %>%
  select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=prin_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     PRIN: lots of disturbance, April-May seem to be the best months for the autotrophic cycle (except 2024, where June was *lovely*); maybe a tough sensor placement? Often sudden peaks from ~ 8-noon, centered at 10a: sharper than other sites I've seen

# Jdays: 
##    2021: 181, 184, 186, 188, 234-237, 240-244, 249, 251, 253, 254, 255, 261, 265-269, 294, 295, 304, 318, 319, 324, 343, 344, 355, 356, 357, 

# 2021: maybes: [127-129, 170-171 -MESSY] [185-outliers]

##    2022: 4, 5, 6, 10, 11, 12, 13, 16, 17, 18, 19, 25, 27, 29, 30, 31, 38-41, 44, 45, 61, 68, 74-78, 84-87, 90, 91, 104-107, 110-112, 121, 130-132, 134-140, 182, 304, 305, 306, 310

# 2022-62 has declining Neq throughout day; 97-100(? - slanty baseline; april)]; [186, 187, weird sharp bump up ~ 10a]

##    2023: 55, 71, 72, 75, 77, 84, 85, 86, 88, 90, 94, 95, 96, 97, 100, 102-104, 106-111, 113, 115, 121-126, 137-143, 146-148, 149, 150, 151, 152, 328, 329, 337

# 2024: 48, 61, 69, 71, 72, 73, 74, 80, 95, 97, 118, 139, 140, 141, 142, 144, 145, 147, 159, 160, 161, 165-175, 177, 179


## Remove additional days due to data / modeling weirdness: 
# 2022: 044, 305
# 2023: 075 (changing background, model missed it), 113, 115, 121, 122, 123 [bump ~ 9a / 5a model time for all 5], 143 - HIGH U and glitchy sensor, 328 sensor glitchy
# 2024: 139, 144 [bump ~ 9a / 5a model time for both]


list.21 <- c(181, 184, 186, 188, 234, 235, 236, 237, 240, 241, 242, 243, 244, 249, 251, 253, 254, 255, 261, 265, 266, 267, 268, 269, 294, 295, 304, 318, 319, 324, 343, 344, 355, 356, 357)

list.22 <- c(4, 5, 6, 10, 11, 12, 13, 16, 17, 18, 19, 25, 27, 29, 30, 31, 38, 39, 40, 41, 45, 61, 68, 74, 75, 76, 77, 78, 84, 85, 86, 87, 90, 91, 104, 105, 106, 107, 110, 111, 112, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 182, 304, 306, 310)

list.23 <- c(55, 72, 77, 84, 85, 86, 88, 90, 94, 95, 96, 97, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 124, 125, 126, 137, 138, 139, 140, 141, 142, 146, 147, 148, 149, 150, 151, 152, 329, 337)

list.24 <- c(48, 71, 72, 73, 74, 80, 95, 97, 140, 141, 142, 145, 147, 159, 160, 161, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179)



# Creating and visualizing dataframes from the selected days - 
#   PRIN looked really ... wobbly and odd, so making sure these seem like reasonable model options

prin.df.21 <- prin.df %>%
  filter(year(model_datetime) == 2021) %>%
  filter(model_jday %in% list.21)

quartz(6.5, 6.5)
prin.df.21 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("PRIN 2021") +
  theme_bw()
  
prin.df.22 <- prin.df %>%  
  filter(year(model_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

quartz(6.5, 6.5)
prin.df.22 %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~Jday) +
  ggtitle("PRIN 2022") +
  theme_bw()

prin.df.23 <- prin.df %>%  
  filter(year(model_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

quartz(6.5, 6.5)
prin.df.23 %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~model_jday) +
  ggtitle("PRIN 2023") +
  theme_bw()

prin.df.24 <- prin.df %>%  
  filter(year(model_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

quartz(6.5, 6.5)
prin.df.24 %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(10, 30) +
  facet_wrap(~model_jday) +
  ggtitle("PRIN 2024") +
  theme_bw()

# Check for complete days: should have 96 obs/ day

# check for days where obs != 96 (often leap years, or some sensor irregularity)

remove.21 <- prin.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- prin.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- prin.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- prin.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)
# remove 69 (missing 1:15) and 118 (glitchy stuff)

length(prin.df.21$model_jday)/96 #11
length(prin.df.22$model_jday)/96 #55
length(prin.df.23$model_jday)/96 #40
length(prin.df.24$model_jday)/96 #29

# prin.df.21 %>% count(model_jday) # 35
# prin.df.22 %>% count(model_jday) # 57 (after removing jday 121 because of no3 spikes at end of model day) 
# prin.df.23 %>% count(model_jday) # 48 (after removing jday 71, w. only 92 obs)


##### Combine selected days into 1 df 
prin.df.2124 <- bind_rows(prin.df.21, prin.df.22, prin.df.23, prin.df.24) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)


##### Combine df with sat_light data for the selected model days
prin.wlight.df.2124 <- left_join(x=prin.df.2124,
                                 y=prin_light.df.15, 
                                 by = "local_datetime") 


View(prin.wlight.df.2124)

# # check the 1st day in the df to make sure light joined correctly 
# jday31 <- prin_light.df %>% 
#   filter(year(local_datetime) == 2021) %>%
#   filter(month(local_datetime) == 1) %>% 
#   filter(day(local_datetime) == 31)


# save to keep progress
write_csv(prin.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/PRIN_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# prin.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/PRIN_wlight_2124_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

QMfail <- which(prin.wlight.df.2124$rangeFailQM == 1) # none, whew

no3NA <- which(is.na(prin.wlight.df.2124$surfWaterNitrateMean))
no3NA
# 20 NAs: 5251  5252  6465  6466  6467  6468  8230  8231  8232  8233 10396 10397 10398 10399 11325 12210 12211 12212 12213 12214

# 
# When do these occur? (ID any particularly bad days to remove)
NAdays <- prin.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays 
# 2022: 132(2)
# 2023:  72(4), 109(4), 
# 2024: 72(4), 145, 170(5)


lightNA <- which(is.na(prin.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  ###################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()
# 12406 12407 12408 12409 12410 12411 12412    13756 13757 13758 13759
#    first see where in the curve this gap falls: 
span <- 15755:15770
plot(prin.wlight.df.2124$local_datetime[span], prin.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #nope, the last day it seems not linear... 

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
prin.wlight.df.2124$surfWaterNitrateMean <- na.spline(prin.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill

# re-check NAs
which(is.na(prin.wlight.df.2124$surfWaterNitrateMean)) 
# no NAs remain

# visualize to make sure the spline didn't create weird outliers (esp 2023 and 2024)
yr <- 2024
# mo <- 3
plottitle <- "PRIN, 2024"

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
prin.wlight.df.2124 %>%
  filter(year(model_datetime) == yr) %>%
  # filter(month(model_datetime) == mo) %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(5, 30) +
  facet_wrap(~model_jday) +
  ggtitle(plottitle) +
  theme_bw()




N_e <- mean(prin.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #15.61
N_sd <- sd(prin.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #5.62

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
prin.wlight.df.h <- prin.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = prin_light.df.h, by = "local_datetime")

# Mean of selected dataset
N_e <- mean(prin.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #15.62
N_sd <- sd(prin.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #5.62



```

###### Visualize cleaned data

```{r - visualize PRIN clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(prin.wlight.df.h$model_jday)

# big gaps in the middle of the year - things really seemed to wash out then (flashy stream?)

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/prin_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/prin_hourly_clean.csv")
write_csv(prin.wlight.df.2124, path)
write_csv(prin.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# prin.wlight.df.2123 <- read_csv(path)
# prin.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### Sycamore Creek, Maricopa, AZ

nitrate sensor lat-long: 33.751675 -111.508603 elevation (m): 643 tz="US/Arizona"

###### Load data

```{r - SYCA}
#| output: false
#| message: false

##### Create object for SYCA => Rio Cupeyes, San German Municipio, PR

syca.df <- selectRdata(data=no3_data_sensor, site="SYCA", tz="US/Arizona", span=2021:2024)

syca_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/SYCA_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Arizona"))

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(syca_light.df$local_datetime)
tz(syca.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime
```

```{r summarize syca lightdata}
# Get summed 15 and 60m data for light: 
syca_light.df.15 <- syca_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


syca_light.df.h <- syca_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 



```

###### Visualize, select and clean SYCA data

```{r - SYCA visualize data, select days, add sat. light}

##### Visualize data and select days
##    NO days after 5/6/2024

yr <- 2024
mo <- 6
plottitle <- "SYCA, 6 2024"
# ylim(20,30) for Jan-Jun 21, Jan-Jun 23; (20, 33) for ~ Aug-Dec 2023, Jan- 2024; (17,27) for Jul-Dec 21, most of 2022, Jul 23, Jan- 2024;    : (25,35) for Oct-Dec 22

quartz(width=6.5, height=6.5)
#quartz(width=10, height=4)
syca.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  ylim(5, 15) +
  facet_wrap(~Jday) +
  ggtitle(plottitle) +
  theme_bw()


## Dygraph for interactive chart w slider - meh, doesn't work all that well for my purposes.
# syca_dy <- syca.df %>%
# select(local_datetime, surfWaterNitrateMean)
# 
# dygraph(data=syca_dy) %>%
#   dyRangeSelector()


##### ID MODEL_JDAYS to save for model
# doing this early this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays

# visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
# SYCA: COMMENTS  Clear diel no3 cycling; pattern shoots UP to pointy peak ~ 5-9a, then drops off sharply. Especially noticeable Feb 2021, March 2022, . 
# No data 2021: Jan, Jun-Dec; 2022: Jan; 2023: Jan (crazy-high data (90-120 umol/L), likely sensor error), Feb, [most of] Mar, Nov, Dec; 2024: Jan, Feb, 
# Apr-Nov 2022 - disturbance, and shifts so pattern peaks in afternoon (~10-17), w. trough in AM (~ 5-10); goes back to afternoon trough in Dec. 2022; same in June 2023

# ID Jdays: 

##    2021: 28, 32, 33, 36, 37, 41, 43, 47, 49, 50-70, 79-81, 87-90, 96-98, 103-109, 111-114, 116, 141, 142

##    2022: 34-46, 49-53, 56-62, 64-71, [72-78 - odd shape and 'nipple' at ~ 6-7:30a; nipple also in 64-71 but less evident], 350-352, 356-360

##    2023: 101-106 (a little nipple-y), 125-129, 132, 138, 139, 143-148, 150, [257, 263, 266, 274, 278, 279, 280, 281, 282, - VERY low (<1) but clear cycles]

# We may not use 2024, but it's easiest to ID good days Jan-June now
##    2024: 64, 97-100, 103-105, [112-116, nipple-y], 119-121, 125-129, 131, 138, 142, 145-147, 150-152, 155, 156


# create objects from selected jdays for each year
# list.21 <- c(28, 32, 33, 36, 37, 41, 43, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 79, 80, 81, 87, 88, 89, 90, 96, 97, 98, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 141, 142)

## Removw 2 additional days due to sensor/ model weirdness: 2023: 129; 2024: 131  (2024-129 also a bit off, but keeping) - 12/2025


# FOR WY22 ONLY
# list.21 <- c()  ## NONE

# list.21 <- c(28, 32, 33, 36, 37, 41, 43, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 79, 80, 81, 87, 88, 89, 90, 96, 97, 98, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 141, 142)

list.22 <- c(34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 350, 351, 352, 356, 357, 358, 359, 360)

list.23 <- c(101, 102, 103, 104, 105, 106, 125, 126, 127, 128, 132, 138, 139, 143, 144, 145, 146, 147, 148, 150, 257, 263, 266, 274, 278, 279, 280, 281, 282)

list.24 <- c(64, 97, 98, 99, 100, 103, 104, 105, 112, 113, 114, 115, 116, 119, 120, 121, 125, 126, 127, 128, 129, 138, 142, 145, 146, 147, 150, 151, 152, 155, 156)

# Use the objects to create dataframes of the selected *model* jdays (ensures complete 24-h model days, i.e. from 4a-3:59a)

# No SYCA days in Oct-Dec 2021 (WY 2022) - need to add in days to get > 100
# syca.df.21 <- syca.df %>%
#   filter(year(local_datetime) == 2021) %>%
#   filter(model_jday %in% list.21)

syca.df.22 <- syca.df %>%  
  filter(year(model_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

syca.df.23 <- syca.df %>%  
  filter(year(model_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

syca.df.24 <- syca.df %>%  
  filter(year(model_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

# Check for complete days: should have 96 obs/ day
# causes of n < 96 are often time change days, or some sensor irregularity

# remove.21 <- syca.df.21 %>% 
#   count(model_jday) %>%
#   filter(n != 96)

remove.22 <- syca.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- syca.df.23 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- syca.df.24 %>% 
  count(model_jday) %>%
  filter(n != 96)

# All days, all 3 years had 96 obs. 

# Double-check for even days, and get count per df
# length(syca.df.21$model_jday)/96 #54
length(syca.df.22$model_jday)/96 #41
length(syca.df.23$model_jday)/96 #29
length(syca.df.24$model_jday)/96 #31


##### Combine selected days into 1 df, select columns 
syca.df.2224 <- bind_rows(syca.df.22, syca.df.23,syca.df.24) %>%
  mutate(Year = year(model_datetime)) %>%  #changed to be consistent w. model_jday => important in SYCA where there are year-round good days!
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)

# check the # of days by dividing syca.df.2123 observations by 96 
# XXX for syca


##### Combine df with sat_light data for the selected model days
syca.wlight.df.2224 <- left_join(x=syca.df.2224,
                                 y=syca_light.df, 
                                 by = "local_datetime") 


View(syca.wlight.df.2224)


# check the 1st day in the df to make sure light joined correctly
jday22_28 <- syca_light.df %>%
  filter(year(local_datetime) == 2022) %>%
  filter(month(local_datetime) == 1) %>%
  filter(day(local_datetime) == 28)

View(jday21_28)

# save to keep progress
write_csv(syca.wlight.df.2224,file=here("N_uptake_NEON/data/neon_data_joined/SYCA_wlight_2123_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# syca.wlight.df.2224 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/SYCA_wlight_2224_joined.csv")) %>%
#   mutate(local_datetime = with_tz(local_datetime, tzone="US/Arizona"), 
#          model_datetime = with_tz())


##############################  Where are the NAs?  ############################

QMfail <- which(syca.wlight.df.2224$rangeFailQM == 1) # none, whew

### Set low/ clearly sensor-error values to NA: 

# First, ID whether there are any measurements <0
sensorfaildays <- syca.wlight.df.2224 %>%
  filter(surfWaterNitrateMean < 0)  ### none! 

sensorflagdays <- syca.wlight.df.2224 %>%
  filter(rangeFailQM == 1)  ### also none!

# max(sensorfaildays$surfWaterNitrateMean) #-0.1
# min(sensorfaildays$surfWaterNitrateMean) #-1
# which(min(sensorfaildays$surfWaterNitrateMean) == -1)

# unique(sensorfaildays$yr_jday) #24:  "2021_28" - OK  "2021_32" - kinda low  "2021_33"- OK  "2021_87"  "2021_88"  "2021_89"  "2021_90"  "2021_96"  "2021_97" "2021_98"  "2021_103" "2021_104" "2021_105" "2021_106" "2021_107" "2021_108" "2021_109" "2021_111" "2021_112" "2021_113" "2021_114" "2021_116" "2021_141" "2021_142"

# re-check the images: is this likely to be 0, or is it a sensor blip?  The curves look good, but seems like the sensor is reading low.. check flags

# then change the applicable <0 values to 0
# syca.wlight.df.2123 <- syca.wlight.df.2123 %>%
#   mutate(surfWaterNitrateMean = replace(surfWaterNitrateMean, surfWaterNitrateMean < 0, 0))


no3NA <- which(is.na(syca.wlight.df.2224$surfWaterNitrateMean))
no3NA

# 11 occurrences: 2045 2075 3647 3847 4632 5254 5899 5900 5901 8327 9279


# When do these occur? (ID any particularly bad days to remove)
NAdays <- syca.wlight.df.2224 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  select(yr_jday)                  # Select the 'Jday' column for those rows

NAdays  
# 2022: 2022_59 (2), 2022_357, 2022_360
# 2023: 2023_126, 2023_143, 2023_257 (3)
# 2024: 2024_125, 2024_150


# all are missing < 2h of data, which is fine for a gap fill 

lightNA <- which(is.na(syca.wlight.df.2224$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 5830:5855, 40060:40075
# print(syca.wlight.df.2123[5830:5860,])

span <- #4445:4460
plot(syca.wlight.df.2224$local_datetime[span], syca.wlight.df.2224$surfWaterNitrateMean[span], type = 'l')  #OK, linear seems reasonable for both gaps


# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
syca.wlight.df.2224$surfWaterNitrateMean <- na.approx(syca.wlight.df.2224$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill



# re-check NAs
which(is.na(syca.wlight.df.2224$surfWaterNitrateMean)) 
# no NAs remain

N_e <- mean(syca.wlight.df.2224$surfWaterNitrateMean, na.rm = TRUE)  #12.01
N_e
N_sd <- sd(syca.wlight.df.2224$surfWaterNitrateMean, na.rm = TRUE)   #9.74
N_sd

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
syca.wlight.df.h <- syca.wlight.df.2224 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = syca_light.df.h, by = "local_datetime")


# Mean of selected dataset
N_e <- mean(syca.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #12.01
N_sd <- sd(syca.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #9.74
N_sd



```

###### Visualize cleaned data

```{r - visualize SYCA clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(syca.wlight.df.h$model_jday)

clean.syca.plot <- ggplot(syca.wlight.df.h, aes(x=yr_jday, y=surfWaterNitrateMean)) + 
  geom_point() + 
  ggtitle("SYCA - cleaned and filled data") +
  theme_bw()

  quartz(height=6, width=7.5)
  clean.syca.plot

```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/syca_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/syca_hourly_clean.csv")
write_csv(syca.wlight.df.2224, path)
write_csv(syca.wlight.df.h, path_h)


##### Reload data-in-progress as needed
# syca.wlight.df.2123 <- read_csv(path)
# syca.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```

#### West St Louis Creek, Grand, CO

nitrate sensor lat-long: 39.890673 -105.911297 elevation (m): 2900.74 tz="US/Mountain"

###### Load data

```{r - WLOU}
#| output: false
#| message: false

##### Create object for WLOU => West St Louis Creek, Grand, CO

wlou.df <- selectRdata(data=no3_data_sensor, site="WLOU", tz="US/Mountain", span=2021:2024)

wlou_light.df <- read_csv(here("N_uptake_NEON/data/NSRDB_lightdata_clean/WLOU_satlight_all.csv")) %>%
  mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))

#tz(wlou_light.df$local_datetime) <- "US/Mountain"

# make sure the tz assigned correctly - otherwise the join doesn't work correctly, because R/ tidyverse assumes the assigned tz is correct (so, offsets the join *as if* it needed to match different tzs vs. the same one)
tz(wlou_light.df$local_datetime)
tz(wlou.df$local_datetime)
# Note that model_datetime is assigned the same tz as local_datetime

```

```{r summarize wlou lightdata}
# Get summed 15 and 60m data for light: 
wlou_light.df.15 <- wlou_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "15minutes")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


wlou_light.df.h <- wlou_light.df %>%
  mutate(local_datetime = ceiling_date(local_datetime, unit = "hour")) %>%
  group_by(local_datetime) %>%
  summarise(GHI_wm2 = sum(GHI_wm2), 
            clearsky_GHI_wm2 = sum(clearsky_GHI_wm2)) %>%
  ungroup() 


```

###### Visualize, select and clean WLOU data

```{r - WLOU visualize data, select days, add sat. light}

##### Visualize data and select days

yr <- 2024
mo <- 10

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
wlou.df %>%
  filter(year(local_datetime) == yr) %>%
  filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(local_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3.5) +
  facet_wrap(~Jday) +
  ggtitle("WLOU, 2024 10") +
  theme_bw()


wlou_dy <- wlou.df %>%
  select(local_datetime, surfWaterNitrateMean)

# Dygraph for interactive chart w slider
dygraph(data=wlou_dy) %>%
  dyRangeSelector()


##### ID MODEL_JDAYS to save for model - this makes later steps work better (determining daily light, for example). ID the actual (local time) days, but code for model jdays
#     visual check to select 120+ complete-appearing days to model from the 2.5 year dataset
#     WLOU: summer is both more disturbed and appears to have low autotrophic uptake (Deciduous shading? Cottonwoods?)

# Jdays: 
##    2021 - 32, 34:37, 40:59, 68:72, 74, (80:90 if only 1h missing), 95:113, 153:160 :164?), 238, 240, 241, 265, 268:270, 276:278, 285, 287:294, 299:307, 309:311, 313:321; 340:344  

##    2022 - 43, 53:56, 87:107, 116:123, 171, 173, 178, 179, 182:185, 202, 203, 207, 221:224, 235:240, 242, 244:255 (Xed 249 for missingness), 267:273, 279:283, 305:310, 316:318, 340, 343, 360, 363, 364

## 2023: 3, 4, 13, 16, 17, 18, 20, 21, 24, 46, 60, 62, 63, 67, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 85, 88, 98, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 1116, 117, 118, 119, 124, 125, 126, 128, 129, 142, 143, 144, 146, 147, 148, 149, 150, 152, 154, 158, 159, 162, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 227, 228, 232, 233, 269, 270, 271, 286, 287, 288, 290, 291, 292, 321, 322, 327, 328, 352, 353, 354, 355, 357, 358, 359, 365

## 2024: 1, 4, 34, 35, 40, 41, 45, 46, 47, 49, 52, 53, 54, 65, 67, 71, 73, 74, 77, 81, 82, 83, 84, 86, 88, 91, 92, 95, 97, 100, 104, 105, 113, 115, 117, 123, 124, 125, 135, 150, 151, 155, 157, 158, 159, 172, 173, 175, 176, 177, 181, 

# 2024 looks like it has a great string of days ~ Feb-April

# Removed days in 2021 and 22 for either too few or too many measurements/day: these could not be interpolated /filled/ deleted due to the 45-min data structure that proceeded from the resumed measurement time. Noticed this when looking at the Jday count, below. Excising them seemed like the simplest solution. 
# Removed 2021-73 (n=30), 2021-311 (n=34), and 2022-310 (n=33)


# list.21 <- c(32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 68, 69, 70, 71, 74, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 238, 240, 241, 265, 268, 269, 270, 276, 277, 278, 285, 287, 288, 289, 290, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 340, 341, 342, 343, 344)

#  ALSO remove thee days due to wonky modeling: 
# 2022: 273
# 2023: 158, 182, 195
# 2024: 157, 158, 159

# WY 2022 only (Oct 1 and later - jday 274)
list.21 <- c(276, 277, 278, 285, 287, 288, 289, 290, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 340, 341, 342, 343, 344)

list.22 <- c(43, 53, 54, 55, 56, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 116, 117, 118, 119, 120, 121, 122, 123, 171, 173, 178, 179, 182, 183, 184, 185, 202, 203, 207, 221, 222, 223, 224, 235, 236, 237, 238, 239, 240, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 267, 268, 269, 270, 271, 272, 279, 280, 281, 282, 283, 305, 306, 307, 308, 310, 316, 317, 318, 340, 343, 360, 363, 364)

list.23 <- c(3, 4, 13, 16, 17, 18, 20, 21, 24, 46, 60, 62, 63, 67, 69, 72, 73, 74, 75, 77, 79, 80, 85, 88, 98, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 1116, 117, 118, 119, 124, 125, 126, 128, 129, 142, 143, 144, 146, 147, 148, 149, 150, 152, 154, 159, 162, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 227, 228, 232, 233, 269, 270, 271, 286, 287, 288, 290, 291, 292, 321, 322, 327, 328, 352, 353, 354, 355, 357, 358, 359, 365)

list.24 <- c(1, 4, 34, 35, 40, 41, 45, 46, 47, 49, 52, 53, 54, 65, 67, 71, 73, 74, 77, 81, 82, 83, 84, 86, 88, 91, 92, 95, 97, 100, 104, 105, 113, 115, 117, 123, 124, 125, 135, 150, 151, 155, 172, 173, 175, 176, 177, 181)

wlou.df.21 <- wlou.df %>%
  filter(year(model_datetime) == 2021) %>%
  filter(model_jday %in% list.21)
  
wlou.df.22 <- wlou.df %>%  
  filter(year(model_datetime) == 2022) %>%
  filter(model_jday %in% list.22)

wlou.df.23 <- wlou.df %>%  
  filter(year(model_datetime) == 2023) %>%
  filter(model_jday %in% list.23)

wlou.df.24 <- wlou.df %>%  
  filter(year(model_datetime) == 2024) %>%
  filter(model_jday %in% list.24)

  wlou.df.21 %>% count(model_jday) #37
wlou.df.22 %>% count(model_jday) #92
wlou.df.23 %>% count(model_jday) #111
wlou.df.24 %>% count(model_jday) #51

# check for days where obs != 96 (often leap years, or some sensor irregularity)
remove.21 <- wlou.df.21 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.22 <- wlou.df.22 %>% 
  count(model_jday) %>%
  filter(n != 96)

remove.23 <- wlou.df.23 %>%
  count(model_jday) %>%
  filter(n != 96)

remove.24 <- wlou.df.24 %>%
  count(model_jday) %>%
  filter(n != 96)


##### Combine selected days into 1 df 
wlou.df.2124 <- bind_rows(wlou.df.21, wlou.df.22, wlou.df.23, wlou.df.24) %>%
  mutate(Year = year(model_datetime)) %>% 
  rename(UTC_startDateTime=startDateTime) %>%
  unite("yr_jday", Year:model_jday, remove=FALSE) %>%
  dplyr::select(siteID, yr_jday, model_datetime, surfWaterNitrateMean, surfWaterNitrateVariance, surfWaterNitrateStdErMean, rangeFailQM, UTC_startDateTime, local_datetime, Jday, model_jday, Year, domainID)


# check the # of days - CLUNKY
#unique(wlou.df.2122$yr_jday) #291

##### Combine df with sat_light data for the selected model days
wlou.wlight.df.2124 <- left_join(x=wlou.df.2124,
                                 y=wlou_light.df.15, 
                                 by = "local_datetime") 


View(wlou.wlight.df.2124)

# # check the 1st day in the df to make sure light joined correctly 
# jday31 <- wlou_light.df %>% 
#   filter(year(local_datetime) == 2021) %>%
#   filter(month(local_datetime) == 1) %>% 
#   filter(day(local_datetime) == 31)


# save to keep progress
write_csv(wlou.wlight.df.2124,file=here("N_uptake_NEON/data/neon_data_joined/WLOU_wlight_2124_joined.csv"))

# reload file to re-do for next step
wlou.wlight.df.2124 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WLOU_wlight_2124_joined.csv"))

```

###### Fill any gaps in no3 data

```{r fill gaps}

##############################  Reload data if needed  #########################
# wlou.wlight.df.2122 <- read_csv(here("N_uptake_NEON/data/neon_data_joined/WALK_wlight_2122_joined.csv")) %>%
#   mutate(local_datetime = force_tz(local_datetime, tzone="US/Mountain"))


##############################  Where are the NAs?  ############################

QMfail <- which(wlou.wlight.df.2124$rangeFailQM == 1) # none, whew

no3NA <- which(is.na(wlou.wlight.df.2124$surfWaterNitrateMean))
no3NA
# Occurrences: 7623  7624  9740 10299 10300 10301 10302 12024 12585 12586 12587 12588 12589 12590 15228 16654 16655 16656 16657 16658 17625 17721 17817 17913 18009 18105 18201 18297 18393 18489 18585 18681 18777 18873 18969 19065 19161 19257 19353 19449 19545 19641 19737 19833 19929 20025 20121 20217 20274 21244 21620 21621 23863 24177 24684 24898 26438 26440 26632 26633 26634

# When do these occur? (ID any particularly bad days to remove)
NAdays <- wlou.wlight.df.2124 %>%
  filter(is.na(surfWaterNitrateMean)) %>%   # Filter rows where 'no3mean' is NA
  dplyr::select(yr_jday)                  # Select the 'Jday' column for those rows

print(NAdays, n=Inf) 
# 2021: none
# 2022: 202(2), 253, 270(4), 360
# 2023: 16(6), 109, 142(5), 159, 162, 167, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 227, 290, 322(2)
# 2024: 54, 71, 83, 86, 150(2), 155(3)

lightNA <- which(is.na(wlou.wlight.df.2124$GHI_wm2))
lightNA  
# none, whew

##############################   SMALL GAPS  #####################################

# For smaller NA chunks, (8 or fewer timesteps (<= 2 hours)?) , we will interpolate using zoo()

#    first see where in the curve this gap falls: 10299 10300 10301 10302; 12697 12698 12699 12700 12701 12702;  16766 16767 16768 16769 16770;  27016 27017 27018 
span <- 27010:27023
plot(wlou.wlight.df.2124$local_datetime[span], wlou.wlight.df.2124$surfWaterNitrateMean[span], type = 'l')  #linear could work, spline may better represent actual dynamics

# Then fill
maxgap <- 8  # set the maximum gap for zoo() to fill
wlou.wlight.df.2124$surfWaterNitrateMean <- na.spline(wlou.wlight.df.2124$surfWaterNitrateMean, maxgap = maxgap)  # maxgap = max # of NAs to fill

# re-check NAs - none remain
which(is.na(wlou.wlight.df.2124$surfWaterNitrateMean)) 

# visualize data again to make sure splining didn't do odd things... 

yr <- 2023
# mo <- 1:3

quartz(width=6.5, height=6.5)
# quartz(width=10, height=4)
# wlou.wlight.df.2124 %>%
wlou.wlight.df.2124 %>%
  filter(year(model_datetime) == yr) %>%
  # filter(month(local_datetime) == mo) %>%
  ggplot(aes(x=hour(model_datetime), y = surfWaterNitrateMean)) +
  # ggplot(aes(x=local_datetime, y=surfWaterNitrateMean)) +
  geom_point() + 
  geom_line() +
  # ylim(0,3.5) +
  facet_wrap(~model_jday) +
  ggtitle("WLOU, 2024") +
  theme_bw()


N_e <- mean(wlou.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)  #3.41
N_sd <- sd(wlou.wlight.df.2124$surfWaterNitrateMean, na.rm = TRUE)   #1.61

## Select hourly no3 measurements to match what we've been doing  => CHANGE THIS LATER
wlou.wlight.df.h <- wlou.wlight.df.2124 %>%
  filter(minute(local_datetime) == 0) %>%
  dplyr::select(-c(GHI_wm2, clearsky_GHI_wm2)) %>%
  left_join(y = wlou_light.df.h, by = "local_datetime")


# Mean of selected dataset
N_e <- mean(wlou.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE) #3.41
N_sd <- sd(wlou.wlight.df.h$surfWaterNitrateMean, na.rm = TRUE)  #1.61



```

###### Visualize cleaned data

```{r - visualize WLOU clean}

# jday distribution plot (do we have even coverage across a generic year?)
hist(wlou.wlight.df.h$model_jday)



```

###### Save cleaned site df

```{r - Save cleaned df}

############################  Save cleaned site DF ###############################

path <- here("N_uptake_NEON/data/neon_data_clean/wlou_clean.csv")
path_h <- here("N_uptake_NEON/data/neon_data_clean/wlou_hourly_clean.csv")
write_csv(wlou.wlight.df.2124, path)
write_csv(wlou.wlight.df.h, path_h)

##### Reload data-in-progress as needed
# wlou.wlight.df.2122 <- read_csv(path)
# wlou.wlight.df.h <- read_csv(path_h)

# Once saved, clear the environment EXCEPT for the main dataframe + function: 
rm(list = setdiff(ls(), c("no3_data_sensor", "selectRdata")))

```
